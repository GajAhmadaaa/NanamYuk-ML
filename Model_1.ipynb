{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GajAhmadaaa/NanamYuk-ML/blob/main/Model_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# City Based Weather Analysis"
      ],
      "metadata": {
        "id": "3hWsdMSWy203"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the required libraries\n",
        "import requests\n",
        "# Enter the api key of openweathermap here\n",
        "api_key = \"81c713c1b0fea513c62681c97920daa9\"\n",
        "# Base url for the open map api\n",
        "root_url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
        "# Input the City name for which we need the weather data\n",
        "city_name = input(\"Please Enter The City Name : \")\n",
        "# Building the final url for the API call\n",
        "url = f\"{root_url}appid={api_key}&q={city_name}\"\n",
        "# sending a get request at the url\n",
        "r = requests.get(url)\n",
        "# storing the returned json data into a variable\n",
        "data = r.json()\n",
        "# Checking If there is no error and the status code is 200\n",
        "if data['cod'] == 200:\n",
        "    # getting the temperature from the json data\n",
        "    temp = data['main']['temp'] - 273.15\n",
        "    # getting the pressure from the json data\n",
        "    pressure = data['main']['pressure']\n",
        "    # getting the humidity from the json data\n",
        "    humidity = data['main']['humidity']\n",
        "    # getting the description from the json data\n",
        "    descr = data['weather'][0]['description']\n",
        "    # getting the wind speed from the json data\n",
        "    wind = data['wind']['speed']\n",
        "    # Displaying all the data\n",
        "    print(f\"City Name : {city_name}\")\n",
        "    print(f\"The Weather Condition is {descr}\")\n",
        "    print(f\"The temperature is {temp :.2f} Celsius\")\n",
        "    print(f\"The pressure is {pressure}hPa\")\n",
        "    print(f\"The humidity is {humidity}%\")\n",
        "    print(f\"The speed of wind is {wind}m/s\")\n",
        "    print(url)\n",
        "else:\n",
        "    # If any error occured then print this\n",
        "    print(\"Something Went Wrong\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fam5io_64MMA",
        "outputId": "2bb28f98-7d75-412a-8a9b-a2fe846698b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Enter The City Name : Jakarta\n",
            "City Name : Jakarta\n",
            "The Weather Condition is heavy intensity rain\n",
            "The temperature is 22.96 Celsius\n",
            "The pressure is 1010hPa\n",
            "The humidity is 83%\n",
            "The speed of wind is 1.51m/s\n",
            "http://api.openweathermap.org/data/2.5/weather?appid=81c713c1b0fea513c62681c97920daa9&q=Jakarta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improved City Based Weather Analysis but just avg Temp within month"
      ],
      "metadata": {
        "id": "AD9D0Qouq5RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "today = datetime.today()\n",
        "\n",
        "api_key = \"81c713c1b0fea513c62681c97920daa9\"\n",
        "\n",
        "root_url = \"https://history.openweathermap.org/data/2.5/aggregated/month?\"\n",
        "\n",
        "city_name = input(\"Please Enter The City Name : \")\n",
        "\n",
        "url = f\"{root_url}month={today.month}&q={city_name},ID&appid={api_key}\"\n",
        "\n",
        "r = requests.get(url)\n",
        "\n",
        "data = r.json()\n",
        "# Checking If there is no error and the status code is 200\n",
        "if data['cod'] == 200:\n",
        "    # getting the temperature from the json data\n",
        "    temp = data['result']['temp']['mean'] - 273.15\n",
        "    # getting the humidity from the json data\n",
        "    humidity = data['result']['humidity']['mean']\n",
        "    # getting the month from the json data\n",
        "    month = data['result']['month']\n",
        "    print(f\"City Name : {city_name}\")\n",
        "    print(f\"The avg temperature in month {month} is {temp :.2f} Celsius\")\n",
        "    print(f\"The avg humidity in month {month} is {humidity :.2f} %\")\n",
        "    print(url)\n",
        "else:\n",
        "    message = data['message']\n",
        "    print(\"Something Went Wrong,\", message)"
      ],
      "metadata": {
        "id": "Xv_g8NqYq2t8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93fec13c-dc5e-4976-e870-9dbfe7f150d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Enter The City Name : Jakarta\n",
            "City Name : Jakarta\n",
            "The avg temperature in month 5 is 28.63 Celsius\n",
            "The avg humidity in month 5 is 77.34 %\n",
            "https://history.openweathermap.org/data/2.5/aggregated/month?month=5&q=Jakarta,ID&appid=81c713c1b0fea513c62681c97920daa9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error handling with try except for location that has no weather history data"
      ],
      "metadata": {
        "id": "UFzlOgwNcJ3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "today = datetime.today()\n",
        "\n",
        "api_key = \"81c713c1b0fea513c62681c97920daa9\"\n",
        "city_name = input(\"Please Enter The City Name : \")\n",
        "\n",
        "###########################################################################\n",
        "# Bisa dijadikan Method #\n",
        "root_url = \"https://history.openweathermap.org/data/2.5/aggregated/month?\"\n",
        "url = f\"{root_url}month={today.month}&q={city_name},ID&appid={api_key}\"\n",
        "r = requests.get(url)\n",
        "data = r.json()\n",
        "\n",
        "root_url2 = \"https://api.openweathermap.org/data/2.5/weather?\"\n",
        "url2 = f\"{root_url2}q={city_name}&appid={api_key}\"\n",
        "r2 = requests.get(url2)\n",
        "data2 = r2.json()\n",
        "############################################################################\n",
        "\n",
        "# Checking If there is no error and the status code is 200\n",
        "try:\n",
        "  if data['cod'] == 200:\n",
        "      # getting the temperature from the json data\n",
        "      temp = data['result']['temp']['mean'] - 273.15\n",
        "      # getting the humidity from the json data\n",
        "      humidity = data['result']['humidity']['mean']\n",
        "      precipitation = data['result']['precipitation']['mean']\n",
        "      # getting the month from the json data\n",
        "      month = data['result']['month']\n",
        "      print(f\"City Name : {city_name}\")\n",
        "      print(f\"The avg temperature in month {month} is {temp :.2f} Celsius\")\n",
        "      print(f\"The avg humidity in month {month} is {humidity :.2f} %\")\n",
        "      print(f\"The avg humidity in month {month} is {precipitation * 100 :.2f} %\")\n",
        "      print(url)\n",
        "  else:\n",
        "      message = data['message']\n",
        "      print(\"Something Went Wrong,\", message)\n",
        "except:\n",
        "  if data['code'] == 404000:\n",
        "    message = data['message']\n",
        "    print(f\"Error, {message}. Switching to current weather....\")\n",
        "    # getting the temperature from the json data\n",
        "    temp = data2['main']['temp'] - 273.15\n",
        "    # getting the humidity from the json data\n",
        "    humidity = data2['main']['humidity']\n",
        "    print(f\"City Name : {city_name}\")\n",
        "    print(f\"The current temperature is {temp :.2f} Celsius\")\n",
        "    print(f\"The current humidity is {humidity :.2f} %\")\n",
        "    print(url2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4jWOqCidLZM",
        "outputId": "8db51d21-d0a7-44db-ada0-687e81d719c4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please Enter The City Name : jakarta\n",
            "City Name : jakarta\n",
            "The avg temperature in month 5 is 28.62 Celsius\n",
            "The avg humidity in month 5 is 77.31 %\n",
            "The avg humidity in month 5 is 8.00 %\n",
            "https://history.openweathermap.org/data/2.5/aggregated/month?month=5&q=jakarta,ID&appid=81c713c1b0fea513c62681c97920daa9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dummy Dataset"
      ],
      "metadata": {
        "id": "EUa485-lTZQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "data1 =pd.DataFrame({\"Temperature\" : np.random.uniform(20, 33, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 61, 500).round(2),\n",
        "                     \"Label\"  : \"Bayam Hijau\"})\n",
        "data2 =pd.DataFrame({\"Temperature\" : np.random.uniform(20,28, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(60, 81, 500).round(2),\n",
        "                     \"Label\"  : \"Tomat\"})\n",
        "data3 =pd.DataFrame({\"Temperature\" : np.random.uniform(25,30, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 81 , 500).round(2),\n",
        "                     \"Label\"  : \"Kangkung\"})\n",
        "data4 =pd.DataFrame({\"Temperature\" : np.random.uniform(22,30, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(80, 91, 500).round(2),\n",
        "                     \"Label\"  : \"Terung\"})\n",
        "data5 =pd.DataFrame({\"Temperature\" : np.random.uniform(18,20, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.2, 0.6, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(80, 91, 500).round(2),\n",
        "                     \"Label\"  : \"Kubis\"})\n",
        "data6 =pd.DataFrame({\"Temperature\" : np.random.uniform(21,32, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.6, 0.2, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(2,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(30, 51, 500).round(2),\n",
        "                     \"Label\"  : \"Lidah Mertua\"})\n",
        "data7 =pd.DataFrame({\"Temperature\" : np.random.uniform(23,30, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.4, 0.5, 0.1], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(2,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 61, 500).round(2),\n",
        "                     \"Label\"  : \"Sri Rezeki\"})\n",
        "data8 =pd.DataFrame({\"Temperature\" : np.random.uniform(20,33, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.6, 0.2, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(35, 46, 500).round(2),\n",
        "                     \"Label\"  : \"Lidah Buaya\"})\n",
        "data9 =pd.DataFrame({\"Temperature\" : np.random.uniform(18,31, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.6, 0.2, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,3), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 71, 500).round(2),\n",
        "                     \"Label\"  : \"Kuping Gajah\"})\n",
        "data10 =pd.DataFrame({\"Temperature\" : np.random.uniform(16,32, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.6, 0.2, 0.2], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(80, 96, 500).round(2),\n",
        "                     \"Label\"  : \"Lavender\"})\n",
        "data11 =pd.DataFrame({\"Temperature\" : np.random.uniform(16,30, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.3, 0.3, 0.4], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 61, 500).round(2),\n",
        "                     \"Label\"  : \"Mawar\"})\n",
        "data12 =pd.DataFrame({\"Temperature\" : np.random.uniform(24,36, 500).round(2),\n",
        "                     \"Soil\" : np.random.choice(range(1,4), p=[0.4, 0.2, 0.4], size=500, replace=True),\n",
        "                     \"Light\" : np.random.choice(range(1,2), 500, replace=True),\n",
        "                     \"Humid\" : np.random.uniform(50, 81, 500).round(2),\n",
        "                     \"Label\"  : \"Melati\"})"
      ],
      "metadata": {
        "id": "kKUc71aXWaw5"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data1.append(data2, ignore_index=True).append(data3, ignore_index=True).append(data4, ignore_index=True).append(data5, ignore_index=True)\\\n",
        "          .append(data6, ignore_index=True).append(data7, ignore_index=True).append(data8, ignore_index=True).append(data9, ignore_index=True)\\\n",
        "          .append(data10, ignore_index=True).append(data11, ignore_index=True).append(data12, ignore_index=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5PVSyF0qpaCY",
        "outputId": "10730aa6-8703-465d-f40f-26c5b6ebb0bd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Temperature  Soil  Light  Humid        Label\n",
              "0           27.13     2      1  56.52  Bayam Hijau\n",
              "1           29.30     2      1  50.11  Bayam Hijau\n",
              "2           27.84     2      1  55.23  Bayam Hijau\n",
              "3           27.08     2      1  57.80  Bayam Hijau\n",
              "4           25.51     2      1  50.48  Bayam Hijau\n",
              "...           ...   ...    ...    ...          ...\n",
              "5995        28.82     3      1  63.40       Melati\n",
              "5996        34.49     2      1  79.80       Melati\n",
              "5997        30.43     3      1  60.23       Melati\n",
              "5998        28.25     1      1  50.85       Melati\n",
              "5999        35.23     2      1  74.19       Melati\n",
              "\n",
              "[6000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b16d7438-afad-4989-8aa8-86feb6fb9eb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Soil</th>\n",
              "      <th>Light</th>\n",
              "      <th>Humid</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27.13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>56.52</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>29.30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50.11</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27.84</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>55.23</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.08</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57.80</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.51</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>50.48</td>\n",
              "      <td>Bayam Hijau</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>28.82</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>63.40</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>34.49</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>79.80</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>30.43</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>60.23</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>28.25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50.85</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>35.23</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>74.19</td>\n",
              "      <td>Melati</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b16d7438-afad-4989-8aa8-86feb6fb9eb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b16d7438-afad-4989-8aa8-86feb6fb9eb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b16d7438-afad-4989-8aa8-86feb6fb9eb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using good dataset\n",
        "# df = pd.read_csv('/content/Crop_recommendation.csv')\n",
        "# df = df.drop(['N', 'P', 'K'], axis=1)"
      ],
      "metadata": {
        "id": "8CmzSaAt-6xt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation | TensorFlow Raw"
      ],
      "metadata": {
        "id": "c9yVSA4jTP32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "AnFnIzT1kzvY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    '''\n",
        "    Halts the training after reaching 60 percent accuracy\n",
        "\n",
        "    Args:\n",
        "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
        "      logs (dict) - metric results from the training epoch\n",
        "    '''\n",
        "\n",
        "    # Check accuracy\n",
        "    if(logs.get('accuracy') > 0.8):\n",
        "\n",
        "      # Stop if threshold is met\n",
        "      print(\"\\naccuracy is more than 0.8 so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "# Instantiate class\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "rBTiGNFBFG2z"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:4].values\n",
        "y = df.iloc[:,4].values"
      ],
      "metadata": {
        "id": "chYQosI7R4J9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0:5])\n",
        "print(y[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R6jCOWpR-vm",
        "outputId": "5aa7ad3d-df49-412c-ea1f-a1d34fbc9106"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[27.13  2.    1.   56.52]\n",
            " [29.3   2.    1.   50.11]\n",
            " [27.84  2.    1.   55.23]\n",
            " [27.08  2.    1.   57.8 ]\n",
            " [25.51  2.    1.   50.48]]\n",
            "['Bayam Hijau' 'Bayam Hijau' 'Bayam Hijau' 'Bayam Hijau' 'Bayam Hijau']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "4Xf53TJ3SLK8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ac6606-cdb8-435c-f09b-d92cfdafa02e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6000, 4)\n",
            "(6000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder =  LabelEncoder()\n",
        "y1 = encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "Lj2Who3oSMu-"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y1)"
      ],
      "metadata": {
        "id": "xf_vs3-QSPIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1fd56ea-89cf-4a81-cc28-04d19646a4dc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 8 8 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y = pd.get_dummies(y1).values\n",
        "print(Y[0:5])"
      ],
      "metadata": {
        "id": "JSaprB5lSRC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c80b4ea-4652-4a64-f1ec-b3e744ef232e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# set aside 20% of train and test data for evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
        "    test_size=0.2, shuffle = True, random_state = 8)\n",
        "\n",
        "# Use the same function above for the validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
        "    test_size=0.25, random_state= 8) # 0.25 x 0.8 = 0.2"
      ],
      "metadata": {
        "id": "sNxZyS-fSTKO"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0:5])"
      ],
      "metadata": {
        "id": "rDqZLG76SVtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8fa0d7c-7d8c-4840-e82f-aba9a32f24ce"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[25.34  2.    2.   64.7 ]\n",
            " [31.95  2.    1.   55.57]\n",
            " [23.    1.    1.   81.54]\n",
            " [25.38  3.    1.   52.85]\n",
            " [22.39  2.    1.   52.67]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[0:5])"
      ],
      "metadata": {
        "id": "eKJTsFXxSZ_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fec1640-31d5-4624-ce52-9fa0f810106b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test[0:5])"
      ],
      "metadata": {
        "id": "WO6FiKmKSbsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c36f19e-f210-48cc-8634-22ef4988d92d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18.19  2.    1.   80.47]\n",
            " [19.96  3.    1.   80.09]\n",
            " [23.51  1.    2.   36.69]\n",
            " [25.73  2.    1.   60.55]\n",
            " [27.46  1.    1.   80.93]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[0:5])"
      ],
      "metadata": {
        "id": "OwMTbCGpSdYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11084a7b-b132-4014-b961-3ca085d141cd"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, input_dim=4, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(12, activation='softmax')\n",
        "    # tf.keras.layers.Dense(22, activation='softmax') Example Using good Dataset\n",
        "  ])\n",
        "model"
      ],
      "metadata": {
        "id": "D8LgKJYjSe46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fbb1b7-0906-4db6-f7d6-e39cd5f7a75e"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7fe4cab30a90>"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "x1oV8kUzSg8C"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    batch_size=50, \n",
        "                    epochs=1000, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[callbacks])"
      ],
      "metadata": {
        "id": "qo06yjzISipL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3787e9-3a69-4fcd-db3f-439c28564e7e"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.6900 - val_loss: 0.7612 - val_accuracy: 0.6725\n",
            "Epoch 2/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.6861 - val_loss: 0.7018 - val_accuracy: 0.6975\n",
            "Epoch 3/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.6931 - val_loss: 0.7245 - val_accuracy: 0.6725\n",
            "Epoch 4/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7214 - accuracy: 0.6792 - val_loss: 0.7510 - val_accuracy: 0.6833\n",
            "Epoch 5/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.6786 - val_loss: 0.7898 - val_accuracy: 0.6467\n",
            "Epoch 6/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.6825 - val_loss: 0.7738 - val_accuracy: 0.6667\n",
            "Epoch 7/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7299 - accuracy: 0.6775 - val_loss: 0.7131 - val_accuracy: 0.6950\n",
            "Epoch 8/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7050 - accuracy: 0.6856 - val_loss: 0.6976 - val_accuracy: 0.6892\n",
            "Epoch 9/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7009 - accuracy: 0.6919 - val_loss: 0.7118 - val_accuracy: 0.6908\n",
            "Epoch 10/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7187 - accuracy: 0.6800 - val_loss: 0.7291 - val_accuracy: 0.6875\n",
            "Epoch 11/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7413 - accuracy: 0.6708 - val_loss: 0.8292 - val_accuracy: 0.6242\n",
            "Epoch 12/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7723 - accuracy: 0.6617 - val_loss: 0.7152 - val_accuracy: 0.6883\n",
            "Epoch 13/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.6883 - val_loss: 0.7339 - val_accuracy: 0.6850\n",
            "Epoch 14/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7453 - accuracy: 0.6711 - val_loss: 0.7992 - val_accuracy: 0.6458\n",
            "Epoch 15/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.6839 - val_loss: 0.7438 - val_accuracy: 0.6533\n",
            "Epoch 16/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7436 - accuracy: 0.6753 - val_loss: 0.7556 - val_accuracy: 0.6667\n",
            "Epoch 17/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.6750 - val_loss: 0.8707 - val_accuracy: 0.6342\n",
            "Epoch 18/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.6761 - val_loss: 0.7310 - val_accuracy: 0.6692\n",
            "Epoch 19/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.6858 - val_loss: 0.7387 - val_accuracy: 0.6842\n",
            "Epoch 20/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7265 - accuracy: 0.6808 - val_loss: 0.7082 - val_accuracy: 0.6900\n",
            "Epoch 21/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7089 - accuracy: 0.6858 - val_loss: 0.7582 - val_accuracy: 0.6808\n",
            "Epoch 22/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.6861 - val_loss: 0.7326 - val_accuracy: 0.6783\n",
            "Epoch 23/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.6844 - val_loss: 0.7057 - val_accuracy: 0.7000\n",
            "Epoch 24/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7241 - accuracy: 0.6797 - val_loss: 0.7392 - val_accuracy: 0.6842\n",
            "Epoch 25/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7042 - accuracy: 0.6864 - val_loss: 0.7031 - val_accuracy: 0.6850\n",
            "Epoch 26/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7226 - accuracy: 0.6761 - val_loss: 0.7280 - val_accuracy: 0.6925\n",
            "Epoch 27/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.6744 - val_loss: 0.7272 - val_accuracy: 0.6800\n",
            "Epoch 28/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7001 - accuracy: 0.6914 - val_loss: 0.7602 - val_accuracy: 0.6642\n",
            "Epoch 29/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7130 - accuracy: 0.6867 - val_loss: 0.8149 - val_accuracy: 0.6450\n",
            "Epoch 30/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7370 - accuracy: 0.6756 - val_loss: 0.7571 - val_accuracy: 0.6792\n",
            "Epoch 31/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7225 - accuracy: 0.6844 - val_loss: 0.7248 - val_accuracy: 0.6883\n",
            "Epoch 32/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7309 - accuracy: 0.6800 - val_loss: 0.8323 - val_accuracy: 0.6325\n",
            "Epoch 33/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7300 - accuracy: 0.6728 - val_loss: 0.7504 - val_accuracy: 0.6692\n",
            "Epoch 34/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.6950 - val_loss: 0.7530 - val_accuracy: 0.6758\n",
            "Epoch 35/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.6886 - val_loss: 0.7450 - val_accuracy: 0.6775\n",
            "Epoch 36/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7305 - accuracy: 0.6783 - val_loss: 0.8411 - val_accuracy: 0.6425\n",
            "Epoch 37/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7340 - accuracy: 0.6822 - val_loss: 0.7188 - val_accuracy: 0.6783\n",
            "Epoch 38/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.6892 - val_loss: 0.7258 - val_accuracy: 0.6775\n",
            "Epoch 39/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7095 - accuracy: 0.6847 - val_loss: 0.7515 - val_accuracy: 0.6708\n",
            "Epoch 40/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7310 - accuracy: 0.6819 - val_loss: 0.8028 - val_accuracy: 0.6550\n",
            "Epoch 41/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7248 - accuracy: 0.6847 - val_loss: 0.7665 - val_accuracy: 0.6617\n",
            "Epoch 42/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7286 - accuracy: 0.6778 - val_loss: 0.7443 - val_accuracy: 0.6775\n",
            "Epoch 43/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.6883 - val_loss: 0.7030 - val_accuracy: 0.6833\n",
            "Epoch 44/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7043 - accuracy: 0.6878 - val_loss: 0.7553 - val_accuracy: 0.6600\n",
            "Epoch 45/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7197 - accuracy: 0.6761 - val_loss: 0.7479 - val_accuracy: 0.6775\n",
            "Epoch 46/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.6892 - val_loss: 0.7012 - val_accuracy: 0.6883\n",
            "Epoch 47/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7114 - accuracy: 0.6944 - val_loss: 0.8911 - val_accuracy: 0.6325\n",
            "Epoch 48/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7154 - accuracy: 0.6914 - val_loss: 0.7171 - val_accuracy: 0.6942\n",
            "Epoch 49/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.6931 - val_loss: 0.7082 - val_accuracy: 0.6958\n",
            "Epoch 50/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7021 - accuracy: 0.6925 - val_loss: 0.8810 - val_accuracy: 0.6092\n",
            "Epoch 51/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7105 - accuracy: 0.6911 - val_loss: 0.7232 - val_accuracy: 0.6808\n",
            "Epoch 52/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.6786 - val_loss: 0.7161 - val_accuracy: 0.6750\n",
            "Epoch 53/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7121 - accuracy: 0.6811 - val_loss: 0.7157 - val_accuracy: 0.6750\n",
            "Epoch 54/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.6853 - val_loss: 0.6876 - val_accuracy: 0.7075\n",
            "Epoch 55/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.6872 - val_loss: 0.7135 - val_accuracy: 0.6925\n",
            "Epoch 56/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7031 - accuracy: 0.6928 - val_loss: 0.7124 - val_accuracy: 0.6917\n",
            "Epoch 57/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6967 - accuracy: 0.6933 - val_loss: 0.7460 - val_accuracy: 0.6717\n",
            "Epoch 58/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7311 - accuracy: 0.6775 - val_loss: 0.7066 - val_accuracy: 0.6883\n",
            "Epoch 59/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7015 - accuracy: 0.6889 - val_loss: 0.7187 - val_accuracy: 0.6767\n",
            "Epoch 60/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7058 - accuracy: 0.6967 - val_loss: 0.7237 - val_accuracy: 0.6825\n",
            "Epoch 61/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6992 - accuracy: 0.6886 - val_loss: 0.7097 - val_accuracy: 0.6917\n",
            "Epoch 62/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7305 - accuracy: 0.6803 - val_loss: 0.7213 - val_accuracy: 0.6742\n",
            "Epoch 63/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7150 - accuracy: 0.6864 - val_loss: 0.7010 - val_accuracy: 0.6967\n",
            "Epoch 64/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7047 - accuracy: 0.6850 - val_loss: 0.7145 - val_accuracy: 0.6842\n",
            "Epoch 65/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7272 - accuracy: 0.6769 - val_loss: 0.7077 - val_accuracy: 0.6767\n",
            "Epoch 66/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7059 - accuracy: 0.6883 - val_loss: 0.7447 - val_accuracy: 0.6683\n",
            "Epoch 67/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7037 - accuracy: 0.6908 - val_loss: 0.7446 - val_accuracy: 0.6833\n",
            "Epoch 68/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7333 - accuracy: 0.6817 - val_loss: 0.7389 - val_accuracy: 0.6867\n",
            "Epoch 69/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7017 - accuracy: 0.6944 - val_loss: 0.7169 - val_accuracy: 0.6867\n",
            "Epoch 70/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.6847 - val_loss: 0.7193 - val_accuracy: 0.6783\n",
            "Epoch 71/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.6769 - val_loss: 0.6964 - val_accuracy: 0.7000\n",
            "Epoch 72/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.6889 - val_loss: 0.7680 - val_accuracy: 0.6592\n",
            "Epoch 73/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7393 - accuracy: 0.6733 - val_loss: 0.7725 - val_accuracy: 0.6625\n",
            "Epoch 74/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7537 - accuracy: 0.6669 - val_loss: 0.7324 - val_accuracy: 0.6692\n",
            "Epoch 75/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7055 - accuracy: 0.6897 - val_loss: 0.7111 - val_accuracy: 0.6883\n",
            "Epoch 76/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7043 - accuracy: 0.6861 - val_loss: 0.7144 - val_accuracy: 0.6942\n",
            "Epoch 77/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.6925 - val_loss: 0.7545 - val_accuracy: 0.6667\n",
            "Epoch 78/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6989 - val_loss: 0.7144 - val_accuracy: 0.6933\n",
            "Epoch 79/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.6781 - val_loss: 0.8418 - val_accuracy: 0.6475\n",
            "Epoch 80/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7144 - accuracy: 0.6867 - val_loss: 0.7388 - val_accuracy: 0.6708\n",
            "Epoch 81/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.6861 - val_loss: 0.7061 - val_accuracy: 0.6867\n",
            "Epoch 82/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7175 - accuracy: 0.6892 - val_loss: 0.7285 - val_accuracy: 0.6767\n",
            "Epoch 83/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6988 - accuracy: 0.6867 - val_loss: 0.7415 - val_accuracy: 0.6808\n",
            "Epoch 84/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.6878 - val_loss: 0.7496 - val_accuracy: 0.6650\n",
            "Epoch 85/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7033 - accuracy: 0.6917 - val_loss: 0.7622 - val_accuracy: 0.6767\n",
            "Epoch 86/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6993 - accuracy: 0.6936 - val_loss: 0.7276 - val_accuracy: 0.6725\n",
            "Epoch 87/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7240 - accuracy: 0.6792 - val_loss: 0.7164 - val_accuracy: 0.6867\n",
            "Epoch 88/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7124 - accuracy: 0.6853 - val_loss: 0.8573 - val_accuracy: 0.6508\n",
            "Epoch 89/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7081 - accuracy: 0.6886 - val_loss: 0.7245 - val_accuracy: 0.6842\n",
            "Epoch 90/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7290 - accuracy: 0.6808 - val_loss: 0.7331 - val_accuracy: 0.6783\n",
            "Epoch 91/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7019 - accuracy: 0.6861 - val_loss: 0.7155 - val_accuracy: 0.6825\n",
            "Epoch 92/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7121 - accuracy: 0.6800 - val_loss: 0.7263 - val_accuracy: 0.6792\n",
            "Epoch 93/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7038 - accuracy: 0.6856 - val_loss: 0.7087 - val_accuracy: 0.7025\n",
            "Epoch 94/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.6894 - val_loss: 0.7087 - val_accuracy: 0.6900\n",
            "Epoch 95/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7081 - accuracy: 0.6800 - val_loss: 0.7091 - val_accuracy: 0.6825\n",
            "Epoch 96/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6995 - accuracy: 0.7003 - val_loss: 0.7600 - val_accuracy: 0.6533\n",
            "Epoch 97/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.6889 - val_loss: 0.6936 - val_accuracy: 0.7017\n",
            "Epoch 98/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7023 - accuracy: 0.6947 - val_loss: 0.7138 - val_accuracy: 0.6850\n",
            "Epoch 99/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.6719 - val_loss: 0.6948 - val_accuracy: 0.6967\n",
            "Epoch 100/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7005 - accuracy: 0.6886 - val_loss: 0.7010 - val_accuracy: 0.6858\n",
            "Epoch 101/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6897 - val_loss: 0.7483 - val_accuracy: 0.6625\n",
            "Epoch 102/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.6908 - val_loss: 0.7081 - val_accuracy: 0.6858\n",
            "Epoch 103/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.6878 - val_loss: 0.8110 - val_accuracy: 0.6450\n",
            "Epoch 104/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7217 - accuracy: 0.6758 - val_loss: 0.6989 - val_accuracy: 0.7025\n",
            "Epoch 105/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.6853 - val_loss: 0.7486 - val_accuracy: 0.6667\n",
            "Epoch 106/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7115 - accuracy: 0.6792 - val_loss: 0.6873 - val_accuracy: 0.6983\n",
            "Epoch 107/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7149 - accuracy: 0.6878 - val_loss: 0.7127 - val_accuracy: 0.6775\n",
            "Epoch 108/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7030 - accuracy: 0.6925 - val_loss: 0.7025 - val_accuracy: 0.6917\n",
            "Epoch 109/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.6908 - val_loss: 0.7814 - val_accuracy: 0.6683\n",
            "Epoch 110/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.6703 - val_loss: 0.7832 - val_accuracy: 0.6608\n",
            "Epoch 111/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7188 - accuracy: 0.6858 - val_loss: 0.7126 - val_accuracy: 0.6867\n",
            "Epoch 112/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.6906 - val_loss: 0.7166 - val_accuracy: 0.6867\n",
            "Epoch 113/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7000 - accuracy: 0.6831 - val_loss: 0.7176 - val_accuracy: 0.6825\n",
            "Epoch 114/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.6892 - val_loss: 0.7278 - val_accuracy: 0.6833\n",
            "Epoch 115/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7266 - accuracy: 0.6836 - val_loss: 0.7512 - val_accuracy: 0.6667\n",
            "Epoch 116/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.6917 - val_loss: 0.7065 - val_accuracy: 0.6800\n",
            "Epoch 117/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.6925 - val_loss: 0.7268 - val_accuracy: 0.6775\n",
            "Epoch 118/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7239 - accuracy: 0.6725 - val_loss: 0.7000 - val_accuracy: 0.6875\n",
            "Epoch 119/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.6903 - val_loss: 0.7937 - val_accuracy: 0.6750\n",
            "Epoch 120/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7142 - accuracy: 0.6806 - val_loss: 0.7057 - val_accuracy: 0.6958\n",
            "Epoch 121/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.6967 - val_loss: 0.7534 - val_accuracy: 0.6683\n",
            "Epoch 122/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7040 - accuracy: 0.6861 - val_loss: 0.7059 - val_accuracy: 0.6925\n",
            "Epoch 123/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7084 - accuracy: 0.6903 - val_loss: 0.7152 - val_accuracy: 0.6883\n",
            "Epoch 124/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7043 - accuracy: 0.6886 - val_loss: 0.7099 - val_accuracy: 0.6817\n",
            "Epoch 125/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.6911 - val_loss: 0.7027 - val_accuracy: 0.6917\n",
            "Epoch 126/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.6950 - val_loss: 0.7121 - val_accuracy: 0.6933\n",
            "Epoch 127/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.7028 - val_loss: 0.7035 - val_accuracy: 0.6883\n",
            "Epoch 128/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.6858 - val_loss: 0.7188 - val_accuracy: 0.6858\n",
            "Epoch 129/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.6961 - val_loss: 0.7047 - val_accuracy: 0.6908\n",
            "Epoch 130/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7315 - accuracy: 0.6789 - val_loss: 0.7529 - val_accuracy: 0.6667\n",
            "Epoch 131/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.6908 - val_loss: 0.7371 - val_accuracy: 0.6775\n",
            "Epoch 132/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7193 - accuracy: 0.6844 - val_loss: 0.7168 - val_accuracy: 0.6683\n",
            "Epoch 133/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.6931 - val_loss: 0.7255 - val_accuracy: 0.6908\n",
            "Epoch 134/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7127 - accuracy: 0.6822 - val_loss: 0.7502 - val_accuracy: 0.6675\n",
            "Epoch 135/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6956 - val_loss: 0.7211 - val_accuracy: 0.6875\n",
            "Epoch 136/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7310 - accuracy: 0.6819 - val_loss: 0.7420 - val_accuracy: 0.6808\n",
            "Epoch 137/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.6956 - val_loss: 0.7316 - val_accuracy: 0.6683\n",
            "Epoch 138/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.6883 - val_loss: 0.7047 - val_accuracy: 0.6875\n",
            "Epoch 139/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7097 - accuracy: 0.6831 - val_loss: 0.7531 - val_accuracy: 0.6767\n",
            "Epoch 140/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7136 - accuracy: 0.6906 - val_loss: 0.7457 - val_accuracy: 0.6692\n",
            "Epoch 141/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.6936 - val_loss: 0.7284 - val_accuracy: 0.6917\n",
            "Epoch 142/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.6817 - val_loss: 0.7881 - val_accuracy: 0.6683\n",
            "Epoch 143/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.6947 - val_loss: 0.7414 - val_accuracy: 0.6742\n",
            "Epoch 144/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6990 - accuracy: 0.6922 - val_loss: 0.7027 - val_accuracy: 0.6850\n",
            "Epoch 145/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.6803 - val_loss: 0.7066 - val_accuracy: 0.6850\n",
            "Epoch 146/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.7008 - val_loss: 0.7042 - val_accuracy: 0.6900\n",
            "Epoch 147/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.6844 - val_loss: 0.7083 - val_accuracy: 0.6858\n",
            "Epoch 148/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.7017 - val_loss: 0.7069 - val_accuracy: 0.6942\n",
            "Epoch 149/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.6978 - val_loss: 0.6996 - val_accuracy: 0.6958\n",
            "Epoch 150/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.6972 - val_loss: 0.7274 - val_accuracy: 0.6725\n",
            "Epoch 151/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.6981 - val_loss: 0.6979 - val_accuracy: 0.6833\n",
            "Epoch 152/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.6792 - val_loss: 0.7335 - val_accuracy: 0.6642\n",
            "Epoch 153/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.6939 - val_loss: 0.7011 - val_accuracy: 0.6900\n",
            "Epoch 154/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.6869 - val_loss: 0.7160 - val_accuracy: 0.6733\n",
            "Epoch 155/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7180 - accuracy: 0.6844 - val_loss: 0.7099 - val_accuracy: 0.6750\n",
            "Epoch 156/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.6886 - val_loss: 0.7191 - val_accuracy: 0.6892\n",
            "Epoch 157/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.6936 - val_loss: 0.7211 - val_accuracy: 0.6833\n",
            "Epoch 158/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.6994 - val_loss: 0.7271 - val_accuracy: 0.6758\n",
            "Epoch 159/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.6922 - val_loss: 0.7151 - val_accuracy: 0.6867\n",
            "Epoch 160/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7106 - accuracy: 0.6892 - val_loss: 0.7133 - val_accuracy: 0.6808\n",
            "Epoch 161/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.6842 - val_loss: 0.9677 - val_accuracy: 0.6142\n",
            "Epoch 162/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7034 - accuracy: 0.6872 - val_loss: 0.7169 - val_accuracy: 0.6808\n",
            "Epoch 163/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7105 - accuracy: 0.6903 - val_loss: 0.7392 - val_accuracy: 0.6617\n",
            "Epoch 164/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.6919 - val_loss: 0.8023 - val_accuracy: 0.6600\n",
            "Epoch 165/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7096 - accuracy: 0.6825 - val_loss: 0.7170 - val_accuracy: 0.6767\n",
            "Epoch 166/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.6844 - val_loss: 0.7235 - val_accuracy: 0.6700\n",
            "Epoch 167/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6860 - accuracy: 0.6892 - val_loss: 0.6933 - val_accuracy: 0.7008\n",
            "Epoch 168/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.6992 - val_loss: 0.7859 - val_accuracy: 0.6633\n",
            "Epoch 169/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7507 - accuracy: 0.6642 - val_loss: 0.7206 - val_accuracy: 0.6825\n",
            "Epoch 170/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.6908 - val_loss: 0.6916 - val_accuracy: 0.6950\n",
            "Epoch 171/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.6983 - val_loss: 0.7583 - val_accuracy: 0.6617\n",
            "Epoch 172/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.6944 - val_loss: 0.7695 - val_accuracy: 0.6600\n",
            "Epoch 173/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6970 - accuracy: 0.6942 - val_loss: 0.6976 - val_accuracy: 0.6800\n",
            "Epoch 174/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.7006 - val_loss: 0.7203 - val_accuracy: 0.6725\n",
            "Epoch 175/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.7028 - val_loss: 0.7277 - val_accuracy: 0.6733\n",
            "Epoch 176/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.6906 - val_loss: 0.7142 - val_accuracy: 0.6825\n",
            "Epoch 177/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.6864 - val_loss: 0.7611 - val_accuracy: 0.6608\n",
            "Epoch 178/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.6881 - val_loss: 0.7024 - val_accuracy: 0.6792\n",
            "Epoch 179/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.6942 - val_loss: 0.7032 - val_accuracy: 0.6875\n",
            "Epoch 180/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.6969 - val_loss: 0.7253 - val_accuracy: 0.6808\n",
            "Epoch 181/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.6894 - val_loss: 0.7889 - val_accuracy: 0.6550\n",
            "Epoch 182/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.6842 - val_loss: 0.7129 - val_accuracy: 0.6842\n",
            "Epoch 183/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.6906 - val_loss: 0.7361 - val_accuracy: 0.6775\n",
            "Epoch 184/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7022 - val_loss: 0.7569 - val_accuracy: 0.6633\n",
            "Epoch 185/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7047 - accuracy: 0.6839 - val_loss: 0.7126 - val_accuracy: 0.6892\n",
            "Epoch 186/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.6889 - val_loss: 0.6831 - val_accuracy: 0.7017\n",
            "Epoch 187/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.6936 - val_loss: 0.7181 - val_accuracy: 0.6917\n",
            "Epoch 188/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.6931 - val_loss: 0.7083 - val_accuracy: 0.6692\n",
            "Epoch 189/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.6878 - val_loss: 0.7273 - val_accuracy: 0.6842\n",
            "Epoch 190/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.6903 - val_loss: 0.7225 - val_accuracy: 0.6850\n",
            "Epoch 191/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7127 - accuracy: 0.6853 - val_loss: 0.8315 - val_accuracy: 0.6458\n",
            "Epoch 192/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.6889 - val_loss: 0.6956 - val_accuracy: 0.7017\n",
            "Epoch 193/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6903 - val_loss: 0.8227 - val_accuracy: 0.6450\n",
            "Epoch 194/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6944 - accuracy: 0.6889 - val_loss: 0.7111 - val_accuracy: 0.6908\n",
            "Epoch 195/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7039 - accuracy: 0.6828 - val_loss: 0.7147 - val_accuracy: 0.6883\n",
            "Epoch 196/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.6983 - val_loss: 0.7041 - val_accuracy: 0.6825\n",
            "Epoch 197/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.6964 - val_loss: 0.7013 - val_accuracy: 0.7025\n",
            "Epoch 198/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.6889 - val_loss: 0.7165 - val_accuracy: 0.6875\n",
            "Epoch 199/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.6967 - val_loss: 0.7205 - val_accuracy: 0.6883\n",
            "Epoch 200/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7068 - accuracy: 0.6822 - val_loss: 0.7011 - val_accuracy: 0.6992\n",
            "Epoch 201/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.7008 - val_loss: 0.7099 - val_accuracy: 0.6883\n",
            "Epoch 202/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6843 - accuracy: 0.6947 - val_loss: 0.7063 - val_accuracy: 0.6775\n",
            "Epoch 203/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.6986 - val_loss: 0.7084 - val_accuracy: 0.6900\n",
            "Epoch 204/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.6931 - val_loss: 0.6860 - val_accuracy: 0.7058\n",
            "Epoch 205/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.6981 - val_loss: 0.7690 - val_accuracy: 0.6750\n",
            "Epoch 206/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7016 - accuracy: 0.6889 - val_loss: 0.6965 - val_accuracy: 0.6942\n",
            "Epoch 207/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7001 - accuracy: 0.6886 - val_loss: 0.7464 - val_accuracy: 0.6700\n",
            "Epoch 208/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6764 - accuracy: 0.7006 - val_loss: 0.7150 - val_accuracy: 0.6933\n",
            "Epoch 209/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.6972 - val_loss: 0.7113 - val_accuracy: 0.6758\n",
            "Epoch 210/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.7022 - val_loss: 0.7379 - val_accuracy: 0.6717\n",
            "Epoch 211/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.6892 - val_loss: 0.7050 - val_accuracy: 0.6800\n",
            "Epoch 212/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.6831 - val_loss: 0.7279 - val_accuracy: 0.6833\n",
            "Epoch 213/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.6928 - val_loss: 0.7652 - val_accuracy: 0.6692\n",
            "Epoch 214/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.6881 - val_loss: 0.7229 - val_accuracy: 0.6850\n",
            "Epoch 215/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6753 - accuracy: 0.6972 - val_loss: 0.7105 - val_accuracy: 0.6992\n",
            "Epoch 216/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7082 - accuracy: 0.6839 - val_loss: 0.7050 - val_accuracy: 0.6875\n",
            "Epoch 217/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6971 - accuracy: 0.6872 - val_loss: 0.7333 - val_accuracy: 0.6700\n",
            "Epoch 218/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6998 - accuracy: 0.6961 - val_loss: 0.7181 - val_accuracy: 0.6842\n",
            "Epoch 219/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.7003 - val_loss: 0.7021 - val_accuracy: 0.6933\n",
            "Epoch 220/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.7031 - val_loss: 0.7399 - val_accuracy: 0.6767\n",
            "Epoch 221/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.6997 - val_loss: 0.7556 - val_accuracy: 0.6700\n",
            "Epoch 222/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.6953 - val_loss: 0.7063 - val_accuracy: 0.6733\n",
            "Epoch 223/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.6997 - val_loss: 0.6961 - val_accuracy: 0.7017\n",
            "Epoch 224/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.7014 - val_loss: 0.7253 - val_accuracy: 0.6667\n",
            "Epoch 225/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.6947 - val_loss: 0.7674 - val_accuracy: 0.6517\n",
            "Epoch 226/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7175 - accuracy: 0.6836 - val_loss: 0.7132 - val_accuracy: 0.6800\n",
            "Epoch 227/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7025 - accuracy: 0.6942 - val_loss: 0.6969 - val_accuracy: 0.6950\n",
            "Epoch 228/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.6994 - val_loss: 0.7542 - val_accuracy: 0.6708\n",
            "Epoch 229/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.6894 - val_loss: 0.7725 - val_accuracy: 0.6467\n",
            "Epoch 230/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.6833 - val_loss: 0.7032 - val_accuracy: 0.6875\n",
            "Epoch 231/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.6933 - val_loss: 0.7023 - val_accuracy: 0.6925\n",
            "Epoch 232/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6811 - accuracy: 0.6939 - val_loss: 0.7289 - val_accuracy: 0.6858\n",
            "Epoch 233/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.6928 - val_loss: 0.7643 - val_accuracy: 0.6575\n",
            "Epoch 234/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7000 - val_loss: 0.6980 - val_accuracy: 0.6892\n",
            "Epoch 235/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.6994 - val_loss: 0.7174 - val_accuracy: 0.6725\n",
            "Epoch 236/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.6989 - val_loss: 0.7456 - val_accuracy: 0.6717\n",
            "Epoch 237/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7168 - accuracy: 0.6808 - val_loss: 0.7150 - val_accuracy: 0.6792\n",
            "Epoch 238/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7234 - accuracy: 0.6836 - val_loss: 0.7298 - val_accuracy: 0.6825\n",
            "Epoch 239/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7310 - accuracy: 0.6825 - val_loss: 0.7403 - val_accuracy: 0.6833\n",
            "Epoch 240/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.7028 - val_loss: 0.7027 - val_accuracy: 0.6767\n",
            "Epoch 241/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.7067 - val_loss: 0.7194 - val_accuracy: 0.6908\n",
            "Epoch 242/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.7072 - val_loss: 0.7113 - val_accuracy: 0.6800\n",
            "Epoch 243/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7056 - val_loss: 0.6859 - val_accuracy: 0.7017\n",
            "Epoch 244/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.6983 - val_loss: 0.7355 - val_accuracy: 0.6792\n",
            "Epoch 245/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.6819 - val_loss: 0.7111 - val_accuracy: 0.6883\n",
            "Epoch 246/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.6858 - val_loss: 0.7403 - val_accuracy: 0.6658\n",
            "Epoch 247/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.6858 - val_loss: 0.6845 - val_accuracy: 0.7033\n",
            "Epoch 248/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.6944 - val_loss: 0.7984 - val_accuracy: 0.6425\n",
            "Epoch 249/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.6997 - val_loss: 0.7247 - val_accuracy: 0.6658\n",
            "Epoch 250/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.6950 - val_loss: 0.7442 - val_accuracy: 0.6767\n",
            "Epoch 251/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.6969 - val_loss: 0.6950 - val_accuracy: 0.6850\n",
            "Epoch 252/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.7008 - val_loss: 0.7074 - val_accuracy: 0.6900\n",
            "Epoch 253/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6991 - accuracy: 0.6931 - val_loss: 0.8294 - val_accuracy: 0.6350\n",
            "Epoch 254/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.6767 - val_loss: 0.6851 - val_accuracy: 0.7067\n",
            "Epoch 255/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7368 - accuracy: 0.6742 - val_loss: 0.7266 - val_accuracy: 0.6867\n",
            "Epoch 256/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.6858 - val_loss: 0.7433 - val_accuracy: 0.6800\n",
            "Epoch 257/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.6861 - val_loss: 0.8120 - val_accuracy: 0.6525\n",
            "Epoch 258/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6995 - accuracy: 0.6875 - val_loss: 0.7506 - val_accuracy: 0.6600\n",
            "Epoch 259/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.6828 - val_loss: 0.7063 - val_accuracy: 0.6983\n",
            "Epoch 260/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.6978 - val_loss: 0.6967 - val_accuracy: 0.6992\n",
            "Epoch 261/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.6928 - val_loss: 0.6937 - val_accuracy: 0.6858\n",
            "Epoch 262/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6836 - val_loss: 0.7388 - val_accuracy: 0.6842\n",
            "Epoch 263/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.6844 - val_loss: 0.7149 - val_accuracy: 0.6750\n",
            "Epoch 264/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6909 - accuracy: 0.6942 - val_loss: 0.6943 - val_accuracy: 0.6858\n",
            "Epoch 265/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.6922 - val_loss: 0.7481 - val_accuracy: 0.6725\n",
            "Epoch 266/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.6911 - val_loss: 0.7010 - val_accuracy: 0.6933\n",
            "Epoch 267/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.7011 - val_loss: 0.7203 - val_accuracy: 0.6692\n",
            "Epoch 268/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6974 - accuracy: 0.6922 - val_loss: 0.6914 - val_accuracy: 0.6992\n",
            "Epoch 269/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.6961 - val_loss: 0.6992 - val_accuracy: 0.6900\n",
            "Epoch 270/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.7053 - val_loss: 0.7053 - val_accuracy: 0.6758\n",
            "Epoch 271/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.6953 - val_loss: 0.7082 - val_accuracy: 0.6833\n",
            "Epoch 272/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.6881 - val_loss: 0.7208 - val_accuracy: 0.6708\n",
            "Epoch 273/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.7003 - val_loss: 0.7427 - val_accuracy: 0.6692\n",
            "Epoch 274/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.6969 - val_loss: 0.6979 - val_accuracy: 0.6950\n",
            "Epoch 275/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6875 - accuracy: 0.6942 - val_loss: 0.7093 - val_accuracy: 0.6900\n",
            "Epoch 276/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6844 - accuracy: 0.6933 - val_loss: 0.7006 - val_accuracy: 0.6992\n",
            "Epoch 277/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.7017 - val_loss: 0.6988 - val_accuracy: 0.6783\n",
            "Epoch 278/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.6961 - val_loss: 0.7040 - val_accuracy: 0.6792\n",
            "Epoch 279/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7008 - val_loss: 0.7239 - val_accuracy: 0.6792\n",
            "Epoch 280/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.6989 - val_loss: 0.7067 - val_accuracy: 0.6842\n",
            "Epoch 281/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.6944 - val_loss: 0.7194 - val_accuracy: 0.6933\n",
            "Epoch 282/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.7006 - val_loss: 0.7016 - val_accuracy: 0.6808\n",
            "Epoch 283/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.6956 - val_loss: 0.7099 - val_accuracy: 0.6800\n",
            "Epoch 284/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6914 - accuracy: 0.6958 - val_loss: 0.7021 - val_accuracy: 0.7017\n",
            "Epoch 285/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.6986 - val_loss: 0.7200 - val_accuracy: 0.6817\n",
            "Epoch 286/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.6931 - val_loss: 0.7723 - val_accuracy: 0.6450\n",
            "Epoch 287/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6883 - accuracy: 0.6931 - val_loss: 0.6874 - val_accuracy: 0.6933\n",
            "Epoch 288/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.6956 - val_loss: 0.6843 - val_accuracy: 0.6950\n",
            "Epoch 289/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.6833 - val_loss: 0.7108 - val_accuracy: 0.6900\n",
            "Epoch 290/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7342 - accuracy: 0.6806 - val_loss: 0.7287 - val_accuracy: 0.6750\n",
            "Epoch 291/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7010 - accuracy: 0.6906 - val_loss: 0.7470 - val_accuracy: 0.6542\n",
            "Epoch 292/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.6911 - val_loss: 0.7221 - val_accuracy: 0.6767\n",
            "Epoch 293/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.6869 - val_loss: 0.7171 - val_accuracy: 0.6717\n",
            "Epoch 294/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.6958 - val_loss: 0.7174 - val_accuracy: 0.6817\n",
            "Epoch 295/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6847 - accuracy: 0.6981 - val_loss: 0.7029 - val_accuracy: 0.6900\n",
            "Epoch 296/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.6972 - val_loss: 0.7839 - val_accuracy: 0.6617\n",
            "Epoch 297/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.6947 - val_loss: 0.7234 - val_accuracy: 0.6783\n",
            "Epoch 298/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.6958 - val_loss: 0.6939 - val_accuracy: 0.6925\n",
            "Epoch 299/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6977 - accuracy: 0.6881 - val_loss: 0.7023 - val_accuracy: 0.6875\n",
            "Epoch 300/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.7006 - val_loss: 0.7043 - val_accuracy: 0.6858\n",
            "Epoch 301/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.6992 - val_loss: 0.7319 - val_accuracy: 0.6775\n",
            "Epoch 302/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7068 - accuracy: 0.6808 - val_loss: 0.6942 - val_accuracy: 0.6842\n",
            "Epoch 303/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.6950 - val_loss: 0.6969 - val_accuracy: 0.6892\n",
            "Epoch 304/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.6983 - val_loss: 0.7144 - val_accuracy: 0.6808\n",
            "Epoch 305/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.6981 - val_loss: 0.7639 - val_accuracy: 0.6683\n",
            "Epoch 306/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.7006 - val_loss: 0.6882 - val_accuracy: 0.6942\n",
            "Epoch 307/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.6944 - val_loss: 0.7349 - val_accuracy: 0.6833\n",
            "Epoch 308/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6956 - accuracy: 0.6897 - val_loss: 0.7161 - val_accuracy: 0.6767\n",
            "Epoch 309/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.6917 - val_loss: 0.6879 - val_accuracy: 0.6900\n",
            "Epoch 310/1000\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 0.6876 - accuracy: 0.6975 - val_loss: 0.7240 - val_accuracy: 0.6808\n",
            "Epoch 311/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.6947 - val_loss: 0.7346 - val_accuracy: 0.6825\n",
            "Epoch 312/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6926 - accuracy: 0.6928 - val_loss: 0.6887 - val_accuracy: 0.6942\n",
            "Epoch 313/1000\n",
            "72/72 [==============================] - 1s 10ms/step - loss: 0.6893 - accuracy: 0.6986 - val_loss: 0.7321 - val_accuracy: 0.6642\n",
            "Epoch 314/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.6911 - val_loss: 0.7336 - val_accuracy: 0.6767\n",
            "Epoch 315/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.6807 - accuracy: 0.6961 - val_loss: 0.6946 - val_accuracy: 0.6958\n",
            "Epoch 316/1000\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.6975 - val_loss: 0.7410 - val_accuracy: 0.6642\n",
            "Epoch 317/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6836 - accuracy: 0.6983 - val_loss: 0.7280 - val_accuracy: 0.6783\n",
            "Epoch 318/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7070 - accuracy: 0.6853 - val_loss: 0.7133 - val_accuracy: 0.6975\n",
            "Epoch 319/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.6928 - val_loss: 0.7345 - val_accuracy: 0.6692\n",
            "Epoch 320/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.6942 - val_loss: 0.7816 - val_accuracy: 0.6717\n",
            "Epoch 321/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6738 - accuracy: 0.7006 - val_loss: 0.7767 - val_accuracy: 0.6667\n",
            "Epoch 322/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.7036 - val_loss: 0.7158 - val_accuracy: 0.6858\n",
            "Epoch 323/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.6933 - val_loss: 0.7184 - val_accuracy: 0.6717\n",
            "Epoch 324/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.6989 - val_loss: 0.6803 - val_accuracy: 0.6925\n",
            "Epoch 325/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.6781 - val_loss: 0.7172 - val_accuracy: 0.6808\n",
            "Epoch 326/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.7014 - val_loss: 0.7160 - val_accuracy: 0.6850\n",
            "Epoch 327/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.7025 - val_loss: 0.7121 - val_accuracy: 0.6808\n",
            "Epoch 328/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.6878 - val_loss: 0.7596 - val_accuracy: 0.6725\n",
            "Epoch 329/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.6956 - val_loss: 0.6991 - val_accuracy: 0.6767\n",
            "Epoch 330/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.6994 - val_loss: 0.7536 - val_accuracy: 0.6800\n",
            "Epoch 331/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.6964 - val_loss: 0.7070 - val_accuracy: 0.6867\n",
            "Epoch 332/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6823 - accuracy: 0.6978 - val_loss: 0.7116 - val_accuracy: 0.6892\n",
            "Epoch 333/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.6911 - val_loss: 0.7024 - val_accuracy: 0.6933\n",
            "Epoch 334/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.7031 - val_loss: 0.6794 - val_accuracy: 0.7042\n",
            "Epoch 335/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.7000 - val_loss: 0.7202 - val_accuracy: 0.6875\n",
            "Epoch 336/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.6997 - val_loss: 0.7319 - val_accuracy: 0.6625\n",
            "Epoch 337/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.6964 - val_loss: 0.7214 - val_accuracy: 0.6767\n",
            "Epoch 338/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6942 - val_loss: 0.7174 - val_accuracy: 0.6883\n",
            "Epoch 339/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7014 - val_loss: 0.7001 - val_accuracy: 0.6908\n",
            "Epoch 340/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.7006 - val_loss: 0.7307 - val_accuracy: 0.6658\n",
            "Epoch 341/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.6983 - val_loss: 0.7063 - val_accuracy: 0.6858\n",
            "Epoch 342/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.6908 - val_loss: 0.7205 - val_accuracy: 0.6775\n",
            "Epoch 343/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.6972 - val_loss: 0.7040 - val_accuracy: 0.6758\n",
            "Epoch 344/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6769 - accuracy: 0.7036 - val_loss: 0.7596 - val_accuracy: 0.6592\n",
            "Epoch 345/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.6953 - val_loss: 0.7605 - val_accuracy: 0.6600\n",
            "Epoch 346/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.6917 - val_loss: 0.7053 - val_accuracy: 0.6858\n",
            "Epoch 347/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.7003 - val_loss: 0.7557 - val_accuracy: 0.6775\n",
            "Epoch 348/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.7072 - val_loss: 0.6845 - val_accuracy: 0.6875\n",
            "Epoch 349/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.6997 - val_loss: 0.7179 - val_accuracy: 0.6792\n",
            "Epoch 350/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.6967 - val_loss: 0.6854 - val_accuracy: 0.6967\n",
            "Epoch 351/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.7028 - val_loss: 0.7033 - val_accuracy: 0.6692\n",
            "Epoch 352/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6693 - accuracy: 0.7064 - val_loss: 0.7042 - val_accuracy: 0.6808\n",
            "Epoch 353/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6815 - accuracy: 0.6994 - val_loss: 0.7097 - val_accuracy: 0.6975\n",
            "Epoch 354/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.6969 - val_loss: 0.6878 - val_accuracy: 0.6933\n",
            "Epoch 355/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.6947 - val_loss: 0.7098 - val_accuracy: 0.6842\n",
            "Epoch 356/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6791 - accuracy: 0.7011 - val_loss: 0.7073 - val_accuracy: 0.6875\n",
            "Epoch 357/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.6961 - val_loss: 0.6942 - val_accuracy: 0.6850\n",
            "Epoch 358/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.6906 - val_loss: 0.7197 - val_accuracy: 0.6817\n",
            "Epoch 359/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7140 - accuracy: 0.6850 - val_loss: 0.6871 - val_accuracy: 0.6992\n",
            "Epoch 360/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7019 - val_loss: 0.7070 - val_accuracy: 0.6892\n",
            "Epoch 361/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.6967 - val_loss: 0.7849 - val_accuracy: 0.6533\n",
            "Epoch 362/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.6983 - val_loss: 0.7228 - val_accuracy: 0.6833\n",
            "Epoch 363/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.6908 - val_loss: 0.7147 - val_accuracy: 0.6800\n",
            "Epoch 364/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.6961 - val_loss: 0.7441 - val_accuracy: 0.6750\n",
            "Epoch 365/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7324 - accuracy: 0.6828 - val_loss: 0.7565 - val_accuracy: 0.6567\n",
            "Epoch 366/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.6992 - val_loss: 0.7150 - val_accuracy: 0.6883\n",
            "Epoch 367/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6652 - accuracy: 0.7078 - val_loss: 0.6875 - val_accuracy: 0.6908\n",
            "Epoch 368/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.7006 - val_loss: 0.6994 - val_accuracy: 0.6858\n",
            "Epoch 369/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7014 - val_loss: 0.7059 - val_accuracy: 0.6867\n",
            "Epoch 370/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.6947 - val_loss: 0.7095 - val_accuracy: 0.6875\n",
            "Epoch 371/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.7039 - val_loss: 0.7048 - val_accuracy: 0.6883\n",
            "Epoch 372/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.6939 - val_loss: 0.7216 - val_accuracy: 0.6858\n",
            "Epoch 373/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.6969 - val_loss: 0.6832 - val_accuracy: 0.7042\n",
            "Epoch 374/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.6992 - val_loss: 0.6983 - val_accuracy: 0.6933\n",
            "Epoch 375/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.7017 - val_loss: 0.7090 - val_accuracy: 0.6725\n",
            "Epoch 376/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.7050 - val_loss: 0.7253 - val_accuracy: 0.6758\n",
            "Epoch 377/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6999 - accuracy: 0.6942 - val_loss: 0.6923 - val_accuracy: 0.6925\n",
            "Epoch 378/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6654 - accuracy: 0.7075 - val_loss: 0.7099 - val_accuracy: 0.6875\n",
            "Epoch 379/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6762 - accuracy: 0.6992 - val_loss: 0.7469 - val_accuracy: 0.6642\n",
            "Epoch 380/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.6908 - val_loss: 0.6773 - val_accuracy: 0.7067\n",
            "Epoch 381/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.6964 - val_loss: 0.7036 - val_accuracy: 0.6783\n",
            "Epoch 382/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6768 - accuracy: 0.6969 - val_loss: 0.7146 - val_accuracy: 0.6800\n",
            "Epoch 383/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.6928 - val_loss: 0.6743 - val_accuracy: 0.7058\n",
            "Epoch 384/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.6908 - val_loss: 0.6887 - val_accuracy: 0.6958\n",
            "Epoch 385/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.6936 - val_loss: 0.6954 - val_accuracy: 0.6908\n",
            "Epoch 386/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.6911 - val_loss: 0.7763 - val_accuracy: 0.6492\n",
            "Epoch 387/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.6972 - val_loss: 0.6972 - val_accuracy: 0.6858\n",
            "Epoch 388/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6820 - accuracy: 0.7006 - val_loss: 0.6906 - val_accuracy: 0.6958\n",
            "Epoch 389/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.7072 - val_loss: 0.7070 - val_accuracy: 0.6875\n",
            "Epoch 390/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.6964 - val_loss: 0.7272 - val_accuracy: 0.6825\n",
            "Epoch 391/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6870 - accuracy: 0.6911 - val_loss: 0.8095 - val_accuracy: 0.6242\n",
            "Epoch 392/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.6900 - val_loss: 0.7228 - val_accuracy: 0.6783\n",
            "Epoch 393/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.6978 - val_loss: 0.8012 - val_accuracy: 0.6625\n",
            "Epoch 394/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.6811 - val_loss: 0.6892 - val_accuracy: 0.6908\n",
            "Epoch 395/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.7028 - val_loss: 0.7077 - val_accuracy: 0.6733\n",
            "Epoch 396/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.6986 - val_loss: 0.7045 - val_accuracy: 0.6833\n",
            "Epoch 397/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7034 - accuracy: 0.6894 - val_loss: 0.8518 - val_accuracy: 0.6267\n",
            "Epoch 398/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.6972 - val_loss: 0.6773 - val_accuracy: 0.6900\n",
            "Epoch 399/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.6972 - val_loss: 0.6975 - val_accuracy: 0.6925\n",
            "Epoch 400/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.7053 - val_loss: 0.6993 - val_accuracy: 0.6858\n",
            "Epoch 401/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.7069 - val_loss: 0.7199 - val_accuracy: 0.6767\n",
            "Epoch 402/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6966 - accuracy: 0.6819 - val_loss: 0.6977 - val_accuracy: 0.6867\n",
            "Epoch 403/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.6958 - val_loss: 0.7394 - val_accuracy: 0.6633\n",
            "Epoch 404/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6875 - accuracy: 0.7031 - val_loss: 0.7005 - val_accuracy: 0.6950\n",
            "Epoch 405/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6804 - accuracy: 0.7061 - val_loss: 0.7065 - val_accuracy: 0.6808\n",
            "Epoch 406/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.7086 - val_loss: 0.6889 - val_accuracy: 0.6892\n",
            "Epoch 407/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6688 - accuracy: 0.7008 - val_loss: 0.6939 - val_accuracy: 0.6867\n",
            "Epoch 408/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6810 - accuracy: 0.6919 - val_loss: 0.6983 - val_accuracy: 0.6908\n",
            "Epoch 409/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.7033 - val_loss: 0.7752 - val_accuracy: 0.6608\n",
            "Epoch 410/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.6944 - val_loss: 0.7695 - val_accuracy: 0.6550\n",
            "Epoch 411/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.6994 - val_loss: 0.6983 - val_accuracy: 0.6950\n",
            "Epoch 412/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.7031 - val_loss: 0.6838 - val_accuracy: 0.6925\n",
            "Epoch 413/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7003 - val_loss: 0.6964 - val_accuracy: 0.6925\n",
            "Epoch 414/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.7019 - val_loss: 0.6950 - val_accuracy: 0.6983\n",
            "Epoch 415/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.6994 - val_loss: 0.6937 - val_accuracy: 0.6900\n",
            "Epoch 416/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7058 - val_loss: 0.7572 - val_accuracy: 0.6733\n",
            "Epoch 417/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.7036 - val_loss: 0.7264 - val_accuracy: 0.6725\n",
            "Epoch 418/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.6997 - val_loss: 0.7037 - val_accuracy: 0.6825\n",
            "Epoch 419/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7119 - accuracy: 0.6778 - val_loss: 0.6959 - val_accuracy: 0.6925\n",
            "Epoch 420/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.7003 - val_loss: 0.7188 - val_accuracy: 0.6908\n",
            "Epoch 421/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.6956 - val_loss: 0.6930 - val_accuracy: 0.6942\n",
            "Epoch 422/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.7014 - val_loss: 0.6998 - val_accuracy: 0.6825\n",
            "Epoch 423/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.7114 - val_loss: 0.6960 - val_accuracy: 0.6800\n",
            "Epoch 424/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.7044 - val_loss: 0.7003 - val_accuracy: 0.6867\n",
            "Epoch 425/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.6908 - val_loss: 0.7308 - val_accuracy: 0.6958\n",
            "Epoch 426/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7008 - val_loss: 0.7184 - val_accuracy: 0.6825\n",
            "Epoch 427/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.6936 - val_loss: 0.7323 - val_accuracy: 0.6825\n",
            "Epoch 428/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.6964 - val_loss: 0.6968 - val_accuracy: 0.6967\n",
            "Epoch 429/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7075 - val_loss: 0.7061 - val_accuracy: 0.6808\n",
            "Epoch 430/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6705 - accuracy: 0.7011 - val_loss: 0.6833 - val_accuracy: 0.7058\n",
            "Epoch 431/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7083 - val_loss: 0.7005 - val_accuracy: 0.6775\n",
            "Epoch 432/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7113 - accuracy: 0.6872 - val_loss: 0.6858 - val_accuracy: 0.6933\n",
            "Epoch 433/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6797 - accuracy: 0.7025 - val_loss: 0.7376 - val_accuracy: 0.6725\n",
            "Epoch 434/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.6958 - val_loss: 0.6882 - val_accuracy: 0.6942\n",
            "Epoch 435/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.6969 - val_loss: 0.6936 - val_accuracy: 0.6858\n",
            "Epoch 436/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.7017 - val_loss: 0.7110 - val_accuracy: 0.6917\n",
            "Epoch 437/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6944 - accuracy: 0.6894 - val_loss: 0.6961 - val_accuracy: 0.6958\n",
            "Epoch 438/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.7075 - val_loss: 0.7342 - val_accuracy: 0.6783\n",
            "Epoch 439/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7100 - val_loss: 0.6812 - val_accuracy: 0.6933\n",
            "Epoch 440/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7025 - val_loss: 0.7053 - val_accuracy: 0.6917\n",
            "Epoch 441/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.6939 - val_loss: 0.7001 - val_accuracy: 0.6950\n",
            "Epoch 442/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.6967 - val_loss: 0.6893 - val_accuracy: 0.6975\n",
            "Epoch 443/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.6983 - val_loss: 0.8347 - val_accuracy: 0.6442\n",
            "Epoch 444/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.7008 - val_loss: 0.7084 - val_accuracy: 0.6875\n",
            "Epoch 445/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6836 - accuracy: 0.6931 - val_loss: 0.7140 - val_accuracy: 0.6833\n",
            "Epoch 446/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.6856 - val_loss: 0.7012 - val_accuracy: 0.6975\n",
            "Epoch 447/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6781 - accuracy: 0.6983 - val_loss: 0.6817 - val_accuracy: 0.7058\n",
            "Epoch 448/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.6944 - val_loss: 0.7043 - val_accuracy: 0.6817\n",
            "Epoch 449/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.6967 - val_loss: 0.6841 - val_accuracy: 0.6933\n",
            "Epoch 450/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.7064 - val_loss: 0.7237 - val_accuracy: 0.6808\n",
            "Epoch 451/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6747 - accuracy: 0.7028 - val_loss: 0.7327 - val_accuracy: 0.6767\n",
            "Epoch 452/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.6994 - val_loss: 0.7242 - val_accuracy: 0.6858\n",
            "Epoch 453/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.6911 - val_loss: 0.7110 - val_accuracy: 0.6950\n",
            "Epoch 454/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.7033 - val_loss: 0.6922 - val_accuracy: 0.6925\n",
            "Epoch 455/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.7006 - val_loss: 0.7593 - val_accuracy: 0.6775\n",
            "Epoch 456/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.6972 - val_loss: 0.7109 - val_accuracy: 0.6825\n",
            "Epoch 457/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.7011 - val_loss: 0.7179 - val_accuracy: 0.6733\n",
            "Epoch 458/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.6972 - val_loss: 0.7267 - val_accuracy: 0.6717\n",
            "Epoch 459/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.7039 - val_loss: 0.7097 - val_accuracy: 0.6958\n",
            "Epoch 460/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6735 - accuracy: 0.7025 - val_loss: 0.6869 - val_accuracy: 0.6933\n",
            "Epoch 461/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6753 - accuracy: 0.7011 - val_loss: 0.7027 - val_accuracy: 0.6875\n",
            "Epoch 462/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7019 - val_loss: 0.7008 - val_accuracy: 0.6842\n",
            "Epoch 463/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.6969 - val_loss: 0.7070 - val_accuracy: 0.6933\n",
            "Epoch 464/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.6956 - val_loss: 0.7256 - val_accuracy: 0.6925\n",
            "Epoch 465/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6982 - accuracy: 0.6933 - val_loss: 0.7192 - val_accuracy: 0.6725\n",
            "Epoch 466/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.7017 - val_loss: 0.6844 - val_accuracy: 0.6875\n",
            "Epoch 467/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7039 - val_loss: 0.6869 - val_accuracy: 0.7000\n",
            "Epoch 468/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.7086 - val_loss: 0.7141 - val_accuracy: 0.6758\n",
            "Epoch 469/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.6958 - val_loss: 0.6964 - val_accuracy: 0.6983\n",
            "Epoch 470/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7085 - accuracy: 0.6797 - val_loss: 0.7202 - val_accuracy: 0.6775\n",
            "Epoch 471/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7008 - val_loss: 0.6942 - val_accuracy: 0.6875\n",
            "Epoch 472/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.6961 - val_loss: 0.6968 - val_accuracy: 0.6900\n",
            "Epoch 473/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.7106 - val_loss: 0.6900 - val_accuracy: 0.6967\n",
            "Epoch 474/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7188 - accuracy: 0.6828 - val_loss: 0.7043 - val_accuracy: 0.6867\n",
            "Epoch 475/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6690 - accuracy: 0.7061 - val_loss: 0.6932 - val_accuracy: 0.6992\n",
            "Epoch 476/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7028 - val_loss: 0.7010 - val_accuracy: 0.7025\n",
            "Epoch 477/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6760 - accuracy: 0.7047 - val_loss: 0.6978 - val_accuracy: 0.6825\n",
            "Epoch 478/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7078 - val_loss: 0.7022 - val_accuracy: 0.6892\n",
            "Epoch 479/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.7058 - val_loss: 0.7131 - val_accuracy: 0.6942\n",
            "Epoch 480/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.6972 - val_loss: 0.6918 - val_accuracy: 0.7017\n",
            "Epoch 481/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.7128 - val_loss: 0.6983 - val_accuracy: 0.6908\n",
            "Epoch 482/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.7053 - val_loss: 0.7125 - val_accuracy: 0.6867\n",
            "Epoch 483/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6833 - accuracy: 0.6956 - val_loss: 0.6811 - val_accuracy: 0.6983\n",
            "Epoch 484/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6706 - accuracy: 0.6994 - val_loss: 0.6999 - val_accuracy: 0.6925\n",
            "Epoch 485/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.7047 - val_loss: 0.6994 - val_accuracy: 0.6908\n",
            "Epoch 486/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.7044 - val_loss: 0.6889 - val_accuracy: 0.7017\n",
            "Epoch 487/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.7117 - val_loss: 0.7242 - val_accuracy: 0.6708\n",
            "Epoch 488/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.6989 - val_loss: 0.6923 - val_accuracy: 0.6867\n",
            "Epoch 489/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6739 - accuracy: 0.7011 - val_loss: 0.7210 - val_accuracy: 0.6750\n",
            "Epoch 490/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6740 - accuracy: 0.7031 - val_loss: 0.7372 - val_accuracy: 0.6667\n",
            "Epoch 491/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.6983 - val_loss: 0.7129 - val_accuracy: 0.6825\n",
            "Epoch 492/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.7061 - val_loss: 0.6931 - val_accuracy: 0.6825\n",
            "Epoch 493/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.6989 - val_loss: 0.7708 - val_accuracy: 0.6650\n",
            "Epoch 494/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6740 - accuracy: 0.6978 - val_loss: 0.6899 - val_accuracy: 0.6992\n",
            "Epoch 495/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.7031 - val_loss: 0.7475 - val_accuracy: 0.6700\n",
            "Epoch 496/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6685 - accuracy: 0.7039 - val_loss: 0.7108 - val_accuracy: 0.6825\n",
            "Epoch 497/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.7075 - val_loss: 0.6965 - val_accuracy: 0.6983\n",
            "Epoch 498/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.6983 - val_loss: 0.6916 - val_accuracy: 0.6958\n",
            "Epoch 499/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.6986 - val_loss: 0.7279 - val_accuracy: 0.6783\n",
            "Epoch 500/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.6981 - val_loss: 0.6915 - val_accuracy: 0.6942\n",
            "Epoch 501/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.7111 - val_loss: 0.7254 - val_accuracy: 0.6717\n",
            "Epoch 502/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7003 - accuracy: 0.6844 - val_loss: 0.7278 - val_accuracy: 0.6708\n",
            "Epoch 503/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6812 - accuracy: 0.7042 - val_loss: 0.7113 - val_accuracy: 0.6833\n",
            "Epoch 504/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6874 - accuracy: 0.6975 - val_loss: 0.6883 - val_accuracy: 0.6917\n",
            "Epoch 505/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.7078 - val_loss: 0.7017 - val_accuracy: 0.6758\n",
            "Epoch 506/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.6958 - val_loss: 0.6975 - val_accuracy: 0.6750\n",
            "Epoch 507/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.7119 - val_loss: 0.6878 - val_accuracy: 0.6892\n",
            "Epoch 508/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.6975 - val_loss: 0.7526 - val_accuracy: 0.6592\n",
            "Epoch 509/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.7033 - val_loss: 0.7311 - val_accuracy: 0.6625\n",
            "Epoch 510/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.6972 - val_loss: 0.7174 - val_accuracy: 0.6808\n",
            "Epoch 511/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7020 - accuracy: 0.6911 - val_loss: 0.6998 - val_accuracy: 0.7017\n",
            "Epoch 512/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7011 - val_loss: 0.6867 - val_accuracy: 0.7100\n",
            "Epoch 513/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.6939 - val_loss: 0.6814 - val_accuracy: 0.7017\n",
            "Epoch 514/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.6975 - val_loss: 0.7008 - val_accuracy: 0.6942\n",
            "Epoch 515/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7017 - val_loss: 0.6976 - val_accuracy: 0.6942\n",
            "Epoch 516/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7056 - val_loss: 0.6846 - val_accuracy: 0.6975\n",
            "Epoch 517/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7008 - val_loss: 0.6871 - val_accuracy: 0.7000\n",
            "Epoch 518/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.7100 - val_loss: 0.6939 - val_accuracy: 0.6917\n",
            "Epoch 519/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.6997 - val_loss: 0.7099 - val_accuracy: 0.6875\n",
            "Epoch 520/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.6953 - val_loss: 0.7574 - val_accuracy: 0.6700\n",
            "Epoch 521/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.6933 - val_loss: 0.6792 - val_accuracy: 0.6967\n",
            "Epoch 522/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.6961 - val_loss: 0.7200 - val_accuracy: 0.6875\n",
            "Epoch 523/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.6997 - val_loss: 0.7084 - val_accuracy: 0.6917\n",
            "Epoch 524/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.7003 - val_loss: 0.8355 - val_accuracy: 0.6375\n",
            "Epoch 525/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.6964 - val_loss: 0.6753 - val_accuracy: 0.6925\n",
            "Epoch 526/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.7003 - val_loss: 0.7226 - val_accuracy: 0.6892\n",
            "Epoch 527/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.7081 - val_loss: 0.6844 - val_accuracy: 0.7042\n",
            "Epoch 528/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6764 - accuracy: 0.7006 - val_loss: 0.6794 - val_accuracy: 0.7042\n",
            "Epoch 529/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.6964 - val_loss: 0.7432 - val_accuracy: 0.6617\n",
            "Epoch 530/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.6986 - val_loss: 0.6989 - val_accuracy: 0.6875\n",
            "Epoch 531/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.7011 - val_loss: 0.7064 - val_accuracy: 0.6908\n",
            "Epoch 532/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6771 - accuracy: 0.7033 - val_loss: 0.6928 - val_accuracy: 0.6833\n",
            "Epoch 533/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.7058 - val_loss: 0.6930 - val_accuracy: 0.6925\n",
            "Epoch 534/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.6978 - val_loss: 0.7212 - val_accuracy: 0.6708\n",
            "Epoch 535/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7053 - val_loss: 0.7294 - val_accuracy: 0.6633\n",
            "Epoch 536/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6880 - accuracy: 0.6978 - val_loss: 0.7149 - val_accuracy: 0.6700\n",
            "Epoch 537/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.7092 - val_loss: 0.7357 - val_accuracy: 0.6692\n",
            "Epoch 538/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.7033 - val_loss: 0.7126 - val_accuracy: 0.6725\n",
            "Epoch 539/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6702 - accuracy: 0.7031 - val_loss: 0.6955 - val_accuracy: 0.6875\n",
            "Epoch 540/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6725 - accuracy: 0.7042 - val_loss: 0.7218 - val_accuracy: 0.6783\n",
            "Epoch 541/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.7083 - val_loss: 0.7488 - val_accuracy: 0.6800\n",
            "Epoch 542/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.7014 - val_loss: 0.6916 - val_accuracy: 0.6925\n",
            "Epoch 543/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.7025 - val_loss: 0.6869 - val_accuracy: 0.6917\n",
            "Epoch 544/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6782 - accuracy: 0.6903 - val_loss: 0.6853 - val_accuracy: 0.7050\n",
            "Epoch 545/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.6906 - val_loss: 0.7819 - val_accuracy: 0.6700\n",
            "Epoch 546/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7177 - accuracy: 0.6886 - val_loss: 0.6828 - val_accuracy: 0.7050\n",
            "Epoch 547/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.7047 - val_loss: 0.7154 - val_accuracy: 0.6825\n",
            "Epoch 548/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.6967 - val_loss: 0.7086 - val_accuracy: 0.6817\n",
            "Epoch 549/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.7003 - val_loss: 0.7028 - val_accuracy: 0.6875\n",
            "Epoch 550/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7014 - val_loss: 0.6998 - val_accuracy: 0.6792\n",
            "Epoch 551/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.7031 - val_loss: 0.6848 - val_accuracy: 0.6908\n",
            "Epoch 552/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.6969 - val_loss: 0.6829 - val_accuracy: 0.6992\n",
            "Epoch 553/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.6986 - val_loss: 0.6891 - val_accuracy: 0.6917\n",
            "Epoch 554/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7028 - val_loss: 0.7133 - val_accuracy: 0.6683\n",
            "Epoch 555/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.6964 - val_loss: 0.6864 - val_accuracy: 0.6917\n",
            "Epoch 556/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.7111 - val_loss: 0.6998 - val_accuracy: 0.6950\n",
            "Epoch 557/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6700 - accuracy: 0.7067 - val_loss: 0.7225 - val_accuracy: 0.6733\n",
            "Epoch 558/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.6928 - val_loss: 0.7013 - val_accuracy: 0.6825\n",
            "Epoch 559/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.7069 - val_loss: 0.7183 - val_accuracy: 0.6750\n",
            "Epoch 560/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.6875 - val_loss: 0.7191 - val_accuracy: 0.6717\n",
            "Epoch 561/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.7064 - val_loss: 0.7022 - val_accuracy: 0.6883\n",
            "Epoch 562/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.7056 - val_loss: 0.6876 - val_accuracy: 0.6833\n",
            "Epoch 563/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.7072 - val_loss: 0.7375 - val_accuracy: 0.6625\n",
            "Epoch 564/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7006 - val_loss: 0.6944 - val_accuracy: 0.6892\n",
            "Epoch 565/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.7075 - val_loss: 0.7010 - val_accuracy: 0.6842\n",
            "Epoch 566/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.7031 - val_loss: 0.6793 - val_accuracy: 0.7000\n",
            "Epoch 567/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7136 - accuracy: 0.6914 - val_loss: 0.7072 - val_accuracy: 0.6808\n",
            "Epoch 568/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.7072 - val_loss: 0.7242 - val_accuracy: 0.6800\n",
            "Epoch 569/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.6961 - val_loss: 0.6762 - val_accuracy: 0.7000\n",
            "Epoch 570/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6936 - val_loss: 0.7179 - val_accuracy: 0.6767\n",
            "Epoch 571/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.6961 - val_loss: 0.7090 - val_accuracy: 0.7025\n",
            "Epoch 572/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7067 - val_loss: 0.6692 - val_accuracy: 0.7083\n",
            "Epoch 573/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.7061 - val_loss: 0.6832 - val_accuracy: 0.7008\n",
            "Epoch 574/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6638 - accuracy: 0.7092 - val_loss: 0.6788 - val_accuracy: 0.7100\n",
            "Epoch 575/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.7000 - val_loss: 0.6916 - val_accuracy: 0.6817\n",
            "Epoch 576/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.7047 - val_loss: 0.6842 - val_accuracy: 0.7008\n",
            "Epoch 577/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.6994 - val_loss: 0.7120 - val_accuracy: 0.6608\n",
            "Epoch 578/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6870 - accuracy: 0.6983 - val_loss: 0.7322 - val_accuracy: 0.6792\n",
            "Epoch 579/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.6972 - val_loss: 0.7240 - val_accuracy: 0.6708\n",
            "Epoch 580/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.7003 - val_loss: 0.7095 - val_accuracy: 0.6858\n",
            "Epoch 581/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.6944 - val_loss: 0.6978 - val_accuracy: 0.6892\n",
            "Epoch 582/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.7078 - val_loss: 0.7061 - val_accuracy: 0.6883\n",
            "Epoch 583/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.7131 - val_loss: 0.7678 - val_accuracy: 0.6617\n",
            "Epoch 584/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.6975 - val_loss: 0.6953 - val_accuracy: 0.6883\n",
            "Epoch 585/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.7106 - val_loss: 0.6958 - val_accuracy: 0.6967\n",
            "Epoch 586/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6690 - accuracy: 0.6972 - val_loss: 0.7189 - val_accuracy: 0.6750\n",
            "Epoch 587/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.7067 - val_loss: 0.7001 - val_accuracy: 0.6842\n",
            "Epoch 588/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.6878 - val_loss: 0.6885 - val_accuracy: 0.6850\n",
            "Epoch 589/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6623 - accuracy: 0.7050 - val_loss: 0.7036 - val_accuracy: 0.6850\n",
            "Epoch 590/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.6961 - val_loss: 0.6968 - val_accuracy: 0.6825\n",
            "Epoch 591/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6694 - accuracy: 0.7008 - val_loss: 0.7015 - val_accuracy: 0.6883\n",
            "Epoch 592/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.7056 - val_loss: 0.7122 - val_accuracy: 0.6825\n",
            "Epoch 593/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.6997 - val_loss: 0.7206 - val_accuracy: 0.6908\n",
            "Epoch 594/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.7011 - val_loss: 0.6960 - val_accuracy: 0.6917\n",
            "Epoch 595/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7036 - val_loss: 0.7162 - val_accuracy: 0.6850\n",
            "Epoch 596/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.7061 - val_loss: 0.7136 - val_accuracy: 0.6867\n",
            "Epoch 597/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.7097 - val_loss: 0.7044 - val_accuracy: 0.6900\n",
            "Epoch 598/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.6936 - val_loss: 0.7113 - val_accuracy: 0.6933\n",
            "Epoch 599/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.7044 - val_loss: 0.6985 - val_accuracy: 0.6958\n",
            "Epoch 600/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6845 - accuracy: 0.6939 - val_loss: 0.7623 - val_accuracy: 0.6567\n",
            "Epoch 601/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.7025 - val_loss: 0.6927 - val_accuracy: 0.6842\n",
            "Epoch 602/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.7081 - val_loss: 0.7182 - val_accuracy: 0.6667\n",
            "Epoch 603/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6689 - accuracy: 0.6953 - val_loss: 0.7037 - val_accuracy: 0.6892\n",
            "Epoch 604/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.7044 - val_loss: 0.6863 - val_accuracy: 0.6867\n",
            "Epoch 605/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7028 - val_loss: 0.6992 - val_accuracy: 0.6867\n",
            "Epoch 606/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.7050 - val_loss: 0.7349 - val_accuracy: 0.6533\n",
            "Epoch 607/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.6956 - val_loss: 0.6900 - val_accuracy: 0.6817\n",
            "Epoch 608/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.7106 - val_loss: 0.6809 - val_accuracy: 0.7075\n",
            "Epoch 609/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6631 - accuracy: 0.7100 - val_loss: 0.7692 - val_accuracy: 0.6717\n",
            "Epoch 610/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6939 - val_loss: 0.7185 - val_accuracy: 0.6958\n",
            "Epoch 611/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.7081 - val_loss: 0.6954 - val_accuracy: 0.6975\n",
            "Epoch 612/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.7069 - val_loss: 0.7077 - val_accuracy: 0.6833\n",
            "Epoch 613/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6748 - accuracy: 0.7006 - val_loss: 0.7044 - val_accuracy: 0.6908\n",
            "Epoch 614/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.6944 - val_loss: 0.7057 - val_accuracy: 0.6867\n",
            "Epoch 615/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.7072 - val_loss: 0.7012 - val_accuracy: 0.6833\n",
            "Epoch 616/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6745 - accuracy: 0.7083 - val_loss: 0.7094 - val_accuracy: 0.6767\n",
            "Epoch 617/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.7075 - val_loss: 0.7543 - val_accuracy: 0.6600\n",
            "Epoch 618/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.7100 - val_loss: 0.7054 - val_accuracy: 0.6875\n",
            "Epoch 619/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6615 - accuracy: 0.7017 - val_loss: 0.7004 - val_accuracy: 0.6858\n",
            "Epoch 620/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.6928 - val_loss: 0.6945 - val_accuracy: 0.7042\n",
            "Epoch 621/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6714 - accuracy: 0.7039 - val_loss: 0.6919 - val_accuracy: 0.6825\n",
            "Epoch 622/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.7047 - val_loss: 0.7286 - val_accuracy: 0.6808\n",
            "Epoch 623/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6794 - accuracy: 0.7003 - val_loss: 0.6911 - val_accuracy: 0.7058\n",
            "Epoch 624/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.6967 - val_loss: 0.7038 - val_accuracy: 0.6933\n",
            "Epoch 625/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.7000 - val_loss: 0.7018 - val_accuracy: 0.6858\n",
            "Epoch 626/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.6967 - val_loss: 0.7206 - val_accuracy: 0.6917\n",
            "Epoch 627/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.7061 - val_loss: 0.7034 - val_accuracy: 0.6942\n",
            "Epoch 628/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6707 - accuracy: 0.7047 - val_loss: 0.7160 - val_accuracy: 0.6800\n",
            "Epoch 629/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6821 - accuracy: 0.6939 - val_loss: 0.7033 - val_accuracy: 0.6917\n",
            "Epoch 630/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6598 - accuracy: 0.7053 - val_loss: 0.7022 - val_accuracy: 0.6850\n",
            "Epoch 631/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6647 - accuracy: 0.7050 - val_loss: 0.6857 - val_accuracy: 0.6967\n",
            "Epoch 632/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.6950 - val_loss: 0.7021 - val_accuracy: 0.6867\n",
            "Epoch 633/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6701 - accuracy: 0.7078 - val_loss: 0.6998 - val_accuracy: 0.6892\n",
            "Epoch 634/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6789 - accuracy: 0.6981 - val_loss: 0.6939 - val_accuracy: 0.7033\n",
            "Epoch 635/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.6972 - val_loss: 0.7185 - val_accuracy: 0.6792\n",
            "Epoch 636/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.7017 - val_loss: 0.7044 - val_accuracy: 0.6850\n",
            "Epoch 637/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.6950 - val_loss: 0.7320 - val_accuracy: 0.6742\n",
            "Epoch 638/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.7053 - val_loss: 0.6856 - val_accuracy: 0.7017\n",
            "Epoch 639/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.7086 - val_loss: 0.6866 - val_accuracy: 0.6967\n",
            "Epoch 640/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.7033 - val_loss: 0.7808 - val_accuracy: 0.6558\n",
            "Epoch 641/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.6978 - val_loss: 0.7411 - val_accuracy: 0.6567\n",
            "Epoch 642/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6803 - accuracy: 0.6956 - val_loss: 0.7367 - val_accuracy: 0.6483\n",
            "Epoch 643/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.6994 - val_loss: 0.6842 - val_accuracy: 0.7067\n",
            "Epoch 644/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6641 - accuracy: 0.7069 - val_loss: 0.6898 - val_accuracy: 0.6842\n",
            "Epoch 645/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.6983 - val_loss: 0.6978 - val_accuracy: 0.6933\n",
            "Epoch 646/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6535 - accuracy: 0.7028 - val_loss: 0.7048 - val_accuracy: 0.6800\n",
            "Epoch 647/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.7072 - val_loss: 0.7340 - val_accuracy: 0.6625\n",
            "Epoch 648/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6722 - accuracy: 0.7019 - val_loss: 0.7001 - val_accuracy: 0.6950\n",
            "Epoch 649/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.7072 - val_loss: 0.6923 - val_accuracy: 0.6950\n",
            "Epoch 650/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.7044 - val_loss: 0.7171 - val_accuracy: 0.6758\n",
            "Epoch 651/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6732 - accuracy: 0.6972 - val_loss: 0.7115 - val_accuracy: 0.6817\n",
            "Epoch 652/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.7133 - val_loss: 0.7146 - val_accuracy: 0.6942\n",
            "Epoch 653/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6788 - accuracy: 0.6978 - val_loss: 0.7024 - val_accuracy: 0.6900\n",
            "Epoch 654/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.7081 - val_loss: 0.6919 - val_accuracy: 0.6983\n",
            "Epoch 655/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.6936 - val_loss: 0.7244 - val_accuracy: 0.6825\n",
            "Epoch 656/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.7003 - val_loss: 0.7122 - val_accuracy: 0.6867\n",
            "Epoch 657/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6613 - accuracy: 0.7058 - val_loss: 0.6942 - val_accuracy: 0.7025\n",
            "Epoch 658/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.7056 - val_loss: 0.6957 - val_accuracy: 0.6917\n",
            "Epoch 659/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.6983 - val_loss: 0.6870 - val_accuracy: 0.6967\n",
            "Epoch 660/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.7025 - val_loss: 0.6937 - val_accuracy: 0.6817\n",
            "Epoch 661/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6471 - accuracy: 0.7089 - val_loss: 0.6840 - val_accuracy: 0.6967\n",
            "Epoch 662/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.6972 - val_loss: 0.7141 - val_accuracy: 0.6850\n",
            "Epoch 663/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.7042 - val_loss: 0.7052 - val_accuracy: 0.6858\n",
            "Epoch 664/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.7064 - val_loss: 0.7653 - val_accuracy: 0.6483\n",
            "Epoch 665/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6708 - accuracy: 0.7061 - val_loss: 0.7905 - val_accuracy: 0.6433\n",
            "Epoch 666/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.6900 - val_loss: 0.7050 - val_accuracy: 0.6942\n",
            "Epoch 667/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.7025 - val_loss: 0.7305 - val_accuracy: 0.6733\n",
            "Epoch 668/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6776 - accuracy: 0.6964 - val_loss: 0.6947 - val_accuracy: 0.6892\n",
            "Epoch 669/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.7006 - val_loss: 0.7202 - val_accuracy: 0.6675\n",
            "Epoch 670/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.7033 - val_loss: 0.7084 - val_accuracy: 0.6942\n",
            "Epoch 671/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6948 - accuracy: 0.6933 - val_loss: 0.7565 - val_accuracy: 0.6592\n",
            "Epoch 672/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7119 - val_loss: 0.6915 - val_accuracy: 0.6967\n",
            "Epoch 673/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.6972 - val_loss: 0.7018 - val_accuracy: 0.6742\n",
            "Epoch 674/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.7031 - val_loss: 0.7083 - val_accuracy: 0.6783\n",
            "Epoch 675/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.6967 - val_loss: 0.6994 - val_accuracy: 0.6875\n",
            "Epoch 676/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.7136 - val_loss: 0.7125 - val_accuracy: 0.6758\n",
            "Epoch 677/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.6994 - val_loss: 0.7060 - val_accuracy: 0.6917\n",
            "Epoch 678/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.7033 - val_loss: 0.6997 - val_accuracy: 0.6817\n",
            "Epoch 679/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.7067 - val_loss: 0.7072 - val_accuracy: 0.6858\n",
            "Epoch 680/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.7061 - val_loss: 0.6788 - val_accuracy: 0.7117\n",
            "Epoch 681/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6872 - accuracy: 0.7006 - val_loss: 0.7214 - val_accuracy: 0.6867\n",
            "Epoch 682/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.6994 - val_loss: 0.7435 - val_accuracy: 0.6650\n",
            "Epoch 683/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6563 - accuracy: 0.7069 - val_loss: 0.7084 - val_accuracy: 0.6875\n",
            "Epoch 684/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6791 - accuracy: 0.6975 - val_loss: 0.7436 - val_accuracy: 0.6708\n",
            "Epoch 685/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.6883 - val_loss: 0.7090 - val_accuracy: 0.6692\n",
            "Epoch 686/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.6981 - val_loss: 0.6921 - val_accuracy: 0.6908\n",
            "Epoch 687/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6649 - accuracy: 0.7042 - val_loss: 0.7317 - val_accuracy: 0.6817\n",
            "Epoch 688/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.6883 - val_loss: 0.7404 - val_accuracy: 0.6750\n",
            "Epoch 689/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.6936 - val_loss: 0.6758 - val_accuracy: 0.7050\n",
            "Epoch 690/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6745 - accuracy: 0.7025 - val_loss: 0.6846 - val_accuracy: 0.6942\n",
            "Epoch 691/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.7011 - val_loss: 0.7154 - val_accuracy: 0.6733\n",
            "Epoch 692/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6727 - accuracy: 0.7047 - val_loss: 0.7227 - val_accuracy: 0.6775\n",
            "Epoch 693/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.7042 - val_loss: 0.6978 - val_accuracy: 0.6825\n",
            "Epoch 694/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7114 - val_loss: 0.6880 - val_accuracy: 0.6933\n",
            "Epoch 695/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.7053 - val_loss: 0.7167 - val_accuracy: 0.6858\n",
            "Epoch 696/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.7067 - val_loss: 0.7051 - val_accuracy: 0.6892\n",
            "Epoch 697/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.7014 - val_loss: 0.6859 - val_accuracy: 0.6983\n",
            "Epoch 698/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7027 - accuracy: 0.6875 - val_loss: 0.6844 - val_accuracy: 0.7025\n",
            "Epoch 699/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6726 - accuracy: 0.7039 - val_loss: 0.7104 - val_accuracy: 0.6733\n",
            "Epoch 700/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.7122 - val_loss: 0.6843 - val_accuracy: 0.6950\n",
            "Epoch 701/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7118 - accuracy: 0.6856 - val_loss: 0.7272 - val_accuracy: 0.6600\n",
            "Epoch 702/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.7097 - val_loss: 0.7460 - val_accuracy: 0.6658\n",
            "Epoch 703/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6807 - accuracy: 0.7008 - val_loss: 0.7112 - val_accuracy: 0.6808\n",
            "Epoch 704/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.7094 - val_loss: 0.7193 - val_accuracy: 0.6642\n",
            "Epoch 705/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.7122 - val_loss: 0.6855 - val_accuracy: 0.6983\n",
            "Epoch 706/1000\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.7053 - val_loss: 0.7133 - val_accuracy: 0.6625\n",
            "Epoch 707/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.6953 - val_loss: 0.6670 - val_accuracy: 0.6983\n",
            "Epoch 708/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.7053 - val_loss: 0.7634 - val_accuracy: 0.6642\n",
            "Epoch 709/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6883 - accuracy: 0.6961 - val_loss: 0.7169 - val_accuracy: 0.6850\n",
            "Epoch 710/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.7081 - val_loss: 0.7344 - val_accuracy: 0.6792\n",
            "Epoch 711/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6723 - accuracy: 0.7031 - val_loss: 0.6803 - val_accuracy: 0.6967\n",
            "Epoch 712/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.7072 - val_loss: 0.6869 - val_accuracy: 0.6908\n",
            "Epoch 713/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6544 - accuracy: 0.7092 - val_loss: 0.6892 - val_accuracy: 0.6908\n",
            "Epoch 714/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.7053 - val_loss: 0.7051 - val_accuracy: 0.6900\n",
            "Epoch 715/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.7075 - val_loss: 0.7055 - val_accuracy: 0.6792\n",
            "Epoch 716/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.7031 - val_loss: 0.7933 - val_accuracy: 0.6475\n",
            "Epoch 717/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.6953 - val_loss: 0.7143 - val_accuracy: 0.6775\n",
            "Epoch 718/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6554 - accuracy: 0.7075 - val_loss: 0.6979 - val_accuracy: 0.6775\n",
            "Epoch 719/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.7086 - val_loss: 0.7368 - val_accuracy: 0.6675\n",
            "Epoch 720/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.6969 - val_loss: 0.6850 - val_accuracy: 0.6958\n",
            "Epoch 721/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.7117 - val_loss: 0.6888 - val_accuracy: 0.6950\n",
            "Epoch 722/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6605 - accuracy: 0.7069 - val_loss: 0.6965 - val_accuracy: 0.6792\n",
            "Epoch 723/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.6933 - val_loss: 0.7078 - val_accuracy: 0.6850\n",
            "Epoch 724/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.7033 - val_loss: 0.7078 - val_accuracy: 0.6917\n",
            "Epoch 725/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.7056 - val_loss: 0.7016 - val_accuracy: 0.6900\n",
            "Epoch 726/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6714 - accuracy: 0.7019 - val_loss: 0.6948 - val_accuracy: 0.6992\n",
            "Epoch 727/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.7036 - val_loss: 0.6899 - val_accuracy: 0.6908\n",
            "Epoch 728/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6848 - accuracy: 0.6936 - val_loss: 0.7451 - val_accuracy: 0.6783\n",
            "Epoch 729/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6817 - accuracy: 0.6997 - val_loss: 0.7013 - val_accuracy: 0.6883\n",
            "Epoch 730/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.7106 - val_loss: 0.6893 - val_accuracy: 0.6892\n",
            "Epoch 731/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.7072 - val_loss: 0.6909 - val_accuracy: 0.7000\n",
            "Epoch 732/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.7031 - val_loss: 0.7580 - val_accuracy: 0.6508\n",
            "Epoch 733/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6749 - accuracy: 0.7053 - val_loss: 0.6888 - val_accuracy: 0.6950\n",
            "Epoch 734/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.7019 - val_loss: 0.7148 - val_accuracy: 0.6758\n",
            "Epoch 735/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.7103 - val_loss: 0.6749 - val_accuracy: 0.7025\n",
            "Epoch 736/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6719 - accuracy: 0.6989 - val_loss: 0.7209 - val_accuracy: 0.6800\n",
            "Epoch 737/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.7017 - val_loss: 0.6931 - val_accuracy: 0.6850\n",
            "Epoch 738/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.7147 - val_loss: 0.6802 - val_accuracy: 0.6883\n",
            "Epoch 739/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.7053 - val_loss: 0.7061 - val_accuracy: 0.6892\n",
            "Epoch 740/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.7094 - val_loss: 0.6853 - val_accuracy: 0.6975\n",
            "Epoch 741/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6525 - accuracy: 0.7100 - val_loss: 0.7453 - val_accuracy: 0.6450\n",
            "Epoch 742/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6828 - accuracy: 0.7056 - val_loss: 0.6959 - val_accuracy: 0.6825\n",
            "Epoch 743/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.7047 - val_loss: 0.7190 - val_accuracy: 0.6892\n",
            "Epoch 744/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.7053 - val_loss: 0.7027 - val_accuracy: 0.6875\n",
            "Epoch 745/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.6992 - val_loss: 0.7047 - val_accuracy: 0.6908\n",
            "Epoch 746/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.6992 - val_loss: 0.6946 - val_accuracy: 0.6775\n",
            "Epoch 747/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.6997 - val_loss: 0.7489 - val_accuracy: 0.6725\n",
            "Epoch 748/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.7111 - val_loss: 0.7036 - val_accuracy: 0.6867\n",
            "Epoch 749/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.7056 - val_loss: 0.7205 - val_accuracy: 0.6975\n",
            "Epoch 750/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.6961 - val_loss: 0.6895 - val_accuracy: 0.6900\n",
            "Epoch 751/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.7072 - val_loss: 0.7111 - val_accuracy: 0.6917\n",
            "Epoch 752/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.7111 - val_loss: 0.6912 - val_accuracy: 0.6933\n",
            "Epoch 753/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.7117 - val_loss: 0.6856 - val_accuracy: 0.6875\n",
            "Epoch 754/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6663 - accuracy: 0.7067 - val_loss: 0.7043 - val_accuracy: 0.6850\n",
            "Epoch 755/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.7047 - val_loss: 0.7045 - val_accuracy: 0.6908\n",
            "Epoch 756/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.7131 - val_loss: 0.6923 - val_accuracy: 0.6850\n",
            "Epoch 757/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.7089 - val_loss: 0.7005 - val_accuracy: 0.6900\n",
            "Epoch 758/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7025 - val_loss: 0.7253 - val_accuracy: 0.6900\n",
            "Epoch 759/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.7097 - val_loss: 0.7208 - val_accuracy: 0.6775\n",
            "Epoch 760/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6728 - accuracy: 0.7025 - val_loss: 0.7038 - val_accuracy: 0.6950\n",
            "Epoch 761/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.7039 - val_loss: 0.6927 - val_accuracy: 0.6842\n",
            "Epoch 762/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6475 - accuracy: 0.7106 - val_loss: 0.6881 - val_accuracy: 0.6942\n",
            "Epoch 763/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.7108 - val_loss: 0.6852 - val_accuracy: 0.7067\n",
            "Epoch 764/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.7100 - val_loss: 0.6991 - val_accuracy: 0.6958\n",
            "Epoch 765/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.7081 - val_loss: 0.6925 - val_accuracy: 0.6925\n",
            "Epoch 766/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.7103 - val_loss: 0.7879 - val_accuracy: 0.6625\n",
            "Epoch 767/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.7036 - val_loss: 0.6938 - val_accuracy: 0.6967\n",
            "Epoch 768/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.7078 - val_loss: 0.7135 - val_accuracy: 0.6700\n",
            "Epoch 769/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.6978 - val_loss: 0.7243 - val_accuracy: 0.6775\n",
            "Epoch 770/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6677 - accuracy: 0.7094 - val_loss: 0.7089 - val_accuracy: 0.6858\n",
            "Epoch 771/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6716 - accuracy: 0.7011 - val_loss: 0.7194 - val_accuracy: 0.6783\n",
            "Epoch 772/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.7089 - val_loss: 0.6872 - val_accuracy: 0.6992\n",
            "Epoch 773/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6573 - accuracy: 0.7156 - val_loss: 0.7172 - val_accuracy: 0.6875\n",
            "Epoch 774/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6818 - accuracy: 0.6967 - val_loss: 0.6974 - val_accuracy: 0.6775\n",
            "Epoch 775/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.6992 - val_loss: 0.7669 - val_accuracy: 0.6475\n",
            "Epoch 776/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.6989 - val_loss: 0.6881 - val_accuracy: 0.6825\n",
            "Epoch 777/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6577 - accuracy: 0.7056 - val_loss: 0.6890 - val_accuracy: 0.6908\n",
            "Epoch 778/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.7136 - val_loss: 0.7065 - val_accuracy: 0.6892\n",
            "Epoch 779/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6751 - accuracy: 0.7081 - val_loss: 0.7560 - val_accuracy: 0.6583\n",
            "Epoch 780/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.7142 - val_loss: 0.7310 - val_accuracy: 0.6742\n",
            "Epoch 781/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6611 - accuracy: 0.7067 - val_loss: 0.6891 - val_accuracy: 0.6967\n",
            "Epoch 782/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6838 - accuracy: 0.6994 - val_loss: 0.7118 - val_accuracy: 0.6875\n",
            "Epoch 783/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.7017 - val_loss: 0.6910 - val_accuracy: 0.6950\n",
            "Epoch 784/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6643 - accuracy: 0.7111 - val_loss: 0.7040 - val_accuracy: 0.6775\n",
            "Epoch 785/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.7058 - val_loss: 0.6871 - val_accuracy: 0.6900\n",
            "Epoch 786/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6480 - accuracy: 0.7119 - val_loss: 0.7095 - val_accuracy: 0.6933\n",
            "Epoch 787/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6580 - accuracy: 0.7025 - val_loss: 0.6793 - val_accuracy: 0.6967\n",
            "Epoch 788/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6682 - accuracy: 0.6978 - val_loss: 0.7317 - val_accuracy: 0.6767\n",
            "Epoch 789/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.7117 - val_loss: 0.6851 - val_accuracy: 0.6967\n",
            "Epoch 790/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.6975 - val_loss: 0.7091 - val_accuracy: 0.6850\n",
            "Epoch 791/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.6997 - val_loss: 0.6893 - val_accuracy: 0.7000\n",
            "Epoch 792/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6480 - accuracy: 0.7097 - val_loss: 0.7075 - val_accuracy: 0.6792\n",
            "Epoch 793/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.7108 - val_loss: 0.7076 - val_accuracy: 0.6908\n",
            "Epoch 794/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.6942 - val_loss: 0.7347 - val_accuracy: 0.6733\n",
            "Epoch 795/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.7075 - val_loss: 0.7041 - val_accuracy: 0.6833\n",
            "Epoch 796/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.7019 - val_loss: 0.7164 - val_accuracy: 0.6775\n",
            "Epoch 797/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.7108 - val_loss: 0.7343 - val_accuracy: 0.6767\n",
            "Epoch 798/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.7031 - val_loss: 0.6997 - val_accuracy: 0.6875\n",
            "Epoch 799/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.7089 - val_loss: 0.6930 - val_accuracy: 0.6950\n",
            "Epoch 800/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.7056 - val_loss: 0.7141 - val_accuracy: 0.6942\n",
            "Epoch 801/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.6997 - val_loss: 0.7097 - val_accuracy: 0.6850\n",
            "Epoch 802/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.7083 - val_loss: 0.7046 - val_accuracy: 0.6908\n",
            "Epoch 803/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6646 - accuracy: 0.7042 - val_loss: 0.7191 - val_accuracy: 0.6767\n",
            "Epoch 804/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6967 - accuracy: 0.6925 - val_loss: 0.7020 - val_accuracy: 0.6733\n",
            "Epoch 805/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6538 - accuracy: 0.7117 - val_loss: 0.6933 - val_accuracy: 0.6900\n",
            "Epoch 806/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.7072 - val_loss: 0.6954 - val_accuracy: 0.6942\n",
            "Epoch 807/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.7092 - val_loss: 0.6919 - val_accuracy: 0.6850\n",
            "Epoch 808/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7028 - val_loss: 0.7066 - val_accuracy: 0.6942\n",
            "Epoch 809/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.7100 - val_loss: 0.6883 - val_accuracy: 0.6875\n",
            "Epoch 810/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6531 - accuracy: 0.7139 - val_loss: 0.6806 - val_accuracy: 0.6983\n",
            "Epoch 811/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.6992 - val_loss: 0.6903 - val_accuracy: 0.6983\n",
            "Epoch 812/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6592 - accuracy: 0.7122 - val_loss: 0.7601 - val_accuracy: 0.6692\n",
            "Epoch 813/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.6919 - val_loss: 0.7983 - val_accuracy: 0.6508\n",
            "Epoch 814/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7231 - accuracy: 0.6858 - val_loss: 0.7145 - val_accuracy: 0.6783\n",
            "Epoch 815/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.7006 - val_loss: 0.7220 - val_accuracy: 0.6675\n",
            "Epoch 816/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.7050 - val_loss: 0.7376 - val_accuracy: 0.6550\n",
            "Epoch 817/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.7050 - val_loss: 0.7495 - val_accuracy: 0.6592\n",
            "Epoch 818/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6761 - accuracy: 0.6992 - val_loss: 0.6930 - val_accuracy: 0.6758\n",
            "Epoch 819/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6625 - accuracy: 0.7061 - val_loss: 0.6944 - val_accuracy: 0.6925\n",
            "Epoch 820/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6509 - accuracy: 0.7136 - val_loss: 0.6837 - val_accuracy: 0.6917\n",
            "Epoch 821/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6517 - accuracy: 0.7092 - val_loss: 0.6949 - val_accuracy: 0.6958\n",
            "Epoch 822/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.7047 - val_loss: 0.6878 - val_accuracy: 0.6867\n",
            "Epoch 823/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6534 - accuracy: 0.7056 - val_loss: 0.6802 - val_accuracy: 0.6983\n",
            "Epoch 824/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.7106 - val_loss: 0.7064 - val_accuracy: 0.6892\n",
            "Epoch 825/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.7056 - val_loss: 0.6998 - val_accuracy: 0.6908\n",
            "Epoch 826/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.7133 - val_loss: 0.6954 - val_accuracy: 0.6883\n",
            "Epoch 827/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.7036 - val_loss: 0.7571 - val_accuracy: 0.6633\n",
            "Epoch 828/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6586 - accuracy: 0.7136 - val_loss: 0.7190 - val_accuracy: 0.6675\n",
            "Epoch 829/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6653 - accuracy: 0.7031 - val_loss: 0.6955 - val_accuracy: 0.6808\n",
            "Epoch 830/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.7122 - val_loss: 0.7042 - val_accuracy: 0.6833\n",
            "Epoch 831/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.7139 - val_loss: 0.7039 - val_accuracy: 0.6800\n",
            "Epoch 832/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6724 - accuracy: 0.6983 - val_loss: 0.7458 - val_accuracy: 0.6592\n",
            "Epoch 833/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.7033 - val_loss: 0.6859 - val_accuracy: 0.6958\n",
            "Epoch 834/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6567 - accuracy: 0.7147 - val_loss: 0.6917 - val_accuracy: 0.6792\n",
            "Epoch 835/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.7122 - val_loss: 0.7046 - val_accuracy: 0.6808\n",
            "Epoch 836/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6718 - accuracy: 0.6975 - val_loss: 0.7054 - val_accuracy: 0.6800\n",
            "Epoch 837/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6518 - accuracy: 0.7067 - val_loss: 0.7278 - val_accuracy: 0.6700\n",
            "Epoch 838/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6755 - accuracy: 0.6947 - val_loss: 0.6878 - val_accuracy: 0.6933\n",
            "Epoch 839/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.7053 - val_loss: 0.6898 - val_accuracy: 0.6842\n",
            "Epoch 840/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.7175 - val_loss: 0.6827 - val_accuracy: 0.7033\n",
            "Epoch 841/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6461 - accuracy: 0.7142 - val_loss: 0.6859 - val_accuracy: 0.6858\n",
            "Epoch 842/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.7067 - val_loss: 0.7275 - val_accuracy: 0.6775\n",
            "Epoch 843/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.6969 - val_loss: 0.7059 - val_accuracy: 0.6742\n",
            "Epoch 844/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.7119 - val_loss: 0.6912 - val_accuracy: 0.7042\n",
            "Epoch 845/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.7053 - val_loss: 0.7140 - val_accuracy: 0.6850\n",
            "Epoch 846/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.7097 - val_loss: 0.7288 - val_accuracy: 0.6758\n",
            "Epoch 847/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7122 - val_loss: 0.7136 - val_accuracy: 0.6783\n",
            "Epoch 848/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.7114 - val_loss: 0.6989 - val_accuracy: 0.6858\n",
            "Epoch 849/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.7131 - val_loss: 0.6834 - val_accuracy: 0.6983\n",
            "Epoch 850/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.7072 - val_loss: 0.6968 - val_accuracy: 0.6892\n",
            "Epoch 851/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.7061 - val_loss: 0.6869 - val_accuracy: 0.6825\n",
            "Epoch 852/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6540 - accuracy: 0.7067 - val_loss: 0.6897 - val_accuracy: 0.6950\n",
            "Epoch 853/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.7011 - val_loss: 0.7260 - val_accuracy: 0.6708\n",
            "Epoch 854/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.7100 - val_loss: 0.6903 - val_accuracy: 0.6883\n",
            "Epoch 855/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.6936 - val_loss: 0.7065 - val_accuracy: 0.6808\n",
            "Epoch 856/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.7017 - val_loss: 0.6987 - val_accuracy: 0.6842\n",
            "Epoch 857/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6678 - accuracy: 0.7047 - val_loss: 0.7591 - val_accuracy: 0.6692\n",
            "Epoch 858/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.7044 - val_loss: 0.6865 - val_accuracy: 0.6950\n",
            "Epoch 859/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.7167 - val_loss: 0.6918 - val_accuracy: 0.6925\n",
            "Epoch 860/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.7139 - val_loss: 0.7212 - val_accuracy: 0.6792\n",
            "Epoch 861/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6656 - accuracy: 0.7022 - val_loss: 0.6989 - val_accuracy: 0.6908\n",
            "Epoch 862/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.7019 - val_loss: 0.6946 - val_accuracy: 0.6833\n",
            "Epoch 863/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6530 - accuracy: 0.7117 - val_loss: 0.7141 - val_accuracy: 0.6842\n",
            "Epoch 864/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.7081 - val_loss: 0.6873 - val_accuracy: 0.6950\n",
            "Epoch 865/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6617 - accuracy: 0.7108 - val_loss: 0.7127 - val_accuracy: 0.6833\n",
            "Epoch 866/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.7136 - val_loss: 0.7107 - val_accuracy: 0.6817\n",
            "Epoch 867/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6491 - accuracy: 0.7147 - val_loss: 0.6938 - val_accuracy: 0.6842\n",
            "Epoch 868/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.7164 - val_loss: 0.7112 - val_accuracy: 0.6700\n",
            "Epoch 869/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.7089 - val_loss: 0.6971 - val_accuracy: 0.6958\n",
            "Epoch 870/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6709 - accuracy: 0.7042 - val_loss: 0.7163 - val_accuracy: 0.6875\n",
            "Epoch 871/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.7053 - val_loss: 0.7293 - val_accuracy: 0.6742\n",
            "Epoch 872/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.7092 - val_loss: 0.6992 - val_accuracy: 0.6942\n",
            "Epoch 873/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.7097 - val_loss: 0.6892 - val_accuracy: 0.6792\n",
            "Epoch 874/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.7058 - val_loss: 0.7042 - val_accuracy: 0.6817\n",
            "Epoch 875/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6530 - accuracy: 0.7114 - val_loss: 0.7221 - val_accuracy: 0.6742\n",
            "Epoch 876/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.7025 - val_loss: 0.6944 - val_accuracy: 0.7025\n",
            "Epoch 877/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.7089 - val_loss: 0.6923 - val_accuracy: 0.6908\n",
            "Epoch 878/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.7058 - val_loss: 0.6985 - val_accuracy: 0.6992\n",
            "Epoch 879/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6606 - accuracy: 0.7036 - val_loss: 0.6993 - val_accuracy: 0.6950\n",
            "Epoch 880/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7142 - val_loss: 0.7081 - val_accuracy: 0.6708\n",
            "Epoch 881/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.7000 - val_loss: 0.7143 - val_accuracy: 0.6758\n",
            "Epoch 882/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.7100 - val_loss: 0.7247 - val_accuracy: 0.6750\n",
            "Epoch 883/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6592 - accuracy: 0.7089 - val_loss: 0.7283 - val_accuracy: 0.6675\n",
            "Epoch 884/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7011 - val_loss: 0.6840 - val_accuracy: 0.7008\n",
            "Epoch 885/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.7050 - val_loss: 0.6900 - val_accuracy: 0.6867\n",
            "Epoch 886/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.7117 - val_loss: 0.7389 - val_accuracy: 0.6700\n",
            "Epoch 887/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.7036 - val_loss: 0.7114 - val_accuracy: 0.6850\n",
            "Epoch 888/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.7114 - val_loss: 0.6850 - val_accuracy: 0.6983\n",
            "Epoch 889/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6920 - accuracy: 0.6906 - val_loss: 0.6916 - val_accuracy: 0.6867\n",
            "Epoch 890/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6412 - accuracy: 0.7142 - val_loss: 0.6986 - val_accuracy: 0.6925\n",
            "Epoch 891/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.7058 - val_loss: 0.6831 - val_accuracy: 0.7000\n",
            "Epoch 892/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.7042 - val_loss: 0.6937 - val_accuracy: 0.6900\n",
            "Epoch 893/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6698 - accuracy: 0.7008 - val_loss: 0.7032 - val_accuracy: 0.6842\n",
            "Epoch 894/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6543 - accuracy: 0.7075 - val_loss: 0.6946 - val_accuracy: 0.6892\n",
            "Epoch 895/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.7144 - val_loss: 0.7339 - val_accuracy: 0.6733\n",
            "Epoch 896/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.7117 - val_loss: 0.7167 - val_accuracy: 0.6858\n",
            "Epoch 897/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.7100 - val_loss: 0.6991 - val_accuracy: 0.6908\n",
            "Epoch 898/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.7147 - val_loss: 0.6892 - val_accuracy: 0.6967\n",
            "Epoch 899/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6567 - accuracy: 0.7097 - val_loss: 0.6880 - val_accuracy: 0.6942\n",
            "Epoch 900/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.7097 - val_loss: 0.7173 - val_accuracy: 0.6925\n",
            "Epoch 901/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.7033 - val_loss: 0.6873 - val_accuracy: 0.6908\n",
            "Epoch 902/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.7119 - val_loss: 0.7006 - val_accuracy: 0.6808\n",
            "Epoch 903/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.7017 - val_loss: 0.7009 - val_accuracy: 0.6783\n",
            "Epoch 904/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.7067 - val_loss: 0.6928 - val_accuracy: 0.6908\n",
            "Epoch 905/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.7189 - val_loss: 0.6976 - val_accuracy: 0.6883\n",
            "Epoch 906/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.6992 - val_loss: 0.7242 - val_accuracy: 0.6775\n",
            "Epoch 907/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.7089 - val_loss: 0.7202 - val_accuracy: 0.6875\n",
            "Epoch 908/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.7106 - val_loss: 0.7017 - val_accuracy: 0.6775\n",
            "Epoch 909/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.7150 - val_loss: 0.6964 - val_accuracy: 0.6900\n",
            "Epoch 910/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.7097 - val_loss: 0.6773 - val_accuracy: 0.7017\n",
            "Epoch 911/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.7067 - val_loss: 0.7029 - val_accuracy: 0.6925\n",
            "Epoch 912/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.6981 - val_loss: 0.7054 - val_accuracy: 0.6825\n",
            "Epoch 913/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6720 - accuracy: 0.7022 - val_loss: 0.7109 - val_accuracy: 0.6892\n",
            "Epoch 914/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.7131 - val_loss: 0.7028 - val_accuracy: 0.6842\n",
            "Epoch 915/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6542 - accuracy: 0.7111 - val_loss: 0.7669 - val_accuracy: 0.6500\n",
            "Epoch 916/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.7019 - val_loss: 0.7033 - val_accuracy: 0.6767\n",
            "Epoch 917/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6483 - accuracy: 0.7161 - val_loss: 0.6854 - val_accuracy: 0.6958\n",
            "Epoch 918/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6466 - accuracy: 0.7131 - val_loss: 0.7021 - val_accuracy: 0.6825\n",
            "Epoch 919/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6658 - accuracy: 0.7014 - val_loss: 0.6994 - val_accuracy: 0.6800\n",
            "Epoch 920/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.6969 - val_loss: 0.7636 - val_accuracy: 0.6358\n",
            "Epoch 921/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.7075 - val_loss: 0.7071 - val_accuracy: 0.6908\n",
            "Epoch 922/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.7131 - val_loss: 0.6961 - val_accuracy: 0.6967\n",
            "Epoch 923/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6448 - accuracy: 0.7167 - val_loss: 0.6961 - val_accuracy: 0.6800\n",
            "Epoch 924/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.7083 - val_loss: 0.6973 - val_accuracy: 0.6817\n",
            "Epoch 925/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.7100 - val_loss: 0.7428 - val_accuracy: 0.6667\n",
            "Epoch 926/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.7111 - val_loss: 0.6979 - val_accuracy: 0.6900\n",
            "Epoch 927/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.7100 - val_loss: 0.6903 - val_accuracy: 0.6958\n",
            "Epoch 928/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6508 - accuracy: 0.7086 - val_loss: 0.7151 - val_accuracy: 0.6758\n",
            "Epoch 929/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6619 - accuracy: 0.7050 - val_loss: 0.7085 - val_accuracy: 0.6808\n",
            "Epoch 930/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6550 - accuracy: 0.7111 - val_loss: 0.7163 - val_accuracy: 0.6850\n",
            "Epoch 931/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6590 - accuracy: 0.7064 - val_loss: 0.7147 - val_accuracy: 0.7025\n",
            "Epoch 932/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7061 - val_loss: 0.6818 - val_accuracy: 0.7017\n",
            "Epoch 933/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6477 - accuracy: 0.7106 - val_loss: 0.7128 - val_accuracy: 0.6650\n",
            "Epoch 934/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.7142 - val_loss: 0.6986 - val_accuracy: 0.6867\n",
            "Epoch 935/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.7150 - val_loss: 0.6732 - val_accuracy: 0.7025\n",
            "Epoch 936/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.7039 - val_loss: 0.7196 - val_accuracy: 0.6758\n",
            "Epoch 937/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6422 - accuracy: 0.7158 - val_loss: 0.7097 - val_accuracy: 0.6875\n",
            "Epoch 938/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.7092 - val_loss: 0.6881 - val_accuracy: 0.6958\n",
            "Epoch 939/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.7117 - val_loss: 0.8047 - val_accuracy: 0.6183\n",
            "Epoch 940/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.7044 - val_loss: 0.7181 - val_accuracy: 0.6783\n",
            "Epoch 941/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.7058 - val_loss: 0.6976 - val_accuracy: 0.6900\n",
            "Epoch 942/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.7092 - val_loss: 0.6953 - val_accuracy: 0.6892\n",
            "Epoch 943/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.7086 - val_loss: 0.6979 - val_accuracy: 0.7058\n",
            "Epoch 944/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.7072 - val_loss: 0.6851 - val_accuracy: 0.6992\n",
            "Epoch 945/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6561 - accuracy: 0.7069 - val_loss: 0.7142 - val_accuracy: 0.6942\n",
            "Epoch 946/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.7081 - val_loss: 0.7122 - val_accuracy: 0.6800\n",
            "Epoch 947/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6589 - accuracy: 0.7050 - val_loss: 0.6947 - val_accuracy: 0.6858\n",
            "Epoch 948/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.7064 - val_loss: 0.7209 - val_accuracy: 0.6858\n",
            "Epoch 949/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6540 - accuracy: 0.7086 - val_loss: 0.6929 - val_accuracy: 0.7025\n",
            "Epoch 950/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7075 - val_loss: 0.7007 - val_accuracy: 0.6808\n",
            "Epoch 951/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.6997 - val_loss: 0.7095 - val_accuracy: 0.6892\n",
            "Epoch 952/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.6953 - val_loss: 0.7764 - val_accuracy: 0.6525\n",
            "Epoch 953/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6619 - accuracy: 0.7053 - val_loss: 0.6917 - val_accuracy: 0.6908\n",
            "Epoch 954/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.7078 - val_loss: 0.7033 - val_accuracy: 0.6925\n",
            "Epoch 955/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.7031 - val_loss: 0.7141 - val_accuracy: 0.6917\n",
            "Epoch 956/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.7122 - val_loss: 0.7236 - val_accuracy: 0.6742\n",
            "Epoch 957/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.7117 - val_loss: 0.6891 - val_accuracy: 0.6917\n",
            "Epoch 958/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.7200 - val_loss: 0.7112 - val_accuracy: 0.6842\n",
            "Epoch 959/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.7114 - val_loss: 0.7214 - val_accuracy: 0.6792\n",
            "Epoch 960/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6639 - accuracy: 0.7061 - val_loss: 0.7131 - val_accuracy: 0.6808\n",
            "Epoch 961/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.7094 - val_loss: 0.7130 - val_accuracy: 0.6750\n",
            "Epoch 962/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7315 - accuracy: 0.6914 - val_loss: 0.7263 - val_accuracy: 0.6858\n",
            "Epoch 963/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6638 - accuracy: 0.7019 - val_loss: 0.7331 - val_accuracy: 0.6783\n",
            "Epoch 964/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6531 - accuracy: 0.7058 - val_loss: 0.7213 - val_accuracy: 0.6800\n",
            "Epoch 965/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6511 - accuracy: 0.7128 - val_loss: 0.7110 - val_accuracy: 0.6783\n",
            "Epoch 966/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.7019 - val_loss: 0.6809 - val_accuracy: 0.7025\n",
            "Epoch 967/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6510 - accuracy: 0.7086 - val_loss: 0.7085 - val_accuracy: 0.6717\n",
            "Epoch 968/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.7025 - val_loss: 0.6858 - val_accuracy: 0.6858\n",
            "Epoch 969/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.7067 - val_loss: 0.7044 - val_accuracy: 0.6858\n",
            "Epoch 970/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6761 - accuracy: 0.7044 - val_loss: 0.7297 - val_accuracy: 0.6833\n",
            "Epoch 971/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.7111 - val_loss: 0.7123 - val_accuracy: 0.6792\n",
            "Epoch 972/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6515 - accuracy: 0.7133 - val_loss: 0.7111 - val_accuracy: 0.6858\n",
            "Epoch 973/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.7014 - val_loss: 0.7439 - val_accuracy: 0.6692\n",
            "Epoch 974/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6596 - accuracy: 0.7064 - val_loss: 0.7559 - val_accuracy: 0.6692\n",
            "Epoch 975/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6535 - accuracy: 0.7131 - val_loss: 0.6826 - val_accuracy: 0.6900\n",
            "Epoch 976/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.7158 - val_loss: 0.7182 - val_accuracy: 0.6750\n",
            "Epoch 977/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.7117 - val_loss: 0.7120 - val_accuracy: 0.6675\n",
            "Epoch 978/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.7144 - val_loss: 0.6763 - val_accuracy: 0.6958\n",
            "Epoch 979/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.7064 - val_loss: 0.7096 - val_accuracy: 0.6783\n",
            "Epoch 980/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.7175 - val_loss: 0.7105 - val_accuracy: 0.6792\n",
            "Epoch 981/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6455 - accuracy: 0.7186 - val_loss: 0.6870 - val_accuracy: 0.6900\n",
            "Epoch 982/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6547 - accuracy: 0.7083 - val_loss: 0.6955 - val_accuracy: 0.6892\n",
            "Epoch 983/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.7083 - val_loss: 0.6953 - val_accuracy: 0.6858\n",
            "Epoch 984/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.7056 - val_loss: 0.6853 - val_accuracy: 0.6983\n",
            "Epoch 985/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.7097 - val_loss: 0.7482 - val_accuracy: 0.6800\n",
            "Epoch 986/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6534 - accuracy: 0.7117 - val_loss: 0.7027 - val_accuracy: 0.6792\n",
            "Epoch 987/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.7136 - val_loss: 0.7419 - val_accuracy: 0.6717\n",
            "Epoch 988/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.6956 - val_loss: 0.6946 - val_accuracy: 0.6917\n",
            "Epoch 989/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.6950 - val_loss: 0.6948 - val_accuracy: 0.6992\n",
            "Epoch 990/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.7011 - val_loss: 0.7320 - val_accuracy: 0.6750\n",
            "Epoch 991/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6569 - accuracy: 0.7089 - val_loss: 0.7444 - val_accuracy: 0.6550\n",
            "Epoch 992/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.7058 - val_loss: 0.7183 - val_accuracy: 0.6800\n",
            "Epoch 993/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.7125 - val_loss: 0.7488 - val_accuracy: 0.6825\n",
            "Epoch 994/1000\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6724 - accuracy: 0.7000 - val_loss: 0.7613 - val_accuracy: 0.6508\n",
            "Epoch 995/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6542 - accuracy: 0.7050 - val_loss: 0.7069 - val_accuracy: 0.6658\n",
            "Epoch 996/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6326 - accuracy: 0.7178 - val_loss: 0.7060 - val_accuracy: 0.6892\n",
            "Epoch 997/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6435 - accuracy: 0.7111 - val_loss: 0.6856 - val_accuracy: 0.6925\n",
            "Epoch 998/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.7056 - val_loss: 0.7296 - val_accuracy: 0.6708\n",
            "Epoch 999/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6613 - accuracy: 0.7078 - val_loss: 0.6996 - val_accuracy: 0.6883\n",
            "Epoch 1000/1000\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6578 - accuracy: 0.7053 - val_loss: 0.7075 - val_accuracy: 0.6858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "rCEsefOLSku0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4797d3c-da9e-4589-8a7f-47d664261a7d"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.7119388580322266\n",
            "Test accuracy: 0.6924999952316284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc      = history.history['accuracy']\n",
        "val_acc  = history.history['val_accuracy']\n",
        "loss     = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  (epochs, acc)\n",
        "plt.plot  (epochs, val_acc)\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot  (epochs, loss)\n",
        "plt.plot  (epochs, val_loss)\n",
        "plt.title ('Training and validation loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "Uqt8HA-CqFRx",
        "outputId": "aed28134-7f6d-498e-8a2e-56b0215a1297"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {},
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd7gURdaHf6cn3ABcsmRJggiioogJFQPmtGZd0/qtrnnNYkbUNa8R42LOOYGiIKCiIKCCEhQk55y5aaa+P7p7prqnqsNMT6Te5+Fhbnd1dXU6derUqXOIMQaFQqFQlC5avhugUCgUiuyiBL1CoVCUOErQKxQKRYmjBL1CoVCUOErQKxQKRYmjBL1CoVCUOErQb4cQ0RdEdH7QZfMJEc0nosOzUC8jop2M388S0e1eyqZxnr8T0VfptlOhcIKUH31xQESbuT8rAdQAiBl//4sx9kbuW1U4ENF8AP9kjI0KuF4GoBtjbE5QZYmoE4B5ACKMsfog2qlQOBHOdwMU3mCMNTR/Owk1Igor4aEoFNT7WBgo002RQ0QDiGgxEd1ERMsBvERETYnocyJaRUTrjN/tuWPGEtE/jd8XENH3RPSwUXYeER2dZtnORPQtEW0iolFENJSIXpe020sb7yai8UZ9XxFRC27/uUS0gIjWENGtDvdnHyJaTkQhbtvfiGia8bsfEf1IROuJaBkRPUVEUUldLxPRPdzfNxjHLCWiC21ljyWiX4hoIxEtIqLB3O5vjf/XE9FmItrPvLfc8fsT0SQi2mD8v7/Xe+PzPjcjopeMa1hHRB9z+04kol+Na/iLiI4ytlvMZEQ02HzORNTJMGH9HxEtBPCNsf094zlsMN6RXtzxFUT0iPE8NxjvWAURDSeiK23XM42I/ia6VoUcJehLg9YAmgHoCOBi6M/1JePvHQFsA/CUw/H7APgDQAsADwIYRkSURtk3AfwEoDmAwQDOdTinlzaeDeAfAHYAEAVwPQAQUU8Azxj1tzXO1x4CGGMTAWwBcKit3jeN3zEA1xjXsx+AwwBc5tBuGG04ymjPQADdANjnB7YAOA9AEwDHAriUiE4y9h1k/N+EMdaQMfajre5mAIYDeMK4tv8CGE5EzW3XkHJvBLjd59egmwJ7GXU9arShH4BXAdxgXMNBAObL7oeAgwHsAuBI4+8voN+nHQD8DIA3NT4MYC8A+0N/j28EEAfwCoBzzEJEtDuAdtDvjcIPjDH1r8j+Qf/gDjd+DwBQC6DcofweANZxf4+FbvoBgAsAzOH2VQJgAFr7KQtdiNQDqOT2vw7gdY/XJGrjbdzflwH40vh9B4C3uX0NjHtwuKTuewC8aPxuBF0Id5SUvRrAR9zfDMBOxu+XAdxj/H4RwP1cue58WUG9jwF41PjdySgb5vZfAOB74/e5AH6yHf8jgAvc7o2f+wygDXSB2lRQ7jmzvU7vn/H3YPM5c9fWxaENTYwyjaF3RNsA7C4oVw5gHfR5D0DvEJ7O9fdWCv+URl8arGKMVZt/EFElET1nDIU3QjcVNOHNFzaWmz8YY1uNnw19lm0LYC23DQAWyRrssY3Lud9buTa15etmjG0BsEZ2Luja+8lEVAbgZAA/M8YWGO3obpgzlhvt+A907d4NSxsALLBd3z5ENMYwmWwAcInHes26F9i2LYCuzZrI7o0Fl/vcAfozWyc4tAOAvzy2V0Ti3hBRiIjuN8w/G5EcGbQw/pWLzmW80+8AOIeINABnQR+BKHyiBH1pYHedug7AzgD2YYxVIWkqkJljgmAZgGZEVMlt6+BQPpM2LuPrNs7ZXFaYMTYDuqA8GlazDaCbgGZB1xqrANySThugj2h43gTwKYAOjLHGAJ7l6nVzdVsK3dTCsyOAJR7aZcfpPi+C/syaCI5bBKCrpM4t0EdzJq0FZfhrPBvAidDNW42ha/1mG1YDqHY41ysA/g7dpLaV2cxcCm8oQV+aNII+HF5v2HvvzPYJDQ15MoDBRBQlov0AHJ+lNr4P4Dgi6m9MnA6B+7v8JoB/Qxd079nasRHAZiLqAeBSj214F8AFRNTT6Gjs7W8EXVuuNuzdZ3P7VkE3mXSR1D0CQHciOpuIwkR0BoCeAD732DZ7O4T3mTG2DLrt/Glj0jZCRGZHMAzAP4joMCLSiKidcX8A4FcAZxrl+wI41UMbaqCPuiqhj5rMNsShm8H+S0RtDe1/P2P0BUOwxwE8AqXNp40S9KXJYwAqoGtLEwB8maPz/h36hOYa6Hbxd6B/4CLSbiNjbDqAy6EL72XQ7biLXQ57C/oE4TeMsdXc9uuhC+FNAF4w2uylDV8Y1/ANgDnG/zyXARhCRJugzym8yx27FcC9AMaT7u2zr63uNQCOg66Nr4E+OXmcrd1ecbvP5wKogz6qWQl9jgKMsZ+gT/Y+CmADgHFIjjJuh66BrwNwF6wjJBGvQh9RLQEww2gHz/UAfgMwCcBaAA/AKpteBdAb+pyPIg3UgilF1iCidwDMYoxlfUShKF2I6DwAFzPG+ue7LcWK0ugVgUFEexNRV2OofxR0u+zHbscpFDIMs9hlAJ7Pd1uKGSXoFUHSGrrr32boPuCXMsZ+yWuLFEULER0JfT5jBdzNQwoHlOlGoVAoShyl0SsUCkWJU3BBzVq0aME6deqU72YoFApFUTFlypTVjLGWon0FJ+g7deqEyZMn57sZCoVCUVQQkX01dQJlulEoFIoSRwl6hUKhKHGUoFcoFIoSRwl6hUKhKHGUoFcoFIoSx5OgJ6KjiOgPIppDRIME+x81Uo79SkR/EtF6Y/sepKdpm26kADsj6AtQKBQKhTOu7pVGgoKh0FOmLQYwiYg+NWJ8AwAYY9dw5a8E0Mf4cyuA8xhjs4moLYApRDSSMbY+yItQKBQKhRwvGn0/6Onj5jLGagG8DT1YlYyzoIeEBWPsT8bYbOP3UuhhUIUO/QqFQlEqLNuwDaNmrMh3MxJ4EfTtYE2ZthjWlGYJiKgjgM5Ijc1tJhuOQpAyjIguJqLJRDR51apVXtqtUCgUBcvJT/+Af75aOAs/g56MPRPA+4yxGL+RiNpAzw7zDyOjjAXG2POMsb6Msb4tWyqFX6FQ5JdZyzfix7+c0hA7s2yDnsI5Hi+MoJFeBP0SWHNjtoc8d+WZMMw2JkRUBWA4gFsZY/bMMgqFQlFwHPXYdzjrhczFVV08Ra/Fo1//iU6Dhmdctx+8CPpJALoRUWcjP+eZ0JMeWzDySTYF8CO3LQrgIwCvMsbeD6bJCoVCURzUxVI1+sdHzwZg1fa/mr4c81ZvyVo7XAU9Y6wewBUARgKYCeBdxth0IhpCRCdwRc8E8DazBrg/HXoy5gs498s9Amy/QqFQ4H/fzUWnQcNRUx9zL5xD6mOpGr1JjBOVF782BYc8PDZr7fAUvZIxNgJ6Znp+2x22vwcLjnsdKqGvQqHIMs+O0308Nmytww5VocT2aYvXY/3WOhzUPfO5v3ic4ZUf5+OMvTugMuot8K9IozepjzFEQtLdgaJWxioUiqKn3JCY2+qsGv0JT43HeS/+BADoNGg4Bn86Pa36P5iyGC/9MB93fTYDD4/80/Nx9QIbvZd9QaMEvUKhyDkjpy/H9KUbAqvPFPRba8WmG9Ok8/IP833XHYszXPfeVNz9ub5GdFN1XWJfp0HDcc07v0qPrec0+tr6uGUSNpZDjxwl6BUKRc7512tTcOwT3wdSF2MM5RFdlG2pqReWWbmxBgCgkb+6X5+wIEUgh0P6ueau2gwA+OgXmRMiUMfZ6LfWWttWb9Sbi7zdStArFIpAuPnD33y7DTLGMhJ0389ejc43j8C8VbrHymaJoF+wZisAoFmDMsu5+d8T565Bp0HDcczj3yW23/bx71ixsdpSV9joLQ59ZJxr++q5TqKm3mqqMbX9XCj2BZdKUKFQ5A7GGOIMCPlVdQW89dNC38fse99oaET48ebDpGV+X7IBc1dvwQm7t7W0t6Y+hnOGTQQAbDFMNltqxKabqYv18Fptm5QD0DuIc4ZNxGdX9EecMZw4dHyi7IxlGy3H1to8Z/zcK16jr7bNH9TF4ojHWU5MOEqjVygKiFgWPvzvZq/CuD/FoUWeGfcXut4yAhs5u3PQ1MXiUq19xcaaxCpSGcc9+T2ueusXAMB1705F11tG4IMpi7HzbV8Kz1Ufi6fcQ1N479BIF/SjZ+lxaCbOW4MJc51XwG61dR5hH4Le1Nqr62J48Ms/LPuOfvw79LzzSyXoFYp8MOK3ZZg8f21ezt1nyFc46MExgdZ57rCfcL7heWLnnUl6GKu1m2sDOx+/EGhLTT263foFnhg9J5C6PzTs4de9N1W4vzYWxyGPjMU+/xlt2b56k26jNzscs98hIlcN/finrHMJpo3eC8s3VmPomDl4btxcDP9tmWXf5pp6VNfFc+L7r0w3CoWNy974GQAw//5jhftr6+MIae4CIh02VtdjY7XYzhw0sTizeIXYYYxh6Jg56Nm2Cmu31OHUvdp7qrcuHkeZpnvBbDKu5Y2JC/Dvw7slzmunpj6GsKY53tO/jMlPJ5as24ZFa7elbF+/tc5om/XcBEDz+RzdNHq+o/v327+gui6OXm2rpOX3GPK1r/Ong9LoFSVDPM5S7KCZMOz7eQnPCp7ut32BiwsoMmG6nPz0eCxZvw0R1KPJhAeAmuS1VtfFMHnBOjz81Z+48OXJuN6mQY/7cxW+mr5cWC8vyF8aPw+AdVKyTrBadOfbvkTXW0ZYhHk8zvDYqKTP+klPjU85zo4ZXsDOHys26eeuj6O2Pp6wuy9etw3PjE0JqOuIplGKKYq/pvlrkqEMquv07WZHky+URq8oGW756De8PWmRVBP3y92fz8AzY6OYfNtAAMDomSsSQ/7Rs1amVeeL38/Dgd1aoFurRoG0MROmLtb92E8NjUOTycOAaBw44h4AQI/bv0SzBlHpsaYpSHSv62IMc1ZuwusTFib81uvq49hUXYeKSEgo6E2OfeI7/HrHEQD0SdjHRiUF9yaJR40f6mJxdL/ti8TfLxodkR+eGD07xdzyxe/LccLubQGIvWi21OZmlCZDafSKkuFtw96czuTWlpp63PfFzJQPmHfX+79XJmcUY5wxhiGfz/DkP752S6rNPBZnuO+LmSnufpkShXGN9TWubRAx7Pt5mLE06alSH4vjlGd+tCxO2lRTj96Dv8Ltn0xPaLkiquvi6HH7l+hx+5cgSt801rBMrMM6dTJ+eG7cXMvfvDlH9P4FOdJMByXoFSUH/zH/8NdqvDt5kUNpnSe/0SfM3v7JWjYkETatsQb45h5MXbgOr/4431O7zO/f7q6HFTOAH560bLrTWKofi7PESszZKzfhuXFzcf6LPyEeZ3h45B9Yuj7VHp02iYlKfx3l3Z/PwDFPJH3PX5+wMGVxkMlbPy3EHZ/87qnesrBVPPmR+wTgPyNmpmy3+7IHRUU0GbRG1JnkYE2UI0rQK0oOXpCe/cJE3Pj+NNdjTI2r3qaNySbqHo8OBb59CLc+8zru+CQ1fsq22liKFicbabDnDgS+us2yrcY49qYPpqH34K/AGINmSLpZyzfhl0Xr8dSYOZ6uzQ17q2TtjMUZ1m2ptXQEosQaj47603FS9YvfxbZ9O1GboNd8SPpNNfV4/tu5KdtnLd/kuQ4/bNyWtMHb3yEgt+EORChBryhKquti0uXudT61ti019QmhbJdPMuFSDt2soaWISZ1d7vgS/e4dZdkWl6h1FNevQ6RJvz9lsbEvKSyIkvFWRM1zujdDx8zBrOUbhftMZBEXf1+yAX3u/hrvTV6c2BaTXFNYy1y0TF203vJ38D5OqfTt2DSt4/799q+Ys3ITVm+uEYYmFgl/EdkKh6AEvaIo6f/AN+h150jLNlPo1dTH8eCXs7BgjbdEDr3uHJmw79uFiR8Xys1chwHorpL/+y6pVQq1uniyfI2DHXft1tqE2YEx4IOfdX/yymhqnNv97hudcm8A3Xb+0Mg/cPLTP0jOorcvxbRkMHqmvsjoxg+SowiZphoOZS6Wb7CNVoj8mW/SYYeqMvdCEq5861f0vWdU2hP1gPcOwS9K0PNsXZsyIaXIDZPnr7UIxZWbnCccVwsW+Jja96+L1uPpsX/hX69N8d2Oz6dZF7WYcn6dbWJS9DnueudIHGpLHnHP8KSd2K79rtxUDSxKLmTaUi2f/Ox7zyhc+dbPaIn1ABg+m7oUANCAm3Scumg9ho6Zg3USVz7TjbDWZcQjm7B84pvURU8ym7cfM4tX4szfqtR0kE3iemGmsfrWr7smz7TFwUX05FGCnufBzsDrp+S7FVnly9+X45U0QrUGxfIN1Rj86fSU4e2pz/6YEIo//rUG/e4djS+MlYSv/DAf381eZalDhCkDzAVPMlOJE5MXrLPVqVfa527xohaCdQJzqcNyft6eff6LP6HfvaNx1ZuTEtu21jj7WkfXzcGk8stwQSiprTfiBNOJQ8fjoZHJZfZzVm7C/vclV4h+NUPXyGXzDltr9WfixzNFaj4LyLuFJ85YRovU/tm/s2uZBi6C/uDuLbFb+8Zpt8GNM5770b1QGihBb2f+d+5liphLXp+S8OgAAHxzL7BUHk87aAZ9OA0v/zAfH/2yRGqPnL50Aw7QfgNNfBaA7oFy7jBd8/1+9mrse99o4XF2d7yQwE7s10tFI3JMB2fa6J2G3OZ18mYOM/bMKm7kwrt2mkKZpzPpk5j9td8S2xpXRITn3IUW4MsnLsfSDcnrNYVvbX1cOIn63pRFmLJgLerqvXeQMu8akaC/JPQp+lGqJ4xXGMvM9i8yc9lx0+gjIULERwgEvyjTjULOenf3QcA60ROLM/3L+fZB4IVDstWyFMwl9ze8Pw0vjp8vLENEeCN6H45a/JhuTuP4fs7qlPJbauqxdkttQqMnxNEGayzDfMYYRv04GfvfPxo//JVah4zlG6sx+DN5VqIwdOHMC/GVNj938+MVTVwSZwSqrfO/epLVb8OypQtxy0e/WbZ/EB2MK8KfoAzJOudyyaevFiTLIAB/LN+M2ph3n2+ZT7xoQndQ5G28W3a357pFZGK5KfOQt89Now9pJDQftcYaaMhdxii/KEFf7MweBTy2KzDjU9eivD119eaapHMvs76gi9dtFWp8QSOKGhiLM+vH/KB1uC2y3R/7xHfY8+6vE2aWK0Mf48fyK9GWJd34YvN/wOEjD8PJ2ne+7aCvTxCF39XPFSFdo+U1sX62gFqmTVyUOY732rHbu0V+4HbOnH4p2jzfG29OtLYxJBA6vG3+U8PGDwCMm4ImAmp9aPRm1iU72XIn9BNQzE65F0HvovWHNS1Fo2+BDZhQfiVuCr/lqR3jbhjgqVyQKEFf7CzTw7di6S+uRbdxadY2ScLSzl+9Bf0fGIOnxgQTbdAOb12JCj7aulgcr/24QHq8aLXmfCOphCno+4d07XYHlhwNxJfp2/poc1DDaaGZ2pIjhkYvM+8crk1Bg/uaY+P8n4UaPS+Q12+xdmJ2P/DEfAAnmNttEQta80wkcf+U0XTjLDT97k6Ip5tTmTgvt1E+vazWbdekQrjdi+tiWdhZ0Ic0Svj3H9itBQCgMenxeQ7XfraUPapXa2EdHZs3wKsX9hPu69E6O6ExlKAvdhJftPuj3Mq57+laW+qLb9p0/Zg3HKnZBGxK2pv5b03kgle3eTXWrpYvqHESzObkqync+EnHmGGOiEGz2MLtyaT9EkFSo2+FtehEVq+d/0Uf0fe/dLxwlBTlTCuXv/Fzyn4x+nWVQS704sanLRP0Its+gWHAjxeizcwXUQVvrqmFRidahjf+uY9wn5fQEfZFWnY0Au792644c+8O2L+rLujrjJBhLSutnYRTXQd1b4lLDu5q2Xbn8T3xyOm7u7YxHZSgL3ZMs4sHQb+Nmziri8Ud12Wnu26DMWYNJzt0H+CR7gB0W/py7mMTTWo1erw7fi3/l7R+p7C69sTQvKCPx3SBGkMINfVx/PDXatz3xcyMY5DwNvoRZTdjbNl10rIicwZvQ3ez8dqF9uORodKyZknZgq5G5WGubPI+bTPMNiLTjxeaN4iiz45NHFqUOYfs3BJtGpenbB+oTcbYsuvQdGFqQhIA2Lm1PFSwiZeJ1jaNK3D/KbslQjSYnWpVFNihUdIP360uu6l/zx2bolfb7Hj0KEFf7CQEPSfU4gxzVqaG1zXTrEVRhw6jLwPWpi4RpwzXH74/ZTEOe2QcfjAnTTcmEyef8swPlnal471gd5l8fJQ4LC1gvRZeox/2/Tyc/cJEPDduLlZvSi/hhikczYBgdbE4mpN8eT3BGr7WhNfovd558w4M1KwB1qqwBc9F/otm2Jhon0yj590i+TIxQyTIOggvdGrewPJ3i4bRjOqz06JhGY7brY1l2270F16I/hcAEFkpjqVzyp7tMH7QoY4umm4aPc9Z/XbEWf06YMSV/fUN8TpfC7rs7fAyh5AuStBnwpq/kgustqyxmCh43pm0EM+O87+Ioj4Wx7Xv/JpYiGEhHgNW/YHEZ89p9E+NmYPD/zsOf66wCh5T491Hm4lm84cDw6/13SY3Js/X/dB/XrhOn/DlsMcZifpcPXn9e1Mxxebn/igXr9zOknVJ18J4TBdsMdsrP31pcmJWQxw70WL4IWwIereRAYHhgpcmpWwvI17Q+9Oi7XfvrNA3ODI0GReHP08Iel7AdqdFMN8X2aIq87jG5RqaYSNawNvEdRR16ETLwJAajAxIjnyCgAEYdPQulm2vRe9L/JYJWyJCuyYViLAadCDxtxoOkdRl1cLmVajYvBD3HVKFqjLjhLE6dI0nJ8WrKvRRU2daljDx2dvDUx7JnjhWgj5dtq0HntwT+PQq/e+HuiRMFHZu+uA33P/FLN+nmL1yMz78ZQmufvtXLFq7Ff946aek3/LY+4Gh/YCVumfGys21uOyNKaiPxTFxnu7NYs/F6WfiMV39y7R5P/zVn+h7zyjHsiFNw5rNNZ7D7r4/ZbEw1reMNVuSHU3SdGN95UdyyTOuCb+PUWU3oistgVcipF/vttr0TB28AHDr9pz3M06oU4pGf7A2FV+V3YRTQ98KjuRGPsb92VJdh5/LL8Hk8kstZf9PsujoochzGFt2HSriW1O04uN2a4uQRNC7ebmIMBdOTRt8hHC/2338sNmz+K7sGmnHes6+O0qPTQjnR7oDT+wBPL57clS9bS3erL8GR2qTMOjoHmhaGUVLrMeYsutwZ/iVlLrsAwu3ieBMUII+XeoMbXHa28CU1IfoheUbqnHusInYsE2sXZkR8aoqwrj/i1nYcc7rWPDxPcCXN+v+70DCNDL8txUY8dtyzFm1GYwBfWg2dvz6YsTqk4Ikzhi60FK8EnlA3+BkiGfAte/+iu9nrwa+vgP41ZvrmGxyk49XzrPXPaNS8ntmiuhDZwmN3voxjZqZjEtygKYP+T+M3okDtWl4LfIfNIDzAitTUFe75P2UmVB4jdurHzYTXGEI8cQ5Lgl/hiraaqmzK+nulL1ovmPdcaNumY1elozEXMQVRW2KN9Xtx/XE1/8+QHhcpYeQAymeKMYtqyqPcJuS90Sj1Hvdr1OzxO9dtuqL72QuqKb3Vhlq8VLkAXHHz7sk29yTd6IlaFVVBo2AKtLNdUc0SPVis4fAzrtGT0RHEdEfRDSHiAYJ9j9KRL8a//4kovXcvvOJaLbx7/wgG59X+MnPz65Kq4pBH07Dd7NX46OfbeaCms3A6tmJDqCqPAIGhrsir2CXGY8CE55OFN1Wa2iqxrsdCWlgDHgm+hg6r/oGr41KxlJhDLgt/HriQ6i3OXbH4wwXv6bbfeOM4cOfl+CcYROB8Y8DH1/i6Zq21YoFHh+v3CSd7D7psmKDLvhiTP7KV0AfATSmrXgtej8ODP2OgZo4Xo4pEE1BL7tuE5mWyQv6JuTm6WILocwJNN00kirgzPq9DIQILDGxGCLx9cjsyBXG9mhIS9HoQxqhfWNxByHT6PnJYnvcHLfQFvZ5pt/vOhIvX7h3cr/x7YYQRzdabPFeqovF8S/DG2YfbSYOCU3FneFXcUTPVvJzx633iiG5gtfsfFsak7SH9tgheV2FZKMnohCAoQCOBtATwFlE1JMvwxi7hjG2B2NsDwBPAvjQOLYZgDsB7AOgH4A7iSi9OKCFhgcvFzfG/qEvg08JDPXmGcBTfRNJoqsqIsLFNgDw1wpdU16zRS8b0TQwsMQLNo/PwcmYRbOcushqf123tTaRzPnnhVZbuJ3r35uKz6Yuxd//NwHzuBWXmborZosxM3W3R7vphqcSqQHt4pLy9cbIwBT0/D0w2aMD730iCVHMaZVfRW+Uto1HpNFria7Hvl0/bzwxyeo8aogzvZYz92or3F8hEUamLK6MhsQTmnHxe1EZFWv0fCgC+6SlW6dFYPjk8uQIomFZ2Hoe0q+hOTbi67Ib8UDk+cSuri0bomFZGIfv0spi/uq6Q0MAkhAFLPWehjWyDJgJhN8GH4Hnzt0rsc3egYnmNoLCS839AMxhjM1ljNUCeBvAiQ7lzwJgjvOPBPA1Y2wtY2wdgK8BHJVJg9Ni2VRg2JFJc4sImZYw5j5g7APZaZdByjLyBXqqOdPfuzyiC28R5vDT/MzjjFns2FWVUdTF4vjnK5NSJjLrbL0HPznkZgt/f8piXPnWLxg/Zw0e/ioZSMspLowTrTIIDyuDF4jmfbIL+jLU4p3oEPSmuaikVEEv6xjixsjglshbODU0zho/yBboTMZTkSdwe+SNxN8RiRbthTBnuuEhm0bvZr82r3ffTmI3P5F54R+hL1BRpw/iK6SCXhwThxfivWku3okOQRlqLR5Z9slVt3dTA0PPtg6ulEaFpnmrnzYLj0SexsQT1mOXNvpxjDGLoG9WqY9IhLkOmP25EcIhDXFmvd+NyiOW67Lb6DNJneiGF0HfDgAfTGWxsS0FIuoIoDOAb/wcS0QXE9FkIpq8atUq++7M+eImYNEEYInDghRBrwwAGHc/MPY/ogMCaRqg23dXbKzGcU9+Z5mYrEskwyBpP7SLttDSGm3dHDSKJTX1dyYtxvPfzsWomSvxtFP41EU/IR6rRxusQVusBiGOPUns0WJf+MNrebJEFDJ60DzJbpsAACAASURBVEJUojrQiSiRwDO9PuptNvqetAD7aLMwJPJywnTDEwehEy1DM2xM2W7ycOQ54fn5e0GAcT+T244LTfB0PXwdMjTEhS6Mpgbv5m5pYmr+URJ/D3Yhvif9iTsjryX+royEhSue7YJ+T/oThLjFFHJvZBj20WZhZ1qEY3on3SftAtCtAyVyCZNsjMav3k8fcRGAU0Lfo9VXlyWby5ilc2xcqc8HCDX6WGonFtbIOoIWtEcjQi+ah86NNdx1Qi/Ha8qUoMcKZwJ4n7GULs4RxtjzjLG+jLG+LVu2DLhJnhvhuPu1CQtw3btTufLBBTCqrovhjQkL8PuSjZacpcO+1/3cQ5r7QnbzA93xjYPwxKoLLfv40LVShg1E9NdX8GP5lfih/CpcEBqJD8sG4yBtakpR+8teHtHw+5IN2FJTDz8KfQgxfFk2CM9HHnEcCbi5HfZu577IJDnyseUh5TTecsFK0zg0jC27DuPKrhEeJ26vcSzX7Ea0DR+WDca5IXG4Yxm3H9czZZvozGHEhG1K2uj9CfqwRNDzGml/7Td8WDbYsr9ZgzB2qEpdzMQL+n21GfiwbDAuDg1HLM5w5aE7oW/HppYQD2f32zGh8R7G2bUB4PBdWjleA4E5Bz8zTDdH/azPO4nMWUf0am25Z1XGnIHQc83WiTGQ/s26yJQGdWswvOxW3BcZhvP37+RYNlO8CPolADpwf7c3tok4E0mzjd9js4j51J1uvPNDuf3j3/EBP2kqE/QLZNl75IyfszoxHOU7/iVGSF0vLw2/twHb4mnxjf2jj9ck7fk7k97htCVr4LEN2+owbbE1xRsAHPfk9+h150ixz78EU/juq810jOMedhD0bbEab9ZehVZwjrmiSUw35j3YU5sj1IhNzb0RbcMJWvLZijw77HWKJu66+XDdBJAQMG5oiIMEbdKIoRLVuCfyktE2Z8zrjcaTo5uzQqMxv/xsHK1NtERubEepYTJuOboHjt+tDSbcfJit4qTu1wb6O7WztgiXDuiK647YGa0bl1u+Uk1L2unPiHyH4WW3ogk24e4Te+Gk6k+Ajy+zVG+Ztxj/OGjkrfKLtM2vtaLU9/nMvTvgxQv0CVyCbnYBJElbUgS97o/vaGKa/BKO/llfAd6p1oMiliFeBP0kAN2IqDMRRaEL85RQiUTUA0BTAHzk/JEAjiCipsYk7BHGtuywdi6wXhBp0JSeju6EPjV0Wfnh1/urB8CfKzYn4qTzmkgiZgu5vDTQvajF272zqLZh4rfMpv3vt3/Bqc9akyPMXqF3EI2wFb3ImydNF1qK1qQLZ7dVkzIfbAA4OzwajTb9hdNC41L2mR9/O6xKxHKXCXpALLwvGZBcG/FE9CnhcXbMfY0EQtpvKFuLrdqodz9tBuxPNiyZjB1ywi7YS0ua4NxGR6ZGH4kn57PuiwwDADwTfdw18UeTjX+Atq5F68bl2IdmJs/HCUOzpRriiXgxTSqti5TCmpbwSmk+4X70onnoQKv0MMIjbwZ+1ec2Hj5NEhtmgjw8hJflq0SE8kjY+M0ScxNC00081T06rNnn1Wzn/PxqNN2im1LjlD1vGxNXQc8YqwdwBXQBPRPAu4yx6UQ0hIhO4IqeCeBtxqmejLG1AO6G3llMAjDE2JYdnugDPNZbsMODRu83uIu0Y0jPdl+XSPzMhYw16lq7pRa/L3FeoSj+zP3x1e/JgFyaMXSPc+6IsTgT+sObEQxfid6P4WUOmhTHN2XX41vDHOKkHQPOqyqTXiWp981kfPm/cVDIGq/dfryMvTo1F253igXTrnE5+nZsiifP2jNlHxch3/G8yVKp5ZrQFpykjbe2h+JCIb57uypLWx0tGkh2hOG4OKWma9iKN04Bnh8AzBmNd8ruxr9Cn+vbOUF/3O7tAej33lyFetNRPSymG01LtpVitUb7UjNMnbpXe19hC/SK/JXv16lZ4rq9mm40gjEZ6/6cGQpA0AMAY2wEY6w7Y6wrY+xeY9sdjLFPuTKDGWMpPvaMsRcZYzsZ/14Kruk+8DSbnXwgJzzwEWof6A6sEIeA1Yu7P8APf16ME4eOdy0HADHDoEsWjV7no1+WYOUm51y2Ipc7v8S4SSWRRl9bHxdqqSZ7auaiENG9SW4bEvb3GngR9PyIJtkOZy45uKv7XZNkNLJr5k9FHk/8Pqh7C7x/6f5oLQi8ZX740qiS2IzxZVdiV9LnZ3g7P39ME9qcctxV4Y9T6mteGcHf+7VP/H1WeAyON0xQl4c+xtORxyzvjtlhhpk4BlCXKfcIt1vYsBDYpCsNO2lG3HtOGA6co9ehgSE6dxTwZF80mvQkemlmeGpCiCih9JAx5aeBCSdZR1zV371NPJqDYP38WmDUXfpvQ5nTCGjftBJHaxPxUvU1qYkFBH70dTEGxnvdOMggVggafUkhE841m4D5SYHcY+N4RLetAH50GP7JNHruHM+8NxyrFyWDbvF5T0360Gw0xuZEVEZy0EydsGv0SYHinXpO0Is05Zr6mPQWViBpYxe1m9cqzwv7m5A8RPtVar5J2t71dvIrPwkMB9smk822vXvOTjitzUqhXdt6gPgjtI8EjgtNTPw+spfTZKF+nGxEsJ82A+1oDa4If5Io3ZPmYwesszzLNczqPriPJguxwTCwh9XB4UnDBHVD5F0cE/rJMhGYWDAVEysWbWbqnfTeNAsNnVYNG/ctMcrg/TPqdLfGPh2qgM+vAdbMBkbfxbXYMN0kBuKGEiQyUG5ajrLV0719KRuWAMt/d9boJw8DvteDoyUEOGNotvZXPBN9HM03/wksmmg9RpCKsy4WF8+r1W6xyBoAiDt1PAGRfsrzokTyOrx5BrBgPFfKtOk72DM92PS/LtMXwHSqfhMAcNGrk1FdF8fOrRph5DUHIYx6fFR2JybGe+AFpn98Vo3eu6BP1eidNUcR9fWxRM9gClDeS+X8lyZJe44HuUUnGliKWBZt88qj0WfQqX4FHq0/NWWfvZ3Dy25J7Ds9NA5nhMemtAMAen99Nio2zAHBxdQkEQpO97V/V7G5BwBaNowA6+WCPukGqqFLiwZgjGFE2S3YxCowqO6iRLltsK47kNr+Wdz1Xe1uLAbSV8YaGr3EdKO3sR7vlQ1xrNO8b4d1123wogVT7RqXAVtT72/CdJOYW4sl2tdxwXvWwk/0QYe6rViLhnDlUcODqcEOzuVMEoI+BgwbmNz+km0pkM39moFQH4+LV9F+fBkwwzryiheK6abouLetHlnShJuMjcUZDrj/G0sqNV7IA7zQTMemLz/GXBj1x4pNmLlsI1oakQG70LLEJA8vRz+IDpaf34ZsBefE8is8B+mKcblCTQ2VN91ctvwO6QihByXdQsVufpm5o3aiZPCxHrQQ08v+gZ1pIf4Z/gKA2HTVSUtNYNJPm4nJZZegYoNu3hH5zlsQCPoPLt3f+XoczHoDq7/Cydq30uP5juuoXVsnqmpEVu3Z3lFI5wxeOR74SB7f3475vENxuReUp1j1xn1rUmEIsddPSS3DmHDExECofOtvOC2mP1viEso02LLAWtgYHYi4PfwavogOAr5/DLifC1Tm1fvbNDdJFns50W2HRjYHCuP9XJGaf9i+tiMblKagr9sCTHuH25AUAtV1MSxZvw03vT8NACzZhkzMZeCrNyU/roHaZOtklwfTjRNHP/4dWpG+UnUVayJMSrGrNt9TXQCwq83bpQG35Pv00FhPdZDgA+BNN0eGJqd4HRyi/YIKVKObluxMnBbupAvfeZwXGokGVIMbwslnHAdhgGYdQovMGceGfkILSk4oN0Vq3H4r1mtphK3QCAhl4Kr7UOQ56SRwytxIPGkrH3p2n8Rv+/08LCRZDLh5BVCbeo37aZzA4d7lhB+9xHQDAH8MOVK6LwHZRsU1ArdbFhd2pASG0ILvcGP8f+hJ80ExvdPRwBDyIXT/L/yFvqBw1J1ANefMsDU1V3EKsfpkh+DTI+/WY3uiQ7PKlJAjAIS2+g7Ns5M+kKc0BT0AxESTSSxxn03BunJj6gttaod/LEu+HC9E/4tzQqPAGMPI6ctRJ1gNZx7tlWaGwFnLGuK72bpPstB9ywNnh7+R7pO5XtpfQpEd3PSQMOEzPPWlWXgp+hBmllsXaLnZ6GUcv7s4vgpg7TzM69mMZG7QXWghXo4+6HoOO00ckoXoJ7Ney9DI49CInN0UXQTDFpRL78cpffQVoQmBa9FYk205bU9r4o1+mj9f7Lei93LVJus1vay0mEPoaC+Cz7Q7O5o/mXBilH/WIzhTHIEhxDhXRq7dzRoEHEJj21pOo/drdNTlB+O9bhICPlXQl0U9xL/PkBIW9NwLwZluTDlqj/PCk/DztU3U3R15GV/NWIF/vTYF708W+Osb57AzoexynCrw807kG+WmSuwLMjo2r5S2085pnOZeWZf0YpV1Hfal5ftqM1PKHDvL6kjFu5c1JbE2LBL0/zkxdYWnnSZeEj4geT1bWfLj3kGw6MULfKwZ57PpdNcWI6QRNDCMjPVFzc6CsE8uo7ptKJOOcPp30Zfl1zNdAO7VRjyNdqhp+w4CgTCO/vBfpwPc6zQ19RmfiNe2mOfVUq9v+OX7CotrxKAxTsHiBbAXLd0PW1ZbJmPTgXnU6EX3IGhKWNDzGr1xc+eMTkyQmM8uJXIkkhqjyB49d5UepXBztdj9zEwMwq8QbU3rcFf45ZSyZho63g5u99P1E9Hu3vAw4fb9tekpsVqA1HjYAwXDf8uHBX0k1A6rsBf9IQ341ZWWoTfZ0xR68Sd2N4f0prnoaGQH4lu/pyZPKZgRNiHIQHosFTDUIYSyCsGwe+4YYPMqqSa4lZXJRzjMTHmon6djA+P+RxoIywUDE/xyKu6m0ZPVJPOXZLTJ4mKvJuFoXFcgmqxMht0WLVQKjK2rrZOxflg5E1g2DQwipUci6NfOAxalZiALipIV9Ks2cENyU6BNGApWbdVCRTZ689GItK51W/WXsHG5WPtctqEaW2rqcfTj1vjrG9AgpWwisTT3GNZusb7kIYkftwhZqIDdtbmWVGsm6UTLY7FajC27Fh+U3SVdpDW87BZ8Vnab9f55sK06KU7mB/NZ2W04MKQnCOGH+GYkwsCxNYpBX6msIa6b+EICbezd84BXTwCmfySschvK5Qu1DOGSmFyvMd7jsobWtvg2Jzjge1W4S3cQiljLVEgik7O4eJ2CZH6AwFCxaT5XLouCfvPK9E03v74OPHcg4sya9Uv/TyLon9gDGHZ42s11o2QF/djpYk+Teautmm1KiGAk/YxFYmydIYiryiTarLYMS9emmjQ2sqSgP0Ebj/nlZ6ORIZx4Qf/2pEWW4/zkz3ZaYdpdS70fITcfcgGheE0inK7M9m9iCRLmYCrzguhZhCSBtwLFJtTa0lq0GXcjNMT15xYSJ9TAqj+AsNhuvNXBdGMK3Rg07Lz6a+Clo/XtUZv7YJAa/UjTDp4MzeuIW8egha3tk90jyWQs6uUavYU0vGE8s3kFNxmb3r0+ff6dgg5dJOiV103a7BfiV7Umb+55/7MudhBp9CZrNqdOSG01Qgc7Zf1asCrVXtxDW4RDtZ/RiZbhurDuC2wGhXJKhmE3r6SLqSEeqCVDAaSj0cdrk/fEqd2A1XWx/bIv0RBbU2KaJPbTKnTZNNmxruM1a8C4U8uyN9RNIghBMOstaDCyMYUFkRoB/eMNiQV9DJrcdBNPpjw8ds6dye1lNhPR/O9dW+6XhlSNA0Kp7n8pbHNOSoO6rcDvHyb//vVNcblVs4Clv6RuF22DwJtrU6r7bGD88jqw3lC60hw97bZ+dLJDT8zFCr65AJIYuVGyC6ba85H1uJtr16RENvoEgiFqTZ0ZA0b+8C9/8xcAqVrMi9GHAQAL4vqCjQhsw3QBaTrhpMAoNfysS3wqIbyW7rYYq4JL5LHnjAcwJNIf7c55FXg1tew30WsRnSu/p4eEpuKQkC1kcr1zPtdAkGivbRqX4aAddgAiksly0hw1Tk02GoknzXkh/h2zC3qL+3AwnBD60b0QAPz2vnuZmZ+Kf/NsWibeLsz/oL9vjEJJN+C3z3JvR7qsnKH/AzIaPX146X7Ai/yW7CUXcaJkBP3KTdUQrndb9BMwZ1TiT7smVSMw3ZiIhtfmCIA5mCK8rka9MPwlAP0Dq8JWXFB3k0PpzCS+yMzSq94hlo+Eq8MfJH5H4WwjrbDFdz9553Kgi3jVaDSD7EpZRWKPjhJDi0YVQFQm6EOOAkJqo2ep8zb6CT2s/MwVy1JzFOQCDQyMtKSgXzc/NyfOxOzIvz9/jQFWiIPrZZuSMd3Ick/il9ctf/LCe8bSjY6mG1Hfa/q7Owl6t4iIoo5gQGiqcAWrGa3P02pEByrYVlTBLfm0O6eFv038PjmUmvDbck77qtNy9wQhhYfkWW5crI8UZRq9FnLU6E3PoRR+1rM1pYzy1s7NirkmLarTc2XNHJYTM0cKGxe7l5GRGBGSHkdHSPa1/JIR9MKkxfW1KVoVLzCPeeI7R9ON06KYr6ZLhp3wF1+GZ3TZDSnbghL0APBo5OmM6+A5NvST4/4GZJvjKEZB7zTxSCEX041ciXgter94x1o9dEe9/dNc/QcwJT/BX1PIpreLAxqY1cbdto+8cKFgeX/yY7YBSkjQixIiLL57F9TZNPYJ5Vfi1nBSyx/z4QvSOp0ey8LV8qXzbhq9H8zrSrfz4GlPWcjH60ATe3iBMoeEzYWKo8+nBkQq5Pskgl4eaTLJAZqHSdF8IfFzzzYEW2wcWSdbSJiCnshbuPTxj7uXSYOSEfQi2tNqVNemvpQXhUckfl8Qlie8corP4pxhKI7mkCcK2VHzLnBjcYYDtWnoSQvcC7vgFNc9GzQmm6koFAWqvacaLAgcNXoNiKauj0gwSa5EuLFXthaABUE+NfoCaIcv/Gr0X9+RlWaUzGSsFJeJFCeTiJNm7uSzXo46PB0NpmfeVF2HD2TDfJ/kWtAf0aUM4JcFkAaM8J9qMb+4aPQSX3lsWwsszl4ytbySzRWpDhCY1RTrd6FXPuDbGJCrdDqUvqB3cY1yEn4Hh6albPu+7Cq0wRqsd4h//VP55d7bZ+MuW/aljduCWxSSkwVGHDs3jtkEPekrDouJd8+T79NC+ZkczDf5NN3wilu2BH0oGuA1BmfGzYSSf0s3b3N+YH7D57an1QgRQ3O3qIdpcr4t+9Idx7sHA/OKGUQtV6REQJz2rh4Hphg41imolwFp0gxUJY00cmt2IQDE4kDHA4DWuyFrQjQsmXdJhx+MhPLLpkpDYuRC0y95Qf/bQmd7eBDeLNnkmN5t3At5JNemG82uFa39S1ywQJgbb63/oBDQyUMeUtKURp9DGkRJH6F33B+oaps9jT4sCdnghKzDLxDFpuTf0kZOeS2ReUKMYiLXgr7Vn5Kl7wJWsyr80PRE4HTBstkcETMz/YQi8DRxRpSTOCUFR55s9I+c2pvzvKHsCfp0wgbL4vn45ZiHg6nHRskL+gg5DzNlER9zxaJ4S+cCacbCFlHIoxcyA2rlUUNOpHTTIt7aQTmy0TfZ0b1MLvHj7fLvaUAHcXx5z+xqpCE03VXNkVSA34YFLY1EIOmMAkz468iSGafkBb1IuJmpAgE90XE+ibtpAgG+zLm20ftBKwhBb5xbC3n74HJhuilvIk/cYcdr0utM8SPom3YE9rk4s/PtuJ/+v7nSWM8cHqxGf8DVyd/pjNIkAey8wQv67IwQS17Qi8Sk+UEfrE1FZ02yFD1HdGQuibsDfJnLXEY3+UTPVkW5ndxss7t4e8ijRpcLQe+no8+V+55vG73RrkZpzjeZz8MU9OZIaqX/WE1S2uyW/J1r043FBTM779N2IOhTX34zjsgRmjwsbtDEWJof4azPg21IAdOoMppbjd52rkTCb8+mG02u/VU0y7BxBr46+lz5afscZTrkS/WEKXgTgl4LvlPjFQyvHb3l+Azaw3vjKEGfHiJBb9pic2nKcApF7Mh750t3zYoE53pZCPRu3yS3gr7aunp5a1lLxFrtBpz4lLcP19GPPiCT2ynpr64tHDIUyglBb9jos7F+ge+w0zHdBGVizaeNnoiOIqI/iGgOEQ2SlDmdiGYQ0XQiepPb/qCxbSYRPUHpZLsIGFPQh3MYGleWdi8TOv5DFg2vgHD6IJvvZPlTy4am5oStbRUVFQhd+h2w02HeNXqZqSmIVH+DNwA7H+29vNO9O+hG4Ih7Mm9TOpjtSvfZpmj0WRD0/HPM69qIPAl6IgoBGArgaAA9AZxFRD1tZboBuBnAAYyxXgCuNrbvD+AAALsB2BXA3gAODvIC0sEU9NFcafRnv4tsPMCKSBEsbJZlYAKAA23hELJt87ZHO7SZRayjLo/ulbL2+o3Dkm3hEooA+14O9P0/78ekY6sWkqlGb9wbi+nG53tysFOuB1ivNa13sDBWwMrwckX9AMxhjM1ljNUCeBvAibYyFwEYyhhbBwCMMXOdOwNQDj3dUhmACICczn6KvG7MpA458ytvuXN26s3/4MgdJ0GvhZMeFSZBCPq9/iHe3mpX6982rduSnMWr141smO/X19x+H7xS3hg4zAyE5dBmLax7q/g5T1ArRIO20Wsh/3VVtnA5B/fs07HRB0UeTTftYI1YstjYxtMdQHciGk9EE4joKABgjP0IYAyAZca/kYyxmZk32zshgTDPuY0+a1pqkQv6UNjmQxyQRn/Av8Xb7ZEm7Ro9/5F5Nt1InoHfxNXpfuAnDk12bB0dhLgpvPycJ+Lw7HwRlI3e1OjTcMPVXMrzIyp72kYvNO7g/5gcEpQECgPoBmAAgLMAvEBETYhoJwC7AGgPvXM4lIgOtB9MRBcT0WQimrxqVbAx04UaPdMvO3eTsVkSyLnS6Bu4LOpyoswhBZ7dXJHOB8xxR935wGUTIR1G2wW9TRh3a8UnRvGi0YeCM7nUyvMbOLdBAyqbAZf+oAt9GWktAgpYo8/URh/LwEbvZobSMhT0HfcDLhoD7DTQ/7EW8qfRLwHAd1ftjW08iwF8yhirY4zNA/AndMH/NwATGGObGWObAXwBIEXtYIw9zxjryxjr27JlmkJFMustXDAFDc2wEdFc+ZUXezyUHsemf6xTrlMtDKtQzkzQb2ANgB16yD0g7IkqbBp9g3LOF9qzRu+xvS13cd6/9Bdv9YjaAACtesmToADBafRpZXUKSKPfYiiB6XjduJmsMtXoKQS029O7x06OJ3y93K1JALoRUWciigI4E4A9rfvH0LV5EFEL6KacuQAWAjiYiMJEFIE+EZsd043E31hkh29GG/Fz+SXYV8uRFYk0RMNZEPa50Ojb98ts1Z/TR2PXsjI03dSbUbdlgt7e6dg9YyyeFxna6O0cdru3cr6xtbPbkeJiCUHv4/6KhFH7fsnfZ78HNOvioZ6AbPRmzlXS/FV1yjD3bFT8c+ywj6/mpRzvhb0uEG/Pl42eMVYP4AoAI6EL6XcZY9OJaAgRnWAUGwlgDRHNgG6Tv4ExtgbA+wD+AvAbgKkApjLGPsvCdUgFfQgxrIy0x7MdH01sqyLnQGee6XOut3KkgWI17uV8k2VBv/9VwHmfZFaHo6AXmG4yCBKWzLPKCfoLRgDNu+m/o3aN3i7oNfFvGV46pkZt3etJB00iuGX3L2G68fPOCDpMu3fKxWOBZl1d6glIo09U51OjZ8z9veI7tT3+DjRs7b1+INker/70xzzkr/4M8XS3GGMjGGPdGWNdGWP3GtvuYIx9avxmjLFrGWM9GWO9GWNvG9tjjLF/McZ2MfZdm7UrkQj6CMWwOdwUG6Kt0qrWcUWr1xyo2TLdEAEDbs5O3QDQonuqcPSLH0EPj3k1JTxwmmFW4LXMZl2S8wQpNnrbO3PILda2uKF5sNFXNnevJx1kphjZu5aO6UYE/8wIutePW9C1LgOAHscBxzzI1eNjzsAu6P2abljc/Tnxk7VEwD+MdKMDh3g8ic/7Ku14VFAzZxxs9IxCYGnaxJjTJI7bTL5J1kwsBAwQrl8LqHqH6+tyiLc63Gz0AXrdNGloCHItpAsgs07zHKYJynwX7J4xjTlnMk+mGw9zCl7fEb9oMkEvaXcoDY1e9E1ZBL3Ha4uUA2e+Ye2A7d/VsY/Ij08Z+Xl4Tyzfu0+NHgCad9UXrMk8uIqMEhL0DjZ6LQQKpSfotZCDoPfaeWRTo/fLyf8Dyhq7l+PrF52Hv6bjn5DX4ctGn2H0StHHTDZN7erfgLPf0f92TPzt1UbvR+AIuHEecEMaCVkSZm/b+WXnk3UMvs/r07wlO9buq973/4ArJuvROgHg/7hMa6K5HNcOi+ukGPPQIWc4OZqpZ5G9noApeUEfQgzRSBiNK9LzCWbkJOgLQKP3S6te3g9zuj7+mpp2lJdzcq8MeDLWUp/5nVvqI93MYHY+vI3+ZHtMmYDCFLsJkMpmQAOXxTzik9v+59qU0oawHtZBVB5w6IxEo2SS/Aawy/GSegTlRfMzLbolRxFNO3Nlfb4nh99lHY2wuH+N3o2dDrdX4O/4HFPygj6MOCrLy9C0UXo+wczpBfHsSiW5zZlq+ul0IKEoPL+Uju3jFxc53Ieog0Zvr9+L5uWEyO5LhITAMu+XWY73utntdOe2ifDiR5+uG11DlzmlhAbpYTL2pGeBcJm4PACc9LT4HCLTjdOisj3OEdcjPFZyX8zvmF/96tdG3/9q2wbm/hz8avT7X+WvfJ4pHUEvWSQTphiaNaxA7/Zpho11stF71ug9CnrfoW2ND6HzQd4PCYV9dBAO5chBO+PxY7ph8eA0ehORYDLNcXavG9lx0jIBaPQyrpzidnLjP1s7Xe+B4Lqkq5dFgl4UJsLWkcrg98vCDCQEfTjpEmk3n3ryurGZblwXTPmM65MyIhGUabcXcP1sf/VmidIR9A4aPWkh9Gzf1L2ONnsINjq9vBkKTLuWBgKqHAAAH91JREFU4abFpRxP/o/zpdE7+T971OhdTTc2YZJJohWhUCVOM5VoiEIC8qNPt+NyW7Qj0+gH3u1SseC6dj7Gc7Osz91+bW6CnisvfQZmToBQcgGYfWQhCz1x7H+BQ24V18k/p70vSlWOfM83CDzGeCpbAKe9DDT0m/VL2eidkXjdaDC0RC9DaPNhh8uBXU/VNzlFpctUo7dnpanym4EnjYUooah3jd5st2wy1tzvJOycFqqkHMeA2q3e2ibCLRiVeR1O8XcSZQPyo89a8nCJoG/Y0poWD3DPSSrKd9qkozhEsn3Ow7LP7b3yMArseZL+fygK9Na/wZR3SGa66dAPOPjG1O3MZro59mGg+1GpdfoJ+SCaY+A57tGCyvVbBHFuPeLkdeN1BWPi5eG9P7Ip6DnB1KhNqp+3a722obMX/ETmc/pwTQ8ZN3OLk1AV2ejrq723z6SiKbBtHVDHLYRLXKctxALgLXaPZ9NNlmz0rud26OTtbbd8Gx6u66b5uitquAz44Unnuq07nev1otGf8ITuux6KAEf+B+h/LVBuW68ie9+ko0GW6h1Vb1vASCHghjnO5jzrAS6709TMldeNC1oYiEgEpZeFLaJjAJDTSje/mrGdUERPCAFk6HnhA6fclic9a6veyeuGc3GTdaIHXgc0clhhmFI/02OS9L1QfoyI014B9v6nNQ7LBcOBg25Iuush2VyLWeT014C/Pe+hbQLMJNVSKLNcoo5INHp+XwIXjd5ORVN9oZzMFJao1r6ymPt9+F3AmW/a9vMavUThCEX0UQmgn79RK6Rcj+zZyJK9iDoAe95b0nQzY7lP1+PkBpe/80vpCPqKJsA1v4v3UcibRm9+lLudliONPgr08GMftdcbsNdNwgXPrN/NR9w07Qjuba+/6XHS3Vw07W5woTBw9IPyY0RUtdUX3PCjlR16AIfeZrtHtgnMVr2BnicAu58hapzDCTkh6/QMog2zo6E17czZ6H1q9EH6eacIVm7fHn8XBMPzOIGfck6BZ5FIeMuUMtF2u0bvl5R5AxczlsgslG6y9DQoHUHvhFeNPhTWh63HPpp4uUgQ/TJBEKabRIwMb1XZKvZX/My3jHsRgHslv7hJ9NGafumOdUieie8JTL+TywAGLQL+OcrfacyQF4kOzqWdsonom+3BX31y2QT40uj9mm68kqLRu3j3WEw3fgS9QKMXCnpum2Uk5eImmhb2Oh00+luWAjfOTa3iKkHE0izN6ZSWoJc9PAp5X4pe0dRwQTQFcBAavaRdoai3kYPfemUk4q7IjrNtT0yMSrxuEoJeYG/1EltFZKMXbXfD9T7YvG4A3e7rlFgjHE1dFHPRGMMcxIVXcCIsifrp5InkhUg5d24vGr1P041XHD2kXNrlx51RtPpX9F3yHc/FY7ntgrL9r5G3zQtSuSCoJ9pAHDMqUmENEdK0kx4TKAuUmKCXXE468UY82egzFPTpJIOwVqz/5zXZgZMXjYjNDlkfeY8TV1u+x32m4MjWSmK/9R54nfXvFjvp5qBEfS7a17r5Se+OFt39ndsNxyX3Djb6IDV6e1A4SxNcNPrG7X2cyFaXzHTD19mqlz5vA1iFshnGuawR0Lp3crtTTCYhMtNNBrljj/xP1tIYlpag9+qv7qkq4xjHeCgZ3r5MH6r5cu1+BjBoYTKGzY3zgP8TmCXcBJ192Fi7xfncXl0QvZ4v3Y8kiAVgwuJc23c7U77/lqXyOvY8T382Lbr5O7dXRPc3mzZ6S72GBu01NC9///2s/RBG6LSdc9Ci1M7D9PgyF1zdstQ6QWwqWud94n+UlXLNfl1NBWQrJhZKyb0ScDDdpK/RBzIZKyMUQeIF8fyxSChvrNuc53ytx0/ZvFJQyMXvvrKZ7i3R/Shg6lvAfpc5nJC8yU3RPRo4RJ/Ia9QaKSsY0yING72n8lzbLWYem4lJ5ha76yn6Ob16cvhrnPGfB42e+dDoT33JexP8BoXj16n4wYuN3u6CCeiRXUORZGgG+3MyzUd+2wMgLaXk8LuAUXfaNgqcBbLAdqLRp3EDTfts+70dTudSr1tIg96n+R/ydUpJuZukZXdgv8uNtjloek7t7n+17rEy8K6kG6LMs8PMkuPo/y84tmln4MAAUxNkS6O3uBIKOiS3jt5ub+0ywOf5HZCtjOX3mVg0epc273qy9zY4ed14aZfXNtnRJDZ6O2WNgMMHixeEAUlB7zeRO5Da0TjNi5ikxOCxoTR6j0g/+DQEfbeBwK3LgW8fBuaNk1Tr8mBOHJrqsggAt63Sh73hcmDlDP9tS5zfaaLTaTIsCM2BgMMGAwNucV7kJPzgg36hXa4nMRfrV6Pny7PU325zP/bJ2HM+lPt6+8VreAogYNMNdx8cPUQc3j9RSAM/yLxu/FJhhkVJ455ITTcZ3F8l6D2ScZRI20OKVPgXpvbz2j/2E4eKNYy0zBZO53cQAEHYaUnTBZ1WDjilSfQj6NP9eLNmo+c1eq5twhDIAuyLpTSP6zk84UOjFx0XBPYwAq5tkJkp/D6XEBCr83eMiBOeBKb0ATrun8bBaZoZz/1I3vashTMvNUEfpOnGrU7A/UPfoUfyd7QR0KA50MceytWn6carq1y2NXqncLWe2wGxScR/YzwW83ndTbg4+8LQ7D4FfTbw5EefBffK/temodHLFLE05k7qA8j73KC57i6bDum+q10Ptf7t9TvKkNKy0QdpunGtE84P5vY1ul+syaCFwJWCBRK+PzyPE2tObav0EMnTDVlwqzZ7AHes43b5+ODT9rpJc8TmRoMWwPGPG38ITDf5FPSOAeccTDe5WprvpV3JHf7q1kJAXRoxkYKgXV/gjrXIintlFjX60hL02dDozY9E9NE6uW3aY2hrmrNN16uG4FU7c9K2zn7X27kckWgimm1xmi/TTZbdK9N5D0wXPOFkbJZCFHvBz2Ss31g3geBkugnARp9O8LsgIPI+GewFy/ecrUinpSbos6HRm/Y0afYi/u90HpRfTcCrRu/Qlqq2Hs9l1uWmnTm0iY+HU9lCXl9KPb4aGHA5DtPrqucJ3EaPGn1WhaoPO7wXrxvXNID2U3iYn3La5hYuwa3ufAl6k5Y76/9X2EfHGTzzrIW0LjVBn41haULQGxr6gddzp7PdvnSG6ubEbKXH6JVBaPSBIJlMs0fh5E0MwmX7AdjovYZASEfwtuwODN7gITZ7jvEzP+PFdHPG6/p1esXtWbnNEfnx7bejhawhqXOJ2e6qtvr9Ei2k84Olw1OC3hvZ+PDipqAPpZ5DFFXPL826AMc9Bpz+irfyXu2tWXxp9Pq5c0crgROf1uOHnPSMvaDxHxfp0ctzOv1V4LKJXhsTcDkXPMfkyYGZRChwszQZ213Q2ekncG+DZVumpptQ/jX6FAJ41kqj90g2hspm3GpRkK6gOpa+//CecoyPue5Xow/Krig6d5+/64tTKiWLxJw6yARc+3qeaPVa4qlq59wWGYG9Hy4jBHMlbLMuAZ1PgFMwPCcbfSYCiV8T4mbO87M/HdNNv4v8HZN1Avi2lNeNRzL9kEXH2003OVqyLIzJfvBNQLPO3s4f6Evj5hPtdKhRrnH75DGy5+TVj/6U/9nMDAWm0e9+tt6+Bs3F+wOBrG0R7TPhA3Zlcgt8Bf5yeGfsc0R+v1stpAcs82NqKgaUoM8jdUaoXjMehkgTycYDkg7jPGpCQQ4DfblI2ohUAKcMA87/zP1+Zd3rJr3qUzDNBk75cN0450Pg0h/SP97Jnc/c16wLcPRDyVAV+s70znfMw8BuogQtbu3jCEf1d+GCEfbC/tqSz7kRKem+XNxx+TbdENFRRPQHEc0hokGSMqcT0Qwimk5Eb3LbdySir4hoprG/UzBNzxFmBEcznrTIBNFyF/3/IE0jnoRIHm30vU/zUfZUQ4sTCHrLPUsjCqLwbxuJcwRsupFFPOz1N/cqdjpMD6Vrp3VvoMM+HtpgavSiUZCxT4sA+1xsFSDpCsl+F/kL9y07T+9TgcZpmt7c6s4J9nc0SHNo9r5Z15WxRBQCMBTAQACLAUwiok8ZYzO4Mt0A3AzgAMbYOiLiDc6vAriXMfY1ETUEnFI2ZYsMHoYp6BOCV2CjD2KxhB0vacby5XWT7pA5qJW5KW6tubbRG/C5Z00yNSdc8r23crK4Mfw+p+Oyjet5MjCBZt2jLE9k8bq8hEDoB2AOY2wuABDR2wBOBMBH47oIwFDG2DoAYIytNMr2BBBmjH1tbN8cYNtzg13QW95PgbvgeZ8EkwuST6rdchdg1UxBoVzZ6IMiKNNNAMPkIJAlo0+HK3/WE5V4xkm58OFj75cAdZkE6SyYKkXy7F7ZDsAi7u/Fxjae7gC6E9F4IppAREdx29cT0YdE9AsRPWSMECwQ0cVENJmIJq9atSqd68geCdON+VG7eN10GZBcTJEJZpyVI+4Fep2k/3ZLSGzZJ3ppsvGV+qDa0HZlJo+0g5p5/PCD1mbTyVwmo3lXcaRTGWaYZz4ej4kX+71XWvf2v5jKL75NNwWo0af7bvGHBfk+2QgqqFkYQDcAAwC0B/AtEfU2th8IoA+AhQDeAXABgGH8wYyx5wE8DwB9+/bNrTQqbwJUr5fvr2oDrJktzhMqy3maKSc9o88JmGaAsfdz5/Q45M3iS5M25VVA7SZbWr00bPTpmm5yFeclF/Q+Vf8nxIdGX97E+TxeTUkZUUw2eq+kkwM6v6abJQA6cH+3N7bxLAYwkTFWB2AeEf0JXfAvBvArZ/b5GMC+sAn6vOKWzu/Ul4FFE4CFE/S/hV43QTcqTzZn+YmCqeaC4bp5QnbPPX8bPidjE8UCuo4rfwY2LQumrmzg1UZ/zofBjD7TUXAyWY/Ch/4+/3Of+WczJJ0VwV7Js9fNJADdiKgzEUUBnAngU1uZj6Fr8yCiFtBNNnONY5sQUUuj3KGw2vbzj1uC7gbNgR7HggtCzu3MkqBNeVkk58mZoA+IZp2Broc4FMhyCISgnlfzrkCn/sHUlQ1MwSmcqOU++Z0OC1hIpnl/D7vD52m483Q+0La2JM9kMqrPp42eMVYP4AoAIwHMBPAuY2w6EQ0hIjPS00gAa4hoBoAxAG5gjK1hjMUAXA9gNBH9Bv1NeCEbF5I2mkfrVWKRTAaLhwIhg3M5LXhx6/BygdePxGtH6HpcqeN3ojYPHPkffVV1sSJ9Z9MwJ+bZ6waMsREARti23cH9ZgCuNf7Zj/0awG6ZNTOLWMIJe3g4sgh8gZIF97gz3wJadJPv99rhBU0QfvTbnQB3wbwfW1bL9ykCJoD7qoKaZYiTpuhZozc9QkSrRAP2ow88jC+AHsc473eaq8iVcNg73fglJS68BtwCtPBhSzfnk4ROBgV2r4JcZFhQpHFdWXSg2D4EvRNeTRZC002hLD4JAL9p4YLm4nFA+728lSXbj1LXUgfcBFzxk/fyTu90YPcq03qK9ZllcTJWxbrJEKebb88EJcVpQi/olzYPH0G+TDdpYdwf0/uiZLXCNDn8ToedxSpgC5UM3z0Vjz5AnATBPpf4qyOT8Kpesdfb+1Q9qFqmSQ6cKCpBb3DiUKDxjlZ3OxHbW0fg5Btf7KOfvhfmuQEB379j/5v8ne+gZiXLJeOBVrt6K2va6GVJsYHsCZRmXYDbVgAtdspO/UAeBX0GPti9TwWu+c3HB1LkQs4rhTDf4hmfz/+4R7PTjLTJUAbsejJXlRL02cHPSy8S9IX2zWSCF0G/xznAFZOzc35fAqiUbnwWyPd8ixcKrsNJlwCVO6XRZwvy8cIJHmj7vfVsR4fcKi+TVrMKzEafiG/eydlFMx2OuBdosiPQ3Ee9JSMkfNL3QqDfxZnVkfG9c3jHt4vnIrn+xCr5wpyMLULDbIAQAcyjzV1koy9vDFw7A9jmECsnaLL1MfEpCnNJl4OBq3/Lz7mLjUDMFtuDMM4jLXsAf4wAGnhMDcqTxY5y+xb06Wj0ol7XKTZ4WmQxzKyIvhfqKxSLBr/3YDubjHWi0LTuUpsoP+RWYKfDgQ5757slFrZv0w0RPAsNpwVTQQvfoD7GPc7xVq59Pz3lX7GQdkjYAhNy+aAoIj8WEfaOKhQGOh2Qn7Y4sJ0/dT+TsZzppvGOtmoKVICcNDSgiswRS0DVKfJIFt7VNrvr/1e2CL7uoiGD+2qmIs0i27nphqUxGUvAv8YBW/gEKSWwYMqJbKRKzIgCuz/FRDaUksMHA71OBlr1DL5uk2tnAbGa7NXvFampKYNv48Ivsx72ejvR6J0eglfTjVlcAyqbWeN45yzWjQKAuj8ZkYV7F4p4D1+RLlVtgKadsnsOGSc86X29TTpUNAF2yK5Wv50Iege8Co2EH32ewxRnRcgViqauyDoF10kWwbu353m6sHek0O6rle1E0Msego/JWKdYNwX38ZQQ18wA+tgnlX3e71Lz7MiIgN5V9c4XFduJjd7JruZVoy+UxCN5JB8Cs3E7oGEr67a0hcx28pwA3c1PFPPGLXWmoiTZTgS9A16FRts9gGlv63FnZHXkRBDmQ1jlW0Dm+/xFyME3ireHyzOrt2UP/f9MbcqtjVxEfuLsFwT2b7w4RotK0HvNAbvPJUDngyWeBUoQZRf7x6Tud9pkKuh7ngBc+mPmHja7nQ607p1dT50gcVMIC9yUVXqCfsDNenCgb+7xVt7rAyKSv5S5fMh+z3X6q8BylxADxWbDLvCPqqAJIotREMLZ6XsqRgr8Gyq9ydgBg3Sf3pySQ8HToru/8j1PBA69LTttyRsqBIJC4YfSE/R5JQcCpeP+2T+HlCIXmGokoMgUmeZe4O9W6ZluAPlNv2A48PKxwZ9PCwH7Xwn0+lvwdYs492NgcZbiwovY/wpg/QJg30tzd04nCvyj2q45+11g1ax8tyILSN65AjfZmJSmoJc9lE79s3Q6Ao7wOCcQBF0P0f/livLGwMnP5+58rvgU9DsNBFb/CVQ0y05zFEm6H6n/UxQU24fppkh63fxR4vdn4BB94VXDlvluiUKRF0pTo1dD+9LG7/MNhfWFVwqdE58GopX5boUih5SmoPc6tK9sDlRv4A7bXjuIAr9uNSILlj5/z3cLipjifBe3D9ONiOtnAw224/jZgxYCPU8y/ijOl1ehyBlFrgR6EvREdBQR/UFEc4hokKTM6UQ0g4imE9Gbtn1VRLSYiJ4KotEeGuxepmEaOR1LifLGQLRBvlvhDfvzLPKPTqHINa6mGyIKARgKYCCAxQAmEdGnjLEZXJluAG4GcABjbB0R2aXo3QC+Da7ZbihB4IuiM42o56soFIrj2/Gi0fcDMIcxNpcxVgvgbQAn2spcBGAoY2wdADDGVpo7iGgvAK0AfBVMkxXbHUXXESkUhYUXQd8OwCLu78XGNp7uALoT0XgimkBERwEAEWkAHgFwvdMJiOhiIppMRJNXrVrlVNQbamjvj2K7X8XWXkXpUKQ6R1CTsWEA3QAMAHAWgBeIqAmAywCMYIwtdjqYMfY8Y6wvY6xvy5ZB+DorQeCLotOY1fNV5JrSj165BEAH7u/2xjaexQAmMsbqAMwjoj+hC/79ABxIRJcBaAggSkSbGWPCCd3sUWyCLFcU9suZoMA/IsV2TJEoSV40+kkAuhFRZyKKAjgTwKe2Mh9D1+ZBRC2gm3LmMsb+zhjbkTHWCbr55tWcCHklGEqLIvmYFIpCxVXQM8bqAVwBYCSAmQDeZYxNJ6IhRHSCUWwkgDVENAPAGAA3MMbWZKvR7tgFvRL8JUUhduQVzYCyqny3QpFrCvFdFOBpZSxjbASAEbZtd3C/GYBrjX+yOl4G8HI6jfRNys33qhEWx0Pb7ilEDf/62flugSIn2N69QnwXBZRoCAQfFEmPnF2K42UtaELqUyppilxOlGgIBB8PpUh65KxQ3O+uQpE7qgyP8j7n5LcdaVKaakiR9745w7Qphyvy2w6FotCpbAbcsc5BthS2zClNQe+H7blTOPQ2oGErYNdc59hVKIoQYWL14rAIlKigtwnvHsflpxmFTrQB0P/qfLdCoVBkmdIU9KaWXtEUuGm+c9nt2UavUCgypDgsAiU6GatQKBS5oDgUxRIV9A697C7HAxEujVrDVtxhxdE7KxSKAqPAZUeJCnoHzngduHVZ8u+yhsDZ7+avPYo0KA4tSqEoFLY/Qa8oQpRgVygyoTQFfYEPoxQKRYlQJM4cpSnoi+TmK7yigtQpCp3CfidLU9D7RXUMRYZ6XgqFH0pT0CvTTYmhBLtCkQmlKegVCoVCkUAJeoVCoShxlKBXKBSKEkcJegvKtl8UhMvz3QKFwqA45o9KM6iZojQ54GqgU3+gUet8t0ShsFLgDiBKo1cUD+VVQLeB+W6FQlF0KEGvUCgUJY4S9AqFQlHilKagL6sCGu8IHPeoxwOKY0Jlu6XPuUC0EbDrKfluiUJhpUhW1ZfmZGwoDFzzW75boQiK5l2BWxbnuxUKRdFSmhq9QqFQKBIoQc9T4C5SCoWiUCls2fH/7d1vjFxlFcfx749d2wZU2oUKS7e1JSyQRvmXpraBGKKl1sbQN0RpJBRp7BuJIEbThsRG35kQEWNDIIpGUDBWxE0lbLSSmBipbQOp7ZZ2t1TtFnArKZjoC1s5vrjPlMtY3J3d270zT3+fZDJzn/t0es6c2TMzz72zO6FGL2mVpAOSRiRtfJc5n5Y0JGmfpJ+ksWsk/SGN7ZH0mSqDNzOz8Y27Ri+pC9gC3ASMAjslDUTEUGlOP7AJuD4ijkv6QNr1L+D2iBiWdAmwW9JgRLxReSZmZnZaE3lHvxQYiYiXI+LfwJPAmqY5nwe2RMRxgIgYS9cHI2I43X4FGAPmVhW8mVm9OuOsm4k0+nnAkdL2aBoruxy4XNLvJT0vaVXznUhaCswADk02WDOzttTmx/eqOr2yG+gHbgT6gN9J+nBjiUZSL/AYsC4i3mr+x5I2ABsAFixYUFFILeiQc2HNrE21eQ+ZyDv6o8D80nZfGisbBQYi4kREHAYOUjR+JL0f+BVwX0Q8f7r/ICIeiYglEbFk7lyv7JiZVWkijX4n0C9pkaQZwK3AQNOcpynezSPpQoqlnJfT/F8AP4qIrZVFbWbWDi6+qrjuWVRvHOMYd+kmIk5KugsYBLqARyNin6RvALsiYiDtWylpCPgP8JWIeF3SbcBHgQsk3ZHu8o6IePFMJGNmNq2WboAFy6D36roj+b8mtEYfEc8AzzSNfa10O4B706U853Hg8amHaWbWhqS2b/Lgb8Y2ae8j52Zmk+FGb2aWOTd6M7PMudGbmWXOjb4dtfmXL8yss+T5h0c61er7YdZsuGJ13ZGYWUbc6NvJ+y6GNd+tOwozy4yXbszMMudGD3TKrxo1M5sMN3ozs8y50ZuZZc6N3swsc270ZmaZc6MHOCedZdo9s944zMzOAJ9HD3DZCrjhXlh+V92RmJlVzo0e4JwuWLG57ijMzM4IL92YmWXOjd7MLHNu9GZmmXOjNzPLnBu9mVnm3OjNzDLnRm9mljk3ejOzzCna7O+TSjoG/GUKd3Eh8PeKwukUzjl/Z1u+4Jxb9cGImHu6HW3X6KdK0q6IWFJ3HNPJOefvbMsXnHOVvHRjZpY5N3ozs8zl2OgfqTuAGjjn/J1t+YJzrkx2a/RmZvZOOb6jNzOzEjd6M7PMZdPoJa2SdEDSiKSNdcdTFUnzJT0naUjSPkl3p/EeSb+WNJyu56RxSfpOehz2SLqu3gwmT1KXpBckbUvbiyTtSLn9VNKMND4zbY+k/QvrjHuyJM2WtFXSS5L2S1qee50lfSk9r/dKekLSrNzqLOlRSWOS9pbGWq6rpHVp/rCkda3EkEWjl9QFbAE+CSwG1kpaXG9UlTkJfDkiFgPLgC+k3DYC2yOiH9ietqF4DPrTZQPw0PSHXJm7gf2l7W8CD0TEZcBxYH0aXw8cT+MPpHmd6EHg2Yi4EriaIvds6yxpHvBFYElEfAjoAm4lvzr/EFjVNNZSXSX1AJuBjwBLgc2NF4cJiYiOvwDLgcHS9iZgU91xnaFcfwncBBwAetNYL3Ag3X4YWFuaf2peJ12AvvQD8DFgGyCKbwx2N9ccGASWp9vdaZ7qzqHFfM8HDjfHnXOdgXnAEaAn1W0b8Ikc6wwsBPZOtq7AWuDh0vg75o13yeIdPW8/YRpG01hW0kfVa4EdwEUR8Wra9RpwUbqdy2PxbeCrwFtp+wLgjYg4mbbLeZ3KOe1/M83vJIuAY8AP0nLV9ySdR8Z1joijwP3AX4FXKeq2m7zr3NBqXadU71waffYkvRf4OXBPRPyjvC+Kl/hszpOV9ClgLCJ21x3LNOoGrgMeiohrgX/y9sd5IMs6zwHWULzIXQKcx/8ucWRvOuqaS6M/CswvbfelsSxIeg9Fk/9xRDyVhv8mqTft7wXG0ngOj8X1wM2S/gw8SbF88yAwW1J3mlPO61TOaf/5wOvTGXAFRoHRiNiRtrdSNP6c67wCOBwRxyLiBPAURe1zrnNDq3WdUr1zafQ7gf50tH4GxQGdgZpjqoQkAd8H9kfEt0q7BoDGkfd1FGv3jfHb09H7ZcCbpY+IHSEiNkVEX0QspKjlbyPis8BzwC1pWnPOjcfiljS/o975RsRrwBFJV6ShjwNDZFxniiWbZZLOTc/zRs7Z1rmk1boOAislzUmfhFamsYmp+yBFhQc7VgMHgUPAfXXHU2FeN1B8rNsDvJguqynWJrcDw8BvgJ40XxRnIB0C/kRxRkPteUwh/xuBben2pcAfgRHgZ8DMND4rbY+k/ZfWHfckc70G2JVq/TQwJ/c6A18HXgL2Ao8BM3OrM/AExTGIExSf3NZPpq7AnSn3EeBzrcTgX4FgZpa5XJZuzMzsXbjRm5llzo3ezCxzbvRmZplzozczy5wbvZlZ5tzozcwy918+TUdJp/XcygAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "-TMHOoQNS3QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2613991c-1f73-4573-d15e-43c6caa66584"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9220431e-20, 2.9922996e-23, 7.2618508e-01, ..., 9.4813587e-24,\n",
              "        1.8137180e-07, 8.1826147e-05],\n",
              "       [1.2394283e-10, 2.9275610e-11, 3.6953855e-01, ..., 1.7794609e-17,\n",
              "        1.6500628e-01, 3.2257432e-01],\n",
              "       [4.6294363e-10, 5.6892077e-06, 6.0332534e-31, ..., 2.9383109e-06,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       ...,\n",
              "       [1.4517970e-01, 2.0842746e-02, 1.2133833e-11, ..., 9.8338319e-07,\n",
              "        1.9883677e-07, 3.4490547e-01],\n",
              "       [2.1708179e-01, 9.1028497e-02, 3.9997276e-18, ..., 1.2549350e-05,\n",
              "        4.6417866e-13, 3.1981224e-05],\n",
              "       [3.0297271e-28, 8.7844546e-34, 5.6414914e-01, ..., 3.6866218e-31,\n",
              "        2.5169118e-07, 6.2646268e-07]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actual = np.argmax(y_test,axis=1)\n",
        "predicted = np.argsort(y_pred,axis=1)\n",
        "print(f\"Actual: {encoder.inverse_transform(actual[:1])}\\nPredicted: \")\n",
        "for top_5 in predicted[:1,7:]:\n",
        "  top_5 = encoder.inverse_transform(top_5)\n",
        "  i = 1\n",
        "  for name in top_5[::-1]:\n",
        "    print(f\"{i}. {name}\")\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "LTKo0gpfTFfg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8662f8ca-fea8-4a1e-b6cb-f45444c525e8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: ['Kubis']\n",
            "Predicted: \n",
            "1. Kubis\n",
            "2. Lavender\n",
            "3. Tomat\n",
            "4. Terung\n",
            "5. Kuping Gajah\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = model.predict([[temp, 1, 1, humidity]])\n",
        "output = np.argsort(input, axis=1)[:,7:].flatten()\n",
        "print(encoder.inverse_transform(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX6i9CvMiedh",
        "outputId": "59242eec-d815-4453-b241-56dd5f967474"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Lavender' 'Terung' 'Tomat' 'Kangkung' 'Melati']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation | LightGBM"
      ],
      "metadata": {
        "id": "F-N-y_41gBQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_2vVKRV2gQcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.iloc[:,0:4].values\n",
        "y = df.iloc[:,4].values"
      ],
      "metadata": {
        "id": "NKSjWDUUgWDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# set aside 20% of train and test data for evaluation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 8)"
      ],
      "metadata": {
        "id": "0YtGH5CkgnNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a lightgbm model\n",
        "import lightgbm as lgb\n",
        "\n",
        "model = lgb.LGBMClassifier()\n",
        "\n",
        "# Training the model using Training Data\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqKUa4dUguSG",
        "outputId": "41983215-e8da-4e5b-941f-04a0290577c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting the outputs over testing data\n",
        "y_pred=model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "hD5bZ3hegu32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Library to measure accuracy of model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Find accuracy on Expected Output and Predicted Output on Testing Data\n",
        "accuracy=accuracy_score(y_pred, y_test)\n",
        "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJSGdISMgxnp",
        "outputId": "23a796e1-1c20-44f1-db76-d4741371c630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Model accuracy score: 0.6725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find Training Score on Expected Output and Predicted Output on Training Data\n",
        "y_pred_train = model.predict(X_train)\n",
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8enDKW0hB4H",
        "outputId": "aca88dd2-8293-4262-8b6e-9c37936aadba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training-set accuracy score: 0.9175\n"
          ]
        }
      ]
    }
  ]
}